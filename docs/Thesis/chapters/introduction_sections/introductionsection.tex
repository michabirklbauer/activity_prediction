The discovery of new drugs or any chemically active compounds for that matter is an expensive and 
time-consuming process. It has been estimated, that it takes about 14 Years from the initial
discovery of a promising new compound to the release of a marketable drug\cite{Myers2001}. In 
addition to that the price of this drug-discovery circle ranges up to 800 Million Dollars\cite{DiMasi2003}.
All techniques which aim to improve the efficiency of drug discovery can be generalized as one of two methods. 
These two are called High-throughput-screening (HTS) and virtual screening (VS).
\\
When using an HTS-approach there are many compounds which are tested 
against some type of target protein. During testing, it is measured whether 
a certain compound biochemically interacts with a protein. Those interacting combinations 
are considered active and are marked by researchers as hits. To improve the performance of HTS there are a number of
factors to consider. Through miniaturization, it is possible to investigate more compounds at the same time. 
With a higher throughput quality-control is more time-consuming and leads to an overall more expensive process.
For this reason HTS is most efficient, when analyzing a small set of compounds as the technology is not 
suitable for large datasets\cite{Mayr2008}.
\\
In contrast to the in vitro approach of HTS, VS is a theoretical in silico approach. To save resources in the laboratory 
the activity of certain compounds is predicted using a preexisting library of small molecules. 
The activity can be predicted using the ligands of a compound and their respective binding sites or the 3D structure of a compound.
The Key idea behind the ligand based approach (LBVS) is that similar compounds have similar chemical properties.
Therefore, the goal of LBVS is to find molecules which have similar or identical chemical properties as the sample compound\cite{Gimeno2019}.
Structure-based VS uses the 3D structure of a compound to predict which molecules from the dataset will bind to the provided sample.
Each molecule of a certain database subset is fitted (docked) to the sample.
Hereby it is important to differentiate between rigid and flexible docking.
\\
In rigid docking the dataset sample is rotated and translated in a six-dimensional space in order to fit the sample protein.
For each fitted molecule a score is calculated based on how well the molecule fits to the sample\cite{Lavecchia2013}.
Although this algorithm often predicts actual possible binding sites and bound proteins, there is no guarantee that this compound will actually bind in vitro. 
Therefore, predicted interactions should be seen as a hypothesis. Still rigid docking provides a great baseline at a comparatively low cost\cite{Gimeno2019}.
The low accuracy of rigid docking is due to the nature of biochemical substances as samples in a database can only provide a snapshot of a sample.
With flexible docking it is possible to simulate moving binding sites.
The flexibility can be introduced at different stages. 
Implicit flexibility is achieved by smoothing protein surfaces and therefore allowing room for interpretation when docking.
Cross- or Ensemble docking can be done by repeating the docking process with different conformations.
Explicit flexibility is reached through allowing side-chain flexibility.
Most commonly utilized is the approach where the ligand is flexible, and the receptor is rigid.
Even though this approach does provide better more accurate results 
it takes considerably longer to compute\cite{Pagadala2017}.
\\
Regardless of the docking type the score decides which pose between a protein and a ligand is most likely to exist.
In addition to that, the score also determines whether a protein-ligand complex is considered active. 
There are a lot of different scoring functions which can be grouped into four categories:  physics-based, empirical, knowledge-based, and machine learning-based\cite{Li2019}.
\\
The focus of this work is on implementing a machine-learning based scoring approach.
Machine-learning based scoring functions work by training on pre-classified data and finding the best model for predicting future data.
To accurately and efficiently train a model crucial binding sites need to be identified beforehand.
The basis of this thesis is the master thesis of Birklbauer Micha\cite{Birklbauer2021}.
In his thesis a selection of eleven proteins from the directory of useful decoys have been selected to be analyzed.
For the selected proteins all possible interactions have been analyzed.
Based on the interaction-data a few basic scoring functions have been implemented.
The direct result of this thesis are proteins and the frequency of their interactions.
\\
Since this work aims to implement different machine learning algorithms for use in scoring functions the state of the art is described in the following. 


