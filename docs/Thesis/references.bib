 
 @Article{Myers2001,
  author       = {Myers, S. and Baker, A.},
  date         = {2001-08},
  journaltitle = {Nature Biotechnology},
  title        = {Drug discovery--an operating model for a new era},
  doi          = {10.1038/90765},
  issn         = {1087-0156},
  language     = {eng},
  number       = {8},
  pages        = {727--730},
  volume       = {19},
  file         = {PubMed entry:http\://www.ncbi.nlm.nih.gov/pubmed/11479559:text/html},
  keywords     = {Biotechnology, Chemistry, Drug Design, Drug Industry, Genome, Humans, Workforce},
  pmid         = {11479559},
}

 @online{WikiReliquienschrein2022,
	title={Reliquienschrein},
	url={https://de.wikipedia.org/wiki/Reliquienschrein},
	date={2022-08-29},
	urldate={2023-02-11},
	langid={ngerman}
}

 
 @Article{Wouters2020,
  author       = {Wouters, Olivier J. and McKee, Martin and Luyten, Jeroen},
  date         = {2020-03},
  journaltitle = {JAMA},
  title        = {Estimated {Research} and {Development} {Investment} {Needed} to {Bring} a {New} {Medicine} to {Market}, 2009-2018},
  doi          = {10.1001/jama.2020.1166},
  issn         = {1538-3598},
  language     = {eng},
  number       = {9},
  pages        = {844--853},
  volume       = {323},
  abstract     = {IMPORTANCE: The mean cost of developing a new drug has been the subject of debate, with recent estimates ranging from \$314 million to \$2.8 billion. OBJECTIVE: To estimate the research and development investment required to bring a new therapeutic agent to market, using publicly available data. DESIGN AND SETTING: Data were analyzed on new therapeutic agents approved by the US Food and Drug Administration (FDA) between 2009 and 2018 to estimate the research and development expenditure required to bring a new medicine to market. Data were accessed from the US Securities and Exchange Commission, Drugs@FDA database, and ClinicalTrials.gov, alongside published data on clinical trial success rates. EXPOSURES: Conduct of preclinical and clinical studies of new therapeutic agents. MAIN OUTCOMES AND MEASURES: Median and mean research and development spending on new therapeutic agents approved by the FDA, capitalized at a real cost of capital rate (the required rate of return for an investor) of 10.5\% per year, with bootstrapped CIs. All amounts were reported in 2018 US dollars. RESULTS: The FDA approved 355 new drugs and biologics over the study period. Research and development expenditures were available for 63 (18\%) products, developed by 47 different companies. After accounting for the costs of failed trials, the median capitalized research and development investment to bring a new drug to market was estimated at \$985.3 million (95\% CI, \$683.6 million-\$1228.9 million), and the mean investment was estimated at \$1335.9 million (95\% CI, \$1042.5 million-\$1637.5 million) in the base case analysis. Median estimates by therapeutic area (for areas with ≥5 drugs) ranged from \$765.9 million (95\% CI, \$323.0 million-\$1473.5 million) for nervous system agents to \$2771.6 million (95\% CI, \$2051.8 million-\$5366.2 million) for antineoplastic and immunomodulating agents. Data were mainly accessible for smaller firms, orphan drugs, products in certain therapeutic areas, first-in-class drugs, therapeutic agents that received accelerated approval, and products approved between 2014 and 2018. Results varied in sensitivity analyses using different estimates of clinical trial success rates, preclinical expenditures, and cost of capital. CONCLUSIONS AND RELEVANCE: This study provides an estimate of research and development costs for new therapeutic agents based on publicly available data. Differences from previous studies may reflect the spectrum of products analyzed, the restricted availability of data in the public domain, and differences in underlying assumptions in the cost calculations.},
  file         = {:Wouters2020 - Estimated Research and Development Investment Needed to Bring a New Medicine to Market, 2009 2018.html:URL},
  keywords     = {Costs and Cost Analysis, Drug Costs, Drug Development, Drug Industry, Pharmaceutical Research, United States, United States Food and Drug Administration},
  pmcid        = {PMC7054832},
  pmid         = {32125404},
}

 
@Article{Song2009,
  author       = {Song, Chun Meng and Lim, Shen Jean and Tong, Joo Chuan},
  date         = {2009-09},
  journaltitle = {Briefings in Bioinformatics},
  title        = {Recent advances in computer-aided drug design},
  doi          = {10.1093/bib/bbp023},
  issn         = {1467-5463},
  number       = {5},
  pages        = {579--591},
  url          = {https://doi.org/10.1093/bib/bbp023},
  urldate      = {2024-02-29},
  volume       = {10},
  abstract     = {Modern drug discovery is characterized by the production of vast quantities of compounds and the need to examine these huge libraries in short periods of time. The need to store, manage and analyze these rapidly increasing resources has given rise to the field known as computer-aided drug design (CADD). CADD represents computational methods and resources that are used to facilitate the design and discovery of new therapeutic solutions. Digital repositories, containing detailed information on drugs and other useful compounds, are goldmines for the study of chemical reactions capabilities. Design libraries, with the potential to generate molecular variants in their entirety, allow the selection and sampling of chemical compounds with diverse characteristics. Fold recognition, for studying sequence-structure homology between protein sequences and structures, are helpful for inferring binding sites and molecular functions. Virtual screening, the in silico analog of high-throughput screening, offers great promise for systematic evaluation of huge chemical libraries to identify potential lead candidates that can be synthesized and tested. In this article, we present an overview of the most important data sources and computational methods for the discovery of new molecular entities. The workflow of the entire virtual screening campaign is discussed, from data collection through to post-screening analysis.},
  file         = {:Song2009 - Recent Advances in Computer Aided Drug Design.pdf:PDF},
}

 

 
@Article{DiMasi2003,
  author       = {DiMasi, Joseph A. and Hansen, Ronald W. and Grabowski, Henry G.},
  date         = {2003-03},
  journaltitle = {Journal of Health Economics},
  title        = {The price of innovation: new estimates of drug development costs},
  doi          = {10.1016/S0167-6296(02)00126-1},
  issn         = {0167-6296},
  language     = {eng},
  number       = {2},
  pages        = {151--185},
  volume       = {22},
  abstract     = {The research and development costs of 68 randomly selected new drugs were obtained from a survey of 10 pharmaceutical firms. These data were used to estimate the average pre-tax cost of new drug development. The costs of compounds abandoned during testing were linked to the costs of compounds that obtained marketing approval. The estimated average out-of-pocket cost per new drug is 403 million US dollars (2000 dollars). Capitalizing out-of-pocket costs to the point of marketing approval at a real discount rate of 11\% yields a total pre-approval cost estimate of 802 million US dollars (2000 dollars). When compared to the results of an earlier study with a similar methodology, total capitalized costs were shown to have increased at an annual rate of 7.4\% above general price inflation.},
  file         = {PubMed entry:http\://www.ncbi.nlm.nih.gov/pubmed/12606142:text/html},
  keywords     = {Capital Expenditures, Costs and Cost Analysis, Data Collection, Drug Approval, Drug Evaluation, Drug Evaluation, Preclinical, Drug Industry, Drugs, Investigational, Humans, Inflation, Economic, Organizational Innovation, Research Support as Topic, United States},
  pmid         = {12606142},
  shorttitle   = {The price of innovation},
}

 
@Article{Mayr2008,
  author       = {Mayr, Lorenz M. and Fuerst, Peter},
  date         = {2008-07},
  journaltitle = {SLAS Discovery},
  title        = {The {Future} of {High}-{Throughput} {Screening}},
  doi          = {10.1177/1087057108319644},
  issn         = {2472-5552},
  number       = {6},
  pages        = {443--448},
  url          = {https://www.sciencedirect.com/science/article/pii/S2472555222082260},
  urldate      = {2024-02-29},
  volume       = {13},
  abstract     = {High-throughput screening (HTS) is a well-established process in lead discovery for pharma and biotech companies and is now also being set up for basic and applied research in academia and some research hospitals. Since its first advent in the early to mid-1990s, the field of HTS has seen not only a continuous change in technology and processes but also an adaptation to various needs in lead discovery. HTS has now evolved into a quite mature discipline of modern drug discovery. Whereas in previous years, much emphasis has been put toward a steady increase in capacity (“quantitative increase”) via various strategies in the fields of automation and miniaturization, the past years have seen a steady shift toward higher content and quality (“quality increase”) for these biological test systems. Today, many experts in the field see HTS at the crossroads with the need to decide either toward further increase in throughput or more focus toward relevance of biological data. In this article, the authors describe the development of HTS over the past decade and point out their own ideas for future directions of HTS in biomedical research. They predict that the trend toward further miniaturization will slow down with the implementation of 384-well, 1536-well, and 384 low-volume-well plates. The authors predict that, ultimately, each hit-finding strategy will be much more project related, tailor-made, and better integrated into the broader drug discovery efforts.},
  file         = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S2472555222082260/pdf?md5=2a40ac08b6e393e047e6064efdd88669&pid=1-s2.0-S2472555222082260-main.pdf&isDTMRedir=Y:application/pdf},
  keywords     = {high-throughput screening, lead finding, drug discovery, miniaturization, automation},
}

 
@Article{Gimeno2019,
  author       = {Gimeno, Aleix and Ojeda-Montes, María José and Tomás-Hernández, Sarah and Cereto-Massagué, Adrià and Beltrán-Debón, Raúl and Mulero, Miquel and Pujadas, Gerard and Garcia-Vallvé, Santiago},
  date         = {2019-03},
  journaltitle = {International Journal of Molecular Sciences},
  title        = {The {Light} and {Dark} {Sides} of {Virtual} {Screening}: {What} {Is} {There} to {Know}?},
  doi          = {10.3390/ijms20061375},
  issn         = {1422-0067},
  number       = {6},
  pages        = {1375},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6470506/},
  urldate      = {2024-02-29},
  volume       = {20},
  abstract     = {Virtual screening consists of using computational tools to predict potentially bioactive compounds from files containing large libraries of small molecules. Virtual screening is becoming increasingly popular in the field of drug discovery as in silico techniques are continuously being developed, improved, and made available. As most of these techniques are easy to use, both private and public organizations apply virtual screening methodologies to save resources in the laboratory. However, it is often the case that the techniques implemented in virtual screening workflows are restricted to those that the research team knows. Moreover, although the software is often easy to use, each methodology has a series of drawbacks that should be avoided so that false results or artifacts are not produced. Here, we review the most common methodologies used in virtual screening workflows in order to both introduce the inexperienced researcher to new methodologies and advise the experienced researcher on how to prevent common mistakes and the improper usage of virtual screening methodologies.},
  file         = {PubMed Central Link:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC6470506/:text/html;PubMed Central Full Text PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC6470506/pdf/ijms-20-01375.pdf:application/pdf},
  pmcid        = {PMC6470506},
  pmid         = {30893780},
  shorttitle   = {The {Light} and {Dark} {Sides} of {Virtual} {Screening}},
}

 
@Article{Lavecchia2013,
  author       = {Lavecchia, A. and Di Giovanni, C.},
  date         = {2013},
  journaltitle = {Current Medicinal Chemistry},
  title        = {Virtual screening strategies in drug discovery: a critical review},
  doi          = {10.2174/09298673113209990001},
  issn         = {1875-533X},
  language     = {eng},
  number       = {23},
  pages        = {2839--2860},
  volume       = {20},
  abstract     = {Virtual screening (VS) is a powerful technique for identifying hit molecules as starting points for medicinal chemistry. The number of methods and softwares which use the ligand and target-based VS approaches is increasing at a rapid pace. What, however, are the real advantages and disadvantages of the VS technology and how applicable is it to drug discovery projects? This review provides a comprehensive appraisal of several VS approaches currently available. In the first part of this work, an overview of the recent progress and advances in both ligand-based VS (LBVS) and structure-based VS (SBVS) strategies highlighting current problems and limitations will be provided. Special emphasis will be given to in silico chemogenomics approaches which utilize annotated ligand-target as well as protein-ligand interaction databases and which could predict or reveal promiscuous binding and polypharmacology, the knowledge of which would help medicinal chemists to design more potent clinical candidates with fewer side effects. In the second part, recent case studies (all published in the last two years) will be discussed where the VS technology has been applied successfully. A critical analysis of these case studies provides a good platform in order to estimate the applicability of various VS strategies in the new lead identification and optimization.},
  file         = {PubMed entry:http\://www.ncbi.nlm.nih.gov/pubmed/23651302:text/html},
  keywords     = {Drug Discovery, Drug Evaluation, Preclinical, Genomics, Humans, Ligands, Proteins},
  pmid         = {23651302},
  shorttitle   = {Virtual screening strategies in drug discovery},
}

 
@Article{Pagadala2017,
  author       = {Pagadala, Nataraj S. and Syed, Khajamohiddin and Tuszynski, Jack},
  date         = {2017-01},
  journaltitle = {Biophysical Reviews},
  title        = {Software for molecular docking: a review},
  doi          = {10.1007/s12551-016-0247-1},
  issn         = {1867-2450},
  number       = {2},
  pages        = {91--102},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5425816/},
  urldate      = {2024-02-29},
  volume       = {9},
  abstract     = {Molecular docking methodology explores the behavior of small molecules in the binding site of a target protein. As more protein structures are determined experimentally using X-ray crystallography or nuclear magnetic resonance (NMR) spectroscopy, molecular docking is increasingly used as a tool in drug discovery. Docking against homology-modeled targets also becomes possible for proteins whose structures are not known. With the docking strategies, the druggability of the compounds and their specificity against a particular target can be calculated for further lead optimization processes. Molecular docking programs perform a search algorithm in which the conformation of the ligand is evaluated recursively until the convergence to the minimum energy is reached. Finally, an affinity scoring function, ΔG [U total in kcal/mol], is employed to rank the candidate poses as the sum of the electrostatic and van der Waals energies. The driving forces for these specific interactions in biological systems aim toward complementarities between the shape and electrostatics of the binding site surfaces and the ligand or substrate.},
  file         = {PubMed Central Link:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC5425816/:text/html;PubMed Central Full Text PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC5425816/pdf/12551_2016_Article_247.pdf:application/pdf},
  pmcid        = {PMC5425816},
  pmid         = {28510083},
  shorttitle   = {Software for molecular docking},
}

 
@Article{Li2019,
  author       = {Li, Jin and Fu, Ailing and Zhang, Le},
  date         = {2019-06},
  journaltitle = {Interdisciplinary Sciences: Computational Life Sciences},
  title        = {An {Overview} of {Scoring} {Functions} {Used} for {Protein}–{Ligand} {Interactions} in {Molecular} {Docking}},
  doi          = {10.1007/s12539-019-00327-w},
  issn         = {1867-1462},
  language     = {en},
  number       = {2},
  pages        = {320--328},
  url          = {https://doi.org/10.1007/s12539-019-00327-w},
  urldate      = {2024-02-29},
  volume       = {11},
  abstract     = {Currently, molecular docking is becoming a key tool in drug discovery and molecular modeling applications. The reliability of molecular docking depends on the accuracy of the adopted scoring function, which can guide and determine the ligand poses when thousands of possible poses of ligand are generated. The scoring function can be used to determine the binding mode and site of a ligand, predict binding affinity and identify the potential drug leads for a given protein target. Despite intensive research over the years, accurate and rapid prediction of protein–ligand interactions is still a challenge in molecular docking. For this reason, this study reviews four basic types of scoring functions, physics-based, empirical, knowledge-based, and machine learning-based scoring functions, based on an up-to-date classification scheme. We not only discuss the foundations of the four types scoring functions, suitable application areas and shortcomings, but also discuss challenges and potential future study directions.},
  file         = {Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2Fs12539-019-00327-w.pdf:application/pdf},
  keywords     = {Molecular docking, Scoring function, Ligand pose, Binding affinity, Protein–ligand interaction},
}

@MastersThesis{Birklbauer2021,
  author      = {Micha Johannes Birklbauer},
  date        = {2021-08-31},
  institution = {FH Hagenberg},
  title       = {Automatic identification of important interactionsand interaction-frequency-based scoring inprotein-ligand complexes},
}

 
@Article{Bonvin2006,
  author       = {Bonvin, Alexandre MJJ},
  date         = {2006-04},
  journaltitle = {Current Opinion in Structural Biology},
  title        = {Flexible protein–protein docking},
  doi          = {10.1016/j.sbi.2006.02.002},
  issn         = {0959-440X},
  number       = {2},
  pages        = {194--200},
  series       = {Theory and simulation/{Macromolecular} assemblages},
  url          = {https://www.sciencedirect.com/science/article/pii/S0959440X06000315},
  urldate      = {2024-02-29},
  volume       = {16},
  abstract     = {Predicting the structure of protein–protein complexes using docking approaches is a difficult problem whose major challenges include identifying correct solutions, and properly dealing with molecular flexibility and conformational changes. Flexibility can be addressed at several levels: implicitly, by smoothing the protein surfaces or allowing some degree of interpenetration (soft docking) or by performing multiple docking runs from various conformations (cross or ensemble docking); or explicitly, by allowing sidechain and/or backbone flexibility. Although significant improvements have been achieved in the modeling of sidechains, methods for the explicit inclusion of backbone flexibility in docking are still being developed. A few novel approaches have emerged involving collective degrees of motion, multicopy representations and multibody docking, which should allow larger conformational changes to be modeled.},
  file         = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0959440X06000315/pdfft?md5=6e9d43b3a78412b370b49f454b2120a7&pid=1-s2.0-S0959440X06000315-main.pdf&isDTMRedir=Y:application/pdf},
}

 
@Article{Morris2022,
  author       = {Morris, Connor and Stern, Jacob and Stark, Brenden and Christopherson, Max and Della Corte, Dennis},
  date         = {2022-11},
  journaltitle = {Journal of chemical information and modeling},
  title        = {{MILCDock}: {Machine} {Learning} {Enhanced} {Consensus} {Docking} for {Virtual} {Screening} in {Drug} {Discovery}},
  doi          = {10.1021/acs.jcim.2c00705},
  volume       = {62},
  abstract     = {Molecular docking tools are regularly used to computationally identify new molecules in virtual screening for drug discovery. However, docking tools suffer from inaccurate scoring functions with widely varying performance on different proteins. To enable more accurate ranking of active over inactive ligands in virtual screening, we created a machine learning consensus docking tool, MILCDock, that uses predictions from five traditional molecular docking tools to predict the probability a ligand binds to a protein. MILCDock was trained and tested on data from both the DUD-E and LIT-PCBA docking datasets and shows improved performance over traditional molecular docking tools and other consensus docking methods on the DUD-E dataset. LIT-PCBA targets proved to be difficult for all methods tested. We also find that DUD-E data, although biased, can be effective in training machine learning tools if care is taken to avoid DUD-E's biases during training.},
  file         = {ResearchGate Link:https\://www.researchgate.net/publication/365205442_MILCDock_Machine_Learning_Enhanced_Consensus_Docking_for_Virtual_Screening_in_Drug_Discovery:},
  shorttitle   = {{MILCDock}},
}

 
@Article{Hossin2015,
  author       = {Hossin, Mohammad and M.N, Sulaiman},
  date         = {2015-03},
  journaltitle = {International Journal of Data Mining \& Knowledge Management Process},
  title        = {A {Review} on {Evaluation} {Metrics} for {Data} {Classification} {Evaluations}},
  doi          = {10.5121/ijdkp.2015.5201},
  pages        = {01--11},
  volume       = {5},
  abstract     = {Evaluation metric plays a critical role in achieving the optimal classifier during the classification training. Thus, a selection of suitable evaluation metric is an important key for discriminating and obtaining the optimal classifier. This paper systematically reviewed the related evaluation metrics that are specifically designed as a discriminator for optimizing generative classifier. Generally, many generative classifiers employ accuracy as a measure to discriminate the optimal solution during the classification training. However, the accuracy has several weaknesses which are less distinctiveness, less discriminability, less informativeness and bias to majority class data. This paper also briefly discusses other metrics that are specifically designed for discriminating the optimal solution. The shortcomings of these alternative metrics are also discussed. Finally, this paper suggests five important aspects that must be taken into consideration in constructing a new discriminator metric.},
  file         = {Full Text PDF:https\://www.researchgate.net/profile/Mohammad-Hossin/publication/275224157_A_Review_on_Evaluation_Metrics_for_Data_Classification_Evaluations/links/57b2c95008ae95f9d8f6154f/A-Review-on-Evaluation-Metrics-for-Data-Classification-Evaluations.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/275224157_A_Review_on_Evaluation_Metrics_for_Data_Classification_Evaluations:},
}

 
@Article{Lopes2017,
  author       = {Lopes, Julio Cesar Dias and dos Santos, Fábio Mendes and Martins-José, Andrelly and Augustyns, Koen and De Winter, Hans},
  date         = {2017-02},
  journaltitle = {Journal of Cheminformatics},
  title        = {The power metric: a new statistically robust enrichment-type metric for virtual screening applications with early recovery capability},
  doi          = {10.1186/s13321-016-0189-4},
  issn         = {1758-2946},
  number       = {1},
  pages        = {7},
  url          = {https://doi.org/10.1186/s13321-016-0189-4},
  urldate      = {2024-04-20},
  volume       = {9},
  abstract     = {A new metric for the evaluation of model performance in the field of virtual screening and quantitative structure–activity relationship applications is described. This metric has been termed the power metric and is defined as the fraction of the true positive rate divided by the sum of the true positive and false positive rates, for a given cutoff threshold. The performance of this metric is compared with alternative metrics such as the enrichment factor, the relative enrichment factor, the receiver operating curve enrichment factor, the correct classification rate, Matthews correlation coefficient and Cohen’s kappa coefficient. The performance of this new metric is found to be quite robust with respect to variations in the applied cutoff threshold and ratio of the number of active compounds to the total number of compounds, and at the same time being sensitive to variations in model quality. It possesses the correct characteristics for its application in early-recognition virtual screening problems.},
  file         = {Full Text PDF:Lopes2017 - The Power Metric_ a New Statistically Robust Enrichment Type Metric for Virtual Screening Applications with Early Recovery Capability.pdf:PDF:https\://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-016-0189-4},
  keywords     = {Power metric (PM), Virtual screening, Metric, Model performance, Enrichment factor, Area under the curve (AUC), Receiver operating curve enrichment factor (ROCE), Correct classification rate (CCR), Matthews correlation coefficient (MCC), Cohen’s kappa coefficient (CKC), Relative enrichment factor (REF)},
  shorttitle   = {The power metric},
}

 
@Article{Giordano2022,
  author       = {Giordano, Deborah and Biancaniello, Carmen and Argenio, Maria Antonia and Facchiano, Angelo},
  date         = {2022-05},
  journaltitle = {Pharmaceuticals},
  title        = {Drug {Design} by {Pharmacophore} and {Virtual} {Screening} {Approach}},
  doi          = {10.3390/ph15050646},
  issn         = {1424-8247},
  number       = {5},
  pages        = {646},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9145410/},
  urldate      = {2024-04-20},
  volume       = {15},
  abstract     = {Computer-aided drug discovery techniques reduce the time and the costs needed to develop novel drugs. Their relevance becomes more and more evident with the needs due to health emergencies as well as to the diffusion of personalized medicine. Pharmacophore approaches represent one of the most interesting tools developed, by defining the molecular functional features needed for the binding of a molecule to a given receptor, and then directing the virtual screening of large collections of compounds for the selection of optimal candidates. Computational tools to create the pharmacophore model and to perform virtual screening are available and generated successful studies. This article describes the procedure of pharmacophore modelling followed by virtual screening, the most used software, possible limitations of the approach, and some applications reported in the literature.},
  file         = {PubMed Central Link:Giordano2022 - Drug Design by Pharmacophore and Virtual Screening Approach.html:URL:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC9145410/;PubMed Central Full Text PDF:Giordano2022 - Drug Design by Pharmacophore and Virtual Screening Approach.pdf:PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC9145410/pdf/pharmaceuticals-15-00646.pdf},
  pmcid        = {PMC9145410},
  pmid         = {35631472},
}

@Article{Molinaro2005,
  author       = {Molinaro, Annette M. and Simon, Richard and Pfeiffer, Ruth M.},
  date         = {2005-05},
  journaltitle = {Bioinformatics},
  title        = {{Prediction error estimation: a comparison of resampling methods}},
  doi          = {10.1093/bioinformatics/bti499},
  eprint       = {https://academic.oup.com/bioinformatics/article-pdf/21/15/3301/50340684/bioinformatics\_21\_15\_3301.pdf},
  issn         = {1367-4803},
  number       = {15},
  pages        = {3301-3307},
  url          = {https://doi.org/10.1093/bioinformatics/bti499},
  volume       = {21},
  abstract     = {{Motivation: In genomic studies, thousands of features are collected on relatively few samples. One of the goals of these studies is to build classifiers to predict the outcome of future observations. There are three inherent steps to this process: feature selection, model selection and prediction assessment. With a focus on prediction assessment, we compare several methods for estimating the ‘true’ prediction error of a prediction model in the presence of feature selection.Results: For small studies where features are selected from thousands of candidates, the resubstitution and simple split-sample estimates are seriously biased. In these small samples, leave-one-out cross-validation (LOOCV), 10-fold cross-validation (CV) and the .632+ bootstrap have the smallest bias for diagonal discriminant analysis, nearest neighbor and classification trees. LOOCV and 10-fold CV have the smallest bias for linear discriminant analysis. Additionally, LOOCV, 5- and 10-fold CV, and the .632+ bootstrap have the lowest mean square error. The .632+ bootstrap is quite biased in small sample sizes with strong signal-to-noise ratios. Differences in performance among resampling methods are reduced as the number of specimens available increase.Contact:  annette.molinaro@yale.eduSupplementary Information: A complete compilation of results and R code for simulations and analyses are available in Molinaro et al. (2005) (http://linus.nci.nih.gov/brb/TechReport.htm).}},
}

 
@Article{Xu2018,
  author       = {Xu, Yun and Goodacre, Royston},
  date         = {2018-07},
  journaltitle = {Journal of Analysis and Testing},
  title        = {On {Splitting} {Training} and {Validation} {Set}: {A} {Comparative} {Study} of {Cross}-{Validation}, {Bootstrap} and {Systematic} {Sampling} for {Estimating} the {Generalization} {Performance} of {Supervised} {Learning}},
  doi          = {10.1007/s41664-018-0068-2},
  issn         = {2509-4696},
  language     = {en},
  number       = {3},
  pages        = {249--262},
  url          = {https://doi.org/10.1007/s41664-018-0068-2},
  urldate      = {2024-04-21},
  volume       = {2},
  abstract     = {Model validation is the most important part of building a supervised model. For building a model with good generalization performance one must have a sensible data splitting strategy, and this is crucial for model validation. In this study, we conducted a comparative study on various reported data splitting methods. The MixSim model was employed to generate nine simulated datasets with different probabilities of mis-classification and variable sample sizes. Then partial least squares for discriminant analysis and support vector machines for classification were applied to these datasets. Data splitting methods tested included variants of cross-validation, bootstrapping, bootstrapped Latin partition, Kennard-Stone algorithm (K-S) and sample set partitioning based on joint X–Y distances algorithm (SPXY). These methods were employed to split the data into training and validation sets. The estimated generalization performances from the validation sets were then compared with the ones obtained from the blind test sets which were generated from the same distribution but were unseen by the training/validation procedure used in model construction. The results showed that the size of the data is the deciding factor for the qualities of the generalization performance estimated from the validation set. We found that there was a significant gap between the performance estimated from the validation set and the one from the test set for the all the data splitting methods employed on small datasets. Such disparity decreased when more samples were available for training/validation, and this is because the models were then moving towards approximations of the central limit theory for the simulated datasets used. We also found that having too many or too few samples in the training set had a negative effect on the estimated model performance, suggesting that it is necessary to have a good balance between the sizes of training set and validation set to have a reliable estimation of model performance. We also found that systematic sampling method such as K-S and SPXY generally had very poor estimation of the model performance, most likely due to the fact that they are designed to take the most representative samples first and thus left a rather poorly representative sample set for model performance estimation.},
  file         = {Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2Fs41664-018-0068-2.pdf:application/pdf},
  keywords     = {Cross-validation, Bootstrapping, Bootstrapped Latin partition, Kennard-Stone algorithm, SPXY, Model selection, Model validation, Partial least squares for discriminant analysis, Support vector machines},
  shorttitle   = {On {Splitting} {Training} and {Validation} {Set}},
}

 
@Article{Tripathi2010,
  author       = {Tripathi, Anurag and Srivastava, U. C.},
  date         = {2010-02},
  journaltitle = {Annals of Neurosciences},
  title        = {Acetylcholinesterase :{A} {Versatile} {Enzyme} of {Nervous} {System}},
  doi          = {10.5214/95},
  issn         = {0972-7531},
  number       = {4},
  pages        = {106--111},
  url          = {http://annalsofneurosciences.org/journal/index.php/annal/article/view/95},
  urldate      = {2024-04-22},
  volume       = {15},
  abstract     = {Acetylcholinesterase (AChE) terminates the neurotransmission at cholinergic synapses by splitting the neurotransmitter acetylcholine. The nature and didtribution of the enzyme has extensively been studied in many invertebrates and vertebrates including human, histochemically and biochemically. The enzyme demonstrates a high degree of variability in distribution with its notable presense in nonneuronal tissues also, which provides pertinent theme to investigate its nonclassical role.  Recently a lot of information has come out regarding its dynamic structure, gene expression, its role in neuronal morphogenesis and synaptogenesis. The significance of AChE stems from the fact that it is the target of drugs designed to treat myasthenia gravis, glaucoma, alzheimer's disease etc.  Keeping in view, above mentioned facts a thorough review has been made in the present article regarding its biochemistry, structural dynamics, wide distribution, isoforms and its implications in neurodegenerative disorders.  doi: 10.5214/ans.0972.7531.2008.150403       Competing interests: None.     Source of Funding: None       Received Date: 08 Sept 2008       Revised Date: 13 Oct 2008       Accepted Date: 22 Oct 2008},
  copyright    = {The corresponding author should agree, by the act of submission, that the copyright of the manuscript, was in fact transferred to the journal and would be done so without any renumeration from the Journal, such transfer being irrevocable after publication. Authors hold the right to withdraw any manuscript from consideration for publication for any reason until the issue was copyset for publication, after which the manuscripts would be retracted. On behalf of all authors the submitting author should either be the corresponding author or if not, the corresponding author should assert by submission of any and all manuscripts for review that the manuscript is not under consideration elsewhere. That all individuals who participated in the study in a material manner are listed as authors, or if not, why. That all authors have reviewed and agree with the content, presentation, organization, data and interpretation of the data or the manuscript as well as their position within the authorship list, that no individual who either holds or claims any authorship right has been excluded and if not, explain, that the facts of the paper are true and honest and that all experiments that require institutional or governmental approval have been submitted, evaluated and awarded required approvals including but not limited to human experimentation and clinical trials, animal use, use of toxic chemicals and radioactive elements, regulators pertaining to any and all aspects of ICMR-DBT guidelines of stem cell research if applicable, or any other regulation pertinent to the study. On behalf of all authors, the corresponding author agrees to be listed as such, and all other authors consent to this listing. The listed corresponding author on behalf of all authors by submission of the paper for review or publication testifies that he or she is reasonably certain that the data presented are accurate, has no reason to question the validity of any fact, statement or experimental result presented in the paper, has directly participated in all aspects of the study has not copied the work or any aspect of it from another source, has not reviewed any paper that presents substantially identical results and has in fact not accepted that paper for publication or is aware that the paper is no longer being evaluated for publication unless that paper is referred to by reference of footnote in the submitted manuscript, that any and all future allegations of scientific misconduct or fraud that arise from either the submission or publication of the paper shall be relayed to the editor in chief in timely manner and that the proceedings of any investigation will be communicated as they evolve, that the journal reserves the right to publish such information if that information is in fact in the public domain and to comment upon it as the findings if invalid relate to the science communicated by the Journal.},
  file         = {Full Text PDF:http\://annalsofneurosciences.org/journal/index.php/annal/article/view/95/199:application/pdf},
  shorttitle   = {Acetylcholinesterase},
}

 
@Article{Rouzer2009,
  author       = {Rouzer, Carol A. and Marnett, Lawrence J.},
  date         = {2009-04},
  journaltitle = {Journal of Lipid Research},
  title        = {Cyclooxygenases: structural and functional insights},
  doi          = {10.1194/jlr.R800042-JLR200},
  issn         = {0022-2275},
  number       = {Suppl},
  pages        = {S29--S34},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2674713/},
  urldate      = {2024-04-22},
  volume       = {50},
  abstract     = {Cyclooxygenase (COX; prostaglandin G/H synthase, EC 1.14.99.1) catalyzes the first two steps in the biosynthesis of prostaglandins (PGs). The two COX isoforms COX-1 and COX-2 are the targets of the widely used nonsteroidal anti-inflammatory drugs, indicating a role for these enzymes in pain, fever, inflammation, and tumorigenesis. The ubiquitous constitutive expression of COX-1 and inducible expression of COX-2 have led to the widely held belief that COX-1 produces homeostatic PGs, while PGs produced by COX-2 are primarily pathophysiological. However, recent discoveries call this paradigm into question and reveal as yet underappreciated functions for both enzymes. This review focuses on some of these new insights.},
  file         = {PubMed Central Link:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC2674713/:text/html;PubMed Central Full Text PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC2674713/pdf/JLR50SUPPS29.pdf:application/pdf},
  pmcid        = {PMC2674713},
  pmid         = {18952571},
  shorttitle   = {Cyclooxygenases},
}

 
@Article{Yu2010,
  author       = {Yu, Denise M. T. and Yao, Tsun-Wen and Chowdhury, Sumaiya and Nadvi, Naveed A. and Osborne, Brenna and Church, W. Bret and McCaughan, Geoffrey W. and Gorrell, Mark D.},
  date         = {2010},
  journaltitle = {The FEBS Journal},
  title        = {The dipeptidyl peptidase {IV} family in cancer and cell biology},
  doi          = {10.1111/j.1742-4658.2009.07526.x},
  issn         = {1742-4658},
  language     = {en},
  number       = {5},
  pages        = {1126--1144},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1742-4658.2009.07526.x},
  urldate      = {2024-04-22},
  volume       = {277},
  abstract     = {Of the 600+ known proteases identified to date in mammals, a significant percentage is involved or implicated in pathogenic and cancer processes. The dipeptidyl peptidase IV (DPIV) gene family, comprising four enzyme members [DPIV (EC 3.4.14.5), fibroblast activation protein, DP8 and DP9] and two nonenzyme members [DP6 (DPL1) and DP10 (DPL2)], are interesting in this regard because of their multiple diverse functions, varying patterns of distribution/localization and subtle, but significant, differences in structure/substrate recognition. In addition, their engagement in cell biological processes involves both enzymatic and nonenzymatic capabilities. This article examines, in detail, our current understanding of the biological involvement of this unique enzyme family and their overall potential as therapeutic targets.},
  copyright    = {© 2010 The Authors Journal compilation © 2010 FEBS},
  file         = {Full Text PDF:https\://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1742-4658.2009.07526.x:application/pdf},
  keywords     = {cancer, dipeptidyl peptidase, distribution, enzyme, extracellular matrix, immune function, liver fibrosis, structure},
}

 
@Article{Ramsay2016,
  author       = {Ramsay, Rona R.},
  date         = {2016-08},
  journaltitle = {Progress in Neuro-Psychopharmacology and Biological Psychiatry},
  title        = {Molecular aspects of monoamine oxidase {B}},
  doi          = {10.1016/j.pnpbp.2016.02.005},
  issn         = {0278-5846},
  pages        = {81--89},
  url          = {https://www.sciencedirect.com/science/article/pii/S0278584616300197},
  urldate      = {2024-04-22},
  volume       = {69},
  abstract     = {Monoamine oxidases (MAO) influence the monoamine levels in brain by virtue of their role in neurotransmitter breakdown. MAO B is the predominant form in glial cells and in platelets. MAO B structure, function and kinetics are described as a background for the effect of alterations in its activity on behavior. The need to inhibit MAO B to combat decreased brain amines continues to drive the search for new drugs. Reversible and irreversible inhibitors are now designed using data-mining, computational screening, docking and molecular dynamics. Multi-target ligands designed to combat the elevated activity of MAO B in Alzheimer's and Parkinson's Diseases incorporate MAO inhibition (usually irreversible) as well as iron chelation, antioxidant or neuroprotective properties. The main focus of drug design is the catalytic activity of MAO, but the imidazoline I2 site in the entrance cavity of MAO B is also a pharmacological target. Endogenous regulation of MAO B expression is discussed briefly in light of new studies measuring mRNA, protein, or activity in healthy and degenerative samples, including the effect of DNA methylation on the expression. Overall, this review focuses on examples of recent research on the molecular aspects of the expression, activity, and inhibition of MAO B.},
  file         = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/abs/pii/S0278584616300197/pdfft?isDTMRedir=true&download=true:application/pdf},
  keywords     = {Monoamine oxidase B, Kinetics, Drug design, Neurotransmitter levels, Platelet},
}

 
@Article{Schmelzer2005,
  author       = {Schmelzer, Kara R. and Kubala, Lukas and Newman, John W. and Kim, In-Hae and Eiserich, Jason P. and Hammock, Bruce D.},
  date         = {2005-07},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  title        = {Soluble epoxide hydrolase is a therapeutic target for acute inflammation},
  doi          = {10.1073/pnas.0503279102},
  issn         = {0027-8424},
  language     = {eng},
  number       = {28},
  pages        = {9772--9777},
  volume       = {102},
  abstract     = {As of 2004, {\textgreater}73 million people were prescribed antiinflammatory medication. Despite the extensive number of current products, many people still suffer from their diseases or the pharmacological properties (side effects) of the medications. Therefore, developing therapeutic strategies to treat inflammation remains an important endeavor. Here, we demonstrate that the soluble epoxide hydrolase (sEH) is a key pharmacologic target for treating acute systemic inflammation. Lipopolysaccharide-induced mortality, systemic hypotension, and histologically evaluated tissue injury were substantially diminished by administration of urea-based, small-molecule inhibitors of sEH to C57BL/6 mice. Moreover, sEH inhibitors decreased plasma levels of proinflammatory cytokines and nitric oxide metabolites while promoting the formation of lipoxins, thus supporting inflammatory resolution. These data suggest that sEH inhibitors have therapeutic efficacy in the treatment and management of acute inflammatory diseases.},
  file         = {PubMed entry:http\://www.ncbi.nlm.nih.gov/pubmed/15994227:text/html},
  keywords     = {Adamantane, Animals, Arachidonic Acids, Blood Pressure, Chromatography, High Pressure Liquid, Cytokines, Dose-Response Relationship, Drug, Epoxide Hydrolases, Immunoblotting, Inflammation, Lipopolysaccharides, Lipoxins, Male, Mass Spectrometry, Mice, Mice, Inbred C57BL, Prostaglandin-Endoperoxide Synthases, Urea},
  pmcid        = {PMC1168955},
  pmid         = {15994227},
}

 
@Article{Salentin2015,
  author       = {Salentin, Sebastian and Schreiber, Sven and Haupt, V. Joachim and Adasme, Melissa F. and Schroeder, Michael},
  date         = {2015-07},
  journaltitle = {Nucleic Acids Research},
  title        = {{PLIP}: fully automated protein–ligand interaction profiler},
  doi          = {10.1093/nar/gkv315},
  issn         = {0305-1048},
  number       = {Web Server issue},
  pages        = {W443--W447},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4489249/},
  urldate      = {2024-04-23},
  volume       = {43},
  abstract     = {The characterization of interactions in protein–ligand complexes is essential for research in structural bioinformatics, drug discovery and biology. However, comprehensive tools are not freely available to the research community. Here, we present the protein–ligand interaction profiler (PLIP), a novel web service for fully automated detection and visualization of relevant non-covalent protein–ligand contacts in 3D structures, freely available at projects.biotec.tu-dresden.de/plip-web. The input is either a Protein Data Bank structure, a protein or ligand name, or a custom protein–ligand complex (e.g. from docking). In contrast to other tools, the rule-based PLIP algorithm does not require any structure preparation. It returns a list of detected interactions on single atom level, covering seven interaction types (hydrogen bonds, hydrophobic contacts, pi-stacking, pi-cation interactions, salt bridges, water bridges and halogen bonds). PLIP stands out by offering publication-ready images, PyMOL session files to generate custom images and parsable result files to facilitate successive data processing. The full python source code is available for download on the website. PLIP's command-line mode allows for high-throughput interaction profiling.},
  file         = {PubMed Central Link:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC4489249/:text/html;PubMed Central Full Text PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC4489249/pdf/gkv315.pdf:application/pdf},
  pmcid        = {PMC4489249},
  pmid         = {25873628},
  shorttitle   = {{PLIP}},
}

 
@Article{Mysinger2012,
  author       = {Mysinger, Michael M. and Carchia, Michael and Irwin, John. J. and Shoichet, Brian K.},
  date         = {2012-07},
  journaltitle = {Journal of Medicinal Chemistry},
  title        = {Directory of {Useful} {Decoys}, {Enhanced} ({DUD}-{E}): {Better} {Ligands} and {Decoys} for {Better} {Benchmarking}},
  doi          = {10.1021/jm300687e},
  issn         = {0022-2623},
  number       = {14},
  pages        = {6582--6594},
  url          = {https://doi.org/10.1021/jm300687e},
  urldate      = {2024-04-30},
  volume       = {55},
  abstract     = {A key metric to assess molecular docking remains ligand enrichment against challenging decoys. Whereas the directory of useful decoys (DUD) has been widely used, clear areas for optimization have emerged. Here we describe an improved benchmarking set that includes more diverse targets such as GPCRs and ion channels, totaling 102 proteins with 22886 clustered ligands drawn from ChEMBL, each with 50 property-matched decoys drawn from ZINC. To ensure chemotype diversity, we cluster each target’s ligands by their Bemis–Murcko atomic frameworks. We add net charge to the matched physicochemical properties and include only the most dissimilar decoys, by topology, from the ligands. An online automated tool (http://decoys.docking.org) generates these improved matched decoys for user-supplied ligands. We test this data set by docking all 102 targets, using the results to improve the balance between ligand desolvation and electrostatics in DOCK 3.6. The complete DUD-E benchmarking set is freely available at http://dude.docking.org.},
  file         = {Full Text PDF:https\://pubs.acs.org/doi/pdf/10.1021/jm300687e:application/pdf},
  publisher    = {American Chemical Society},
  shorttitle   = {Directory of {Useful} {Decoys}, {Enhanced} ({DUD}-{E})},
}

 
@Article{Chen2018,
  author       = {Chen, Hongming and Engkvist, Ola and Wang, Yinhai and Olivecrona, Marcus and Blaschke, Thomas},
  date         = {2018-06},
  journaltitle = {Drug Discovery Today},
  title        = {The rise of deep learning in drug discovery},
  doi          = {10.1016/j.drudis.2018.01.039},
  issn         = {1878-5832},
  language     = {eng},
  number       = {6},
  pages        = {1241--1250},
  volume       = {23},
  abstract     = {Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis.},
  file         = {PubMed entry:http\://www.ncbi.nlm.nih.gov/pubmed/29366762:text/html},
  keywords     = {Datasets as Topic, Diagnostic Imaging, Drug Discovery, Machine Learning, Neural Networks, Computer},
  pmid         = {29366762},
}

 
@Article{Zeng,
  author       = {Zeng, Xiangxiang and Zhu, Siyi and Lu, Weiqiang and Liu, Zehui and Huang, Jin and Zhou, Yadi and Fang, Jiansong and Huang, Yin and Guo, Huimin and Li, Lang and Trapp, Bruce D. and Nussinov, Ruth and Eng, Charis and Loscalzo, Joseph and Cheng, Feixiong},
  journaltitle = {Chemical Science},
  title        = {Target identification among known drugs by deep learning from heterogeneous networks},
  doi          = {10.1039/c9sc04336e},
  issn         = {2041-6520},
  number       = {7},
  pages        = {1775--1797},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8150105/},
  urldate      = {2024-04-30},
  volume       = {11},
  abstract     = {Without foreknowledge of the complete drug target information, development of promising and affordable approaches for effective treatment of human diseases is challenging. Here, we develop deepDTnet, a deep learning methodology for new target identification and drug repurposing in a heterogeneous drug–gene–disease network embedding 15 types of chemical, genomic, phenotypic, and cellular network profiles. Trained on 732 U.S. Food and Drug Administration-approved small molecule drugs, deepDTnet shows high accuracy (the area under the receiver operating characteristic curve = 0.963) in identifying novel molecular targets for known drugs, outperforming previously published state-of-the-art methodologies. We then experimentally validate that deepDTnet-predicted topotecan (an approved topoisomerase inhibitor) is a new, direct inhibitor (IC50 = 0.43 μM) of human retinoic-acid-receptor-related orphan receptor-gamma t (ROR-γt). Furthermore, by specifically targeting ROR-γt, topotecan reveals a potential therapeutic effect in a mouse model of multiple sclerosis. In summary, deepDTnet offers a powerful network-based deep learning methodology for target identification to accelerate drug repurposing and minimize the translational gap in drug development., Target identification and drug repurposing could benefit from network-based, rational deep learning prediction, and explore the relationship between drugs and targets in the heterogeneous drug–gene–disease network.},
  file         = {PubMed Central Link:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC8150105/:text/html;PubMed Central Full Text PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC8150105/pdf/SC-011-C9SC04336E.pdf:application/pdf},
  pmcid        = {PMC8150105},
  pmid         = {34123272},
}

 
@Article{Manavalan2017,
  author       = {Manavalan, Balachandran and Lee, Jooyoung},
  date         = {2017-08},
  journaltitle = {Bioinformatics (Oxford, England)},
  title        = {{SVMQA}: support-vector-machine-based protein single-model quality assessment},
  doi          = {10.1093/bioinformatics/btx222},
  issn         = {1367-4811},
  language     = {eng},
  number       = {16},
  pages        = {2496--2503},
  volume       = {33},
  abstract     = {MOTIVATION: The accurate ranking of predicted structural models and selecting the best model from a given candidate pool remain as open problems in the field of structural bioinformatics. The quality assessment (QA) methods used to address these problems can be grouped into two categories: consensus methods and single-model methods. Consensus methods in general perform better and attain higher correlation between predicted and true quality measures. However, these methods frequently fail to generate proper quality scores for native-like structures which are distinct from the rest of the pool. Conversely, single-model methods do not suffer from this drawback and are better suited for real-life applications where many models from various sources may not be readily available. RESULTS: In this study, we developed a support-vector-machine-based single-model global quality assessment (SVMQA) method. For a given protein model, the SVMQA method predicts TM-score and GDT\_TS score based on a feature vector containing statistical potential energy terms and consistency-based terms between the actual structural features (extracted from the three-dimensional coordinates) and predicted values (from primary sequence). We trained SVMQA using CASP8, CASP9 and CASP10 targets and determined the machine parameters by 10-fold cross-validation. We evaluated the performance of our SVMQA method on various benchmarking datasets. Results show that SVMQA outperformed the existing best single-model QA methods both in ranking provided protein models and in selecting the best model from the pool. According to the CASP12 assessment, SVMQA was the best method in selecting good-quality models from decoys in terms of GDTloss. AVAILABILITY AND IMPLEMENTATION: SVMQA method can be freely downloaded from http://lee.kias.re.kr/SVMQA/SVMQA\_eval.tar.gz. CONTACT: jlee@kias.re.kr. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
  file         = {PubMed entry:http\://www.ncbi.nlm.nih.gov/pubmed/28419290:text/html},
  keywords     = {Caspase 10, Caspase 8, Caspase 9, Computational Biology, Models, Molecular, Protein Conformation, Quality Control, Support Vector Machine},
  pmid         = {28419290},
  shorttitle   = {{SVMQA}},
}

 
@Article{Eid2016,
  author       = {Eid, Fatma-Elzahraa and ElHefnawi, Mahmoud and Heath, Lenwood S.},
  date         = {2016-04},
  journaltitle = {Bioinformatics},
  title        = {{DeNovo}: virus-host sequence-based protein–protein interaction prediction},
  doi          = {10.1093/bioinformatics/btv737},
  issn         = {1367-4803},
  number       = {8},
  pages        = {1144--1150},
  url          = {https://doi.org/10.1093/bioinformatics/btv737},
  urldate      = {2024-04-30},
  volume       = {32},
  abstract     = {Motivation Can we predict protein–protein interactions (PPIs) of a novel virus with its host? Three major problems arise: the lack of known PPIs for that virus to learn from, the cost of learning about its proteins and the sequence dissimilarity among viral families that makes most methods inapplicable or inefficient. We develop DeNovo, a sequence-based negative sampling and machine learning framework that learns from PPIs of different viruses to predict for a novel one, exploiting the shared host proteins. We tested DeNovo on PPIs from different domains to assess generalization.Results: By solving the challenge of generating less noisy negative interactions, DeNovo achieved accuracy up to 81 and 86\% when predicting PPIs of viral proteins that have no and distant sequence similarity to the ones used for training, receptively. This result is comparable to the best achieved in single virus-host and intra-species PPI prediction cases. Thus, we can now predict PPIs for virtually any virus infecting human. DeNovo generalizes well; it achieved near optimal accuracy when tested on bacteria–human interactions.Availability and implementation: Code, data and additional supplementary materials needed to reproduce this study are available at: https://bioinformatics.cs.vt.edu/{\textasciitilde}alzahraa/denovo.Contact:  alzahraa@vt.eduSupplementary information: Supplementary data are available at Bioinformatics online.},
  file         = {Full Text PDF:https\://academic.oup.com/bioinformatics/article-pdf/32/8/1144/49018450/bioinformatics_32_8_1144.pdf:application/pdf},
  shorttitle   = {{DeNovo}},
}

 
@Article{Kraus2016,
  author       = {Kraus, Oren Z. and Ba, Jimmy Lei and Frey, Brendan J.},
  date         = {2016-06},
  journaltitle = {Bioinformatics},
  title        = {Classifying and segmenting microscopy images with deep multiple instance learning},
  doi          = {10.1093/bioinformatics/btw252},
  issn         = {1367-4803},
  number       = {12},
  pages        = {i52--i59},
  url          = {https://doi.org/10.1093/bioinformatics/btw252},
  urldate      = {2024-05-01},
  volume       = {32},
  abstract     = {Motivation : High-content screening (HCS) technologies have enabled large scale imaging experiments for studying cell biology and for drug screening. These systems produce hundreds of thousands of microscopy images per day and their utility depends on automated image analysis. Recently, deep learning approaches that learn feature representations directly from pixel intensity values have dominated object recognition challenges. These tasks typically have a single centered object per image and existing models are not directly applicable to microscopy datasets. Here we develop an approach that combines deep convolutional neural networks (CNNs) with multiple instance learning (MIL) in order to classify and segment microscopy images using only whole image level annotations. Results : We introduce a new neural network architecture that uses MIL to simultaneously classify and segment microscopy images with populations of cells. We base our approach on the similarity between the aggregation function used in MIL and pooling layers used in CNNs. To facilitate aggregating across large numbers of instances in CNN feature maps we present the Noisy-AND pooling function, a new MIL operator that is robust to outliers. Combining CNNs with MIL enables training CNNs using whole microscopy images with image level labels. We show that training end-to-end MIL CNNs outperforms several previous methods on both mammalian and yeast datasets without requiring any segmentation steps. Availability and implementation : Torch7 implementation available upon request. Contact : oren.kraus@mail.utoronto.ca},
  file         = {Full Text PDF:https\://academic.oup.com/bioinformatics/article-pdf/32/12/i52/49021130/bioinformatics_32_12_i52.pdf:application/pdf},
}

 
@Article{Johansson2019,
  author       = {Johansson, Simon and Thakkar, Amol and Kogej, Thierry and Bjerrum, Esben and Genheden, Samuel and Bastys, Tomas and Kannas, Christos and Schliep, Alexander and Chen, Hongming and Engkvist, Ola},
  date         = {2019-12},
  journaltitle = {Drug Discovery Today: Technologies},
  title        = {{AI}-assisted synthesis prediction},
  doi          = {10.1016/j.ddtec.2020.06.002},
  issn         = {1740-6749},
  pages        = {65--72},
  series       = {Artificial {Intelligence}},
  url          = {https://www.sciencedirect.com/science/article/pii/S1740674920300020},
  urldate      = {2024-05-01},
  volume       = {32-33},
  abstract     = {Application of AI technologies in synthesis prediction has developed very rapidly in recent years. We attempt here to give a comprehensive summary on the latest advancement on retro-synthesis planning, forward synthesis prediction as well as quantum chemistry-based reaction prediction models. Besides an introduction on the AI/ML models for addressing various synthesis related problems, the sources of the reaction datasets used in model building is also covered. In addition to the predictive models, the robotics based high throughput experimentation technology will be another crucial factor for conducting synthesis in an automated fashion. Some state-of-the-art of high throughput experimentation practices carried out in the pharmaceutical industry are highlighted in this chapter to give the reader a sense of how future chemistry will be conducted to make compounds faster and cheaper.},
  file         = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/abs/pii/S1740674920300020/pdfft?isDTMRedir=true&download=true:application/pdf},
}

 
@Article{Li2015,
  author       = {Li, Bin and Shin, Hyunjin and Gulbekyan, Georgy and Pustovalova, Olga and Nikolsky, Yuri and Hope, Andrew and Bessarabova, Marina and Schu, Matthew and Kolpakova-Hart, Elona and Merberg, David and Dorner, Andrew and Trepicchio, William L.},
  date         = {2015-06},
  journaltitle = {PLoS ONE},
  title        = {Development of a {Drug}-{Response} {Modeling} {Framework} to {Identify} {Cell} {Line} {Derived} {Translational} {Biomarkers} {That} {Can} {Predict} {Treatment} {Outcome} to {Erlotinib} or {Sorafenib}},
  doi          = {10.1371/journal.pone.0130700},
  issn         = {1932-6203},
  number       = {6},
  pages        = {e0130700},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4480971/},
  urldate      = {2024-05-01},
  volume       = {10},
  abstract     = {Development of drug responsive biomarkers from pre-clinical data is a critical step in drug discovery, as it enables patient stratification in clinical trial design. Such translational biomarkers can be validated in early clinical trial phases and utilized as a patient inclusion parameter in later stage trials. Here we present a study on building accurate and selective drug sensitivity models for Erlotinib or Sorafenib from pre-clinical in vitro data, followed by validation of individual models on corresponding treatment arms from patient data generated in the BATTLE clinical trial. A Partial Least Squares Regression (PLSR) based modeling framework was designed and implemented, using a special splitting strategy and canonical pathways to capture robust information for model building. Erlotinib and Sorafenib predictive models could be used to identify a sub-group of patients that respond better to the corresponding treatment, and these models are specific to the corresponding drugs. The model derived signature genes reflect each drug’s known mechanism of action. Also, the models predict each drug’s potential cancer indications consistent with clinical trial results from a selection of globally normalized GEO expression datasets.},
  file         = {PubMed Central Link:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC4480971/:text/html;PubMed Central Full Text PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC4480971/pdf/pone.0130700.pdf:application/pdf},
  pmcid        = {PMC4480971},
  pmid         = {26107615},
}

 
@Article{Breiman2001,
  author       = {Breiman, Leo},
  date         = {2001-10},
  journaltitle = {Machine Learning},
  title        = {Random {Forests}},
  doi          = {10.1023/A:1010933404324},
  issn         = {1573-0565},
  language     = {en},
  number       = {1},
  pages        = {5--32},
  url          = {https://doi.org/10.1023/A:1010933404324},
  urldate      = {2024-05-10},
  volume       = {45},
  abstract     = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  file         = {Full Text PDF:https\://link.springer.com/content/pdf/10.1023%2FA%3A1010933404324.pdf:application/pdf},
  keywords     = {classification, regression, ensemble},
}

 
@Misc{permutation_importance,
  title        = {4.2. {Permutation} feature importance},
  language     = {en},
  url          = {https://scikit-learn/stable/modules/permutation_importance.html},
  urldate      = {2024-05-10},
  abstract     = {Permutation feature importance is a model inspection technique that measures the contribution of each feature to a fitted model’s statistical performance on a given tabular dataset. This technique ...},
  journaltitle = {scikit-learn},
}

 
@Misc{Soman2023,
  author   = {Soman, Aneesha B.},
  date     = {2023-10},
  title    = {Gini {Impurity} vs {Gini} {Importance} vs {Mean} {Decrease} {Impurity}},
  language = {en},
  url      = {https://medium.com/@aneesha161994/gini-impurity-vs-gini-importance-vs-mean-decrease-impurity-51408bdd0cf1},
  urldate  = {2024-05-11},
  abstract = {Gini Impurity},
}

@Misc{Karabiber,
  author  = {Fatih Karabiber},
  title   = {Gini Impurity},
  url     = {https://www.learndatasci.com/glossary/gini-impurity/},
  urldate = {2024-05-11},
}

 
@Article{Freitas2017,
  author       = {Freitas, Renato Ferreira de and Schapira, Matthieu},
  date         = {2017-10},
  journaltitle = {MedChemComm},
  title        = {A systematic analysis of atomic protein–ligand interactions in the {PDB}},
  doi          = {10.1039/C7MD00381A},
  issn         = {2040-2511},
  language     = {en},
  number       = {10},
  pages        = {1970--1981},
  url          = {https://pubs.rsc.org/en/content/articlelanding/2017/md/c7md00381a},
  urldate      = {2024-05-11},
  volume       = {8},
  abstract     = {As the protein databank (PDB) recently passed the cap of 123 456 structures, it stands more than ever as an important resource not only to analyze structural features of specific biological systems, but also to study the prevalence of structural patterns observed in a large body of unrelated structures, that may reflect rules governing protein folding or molecular recognition. Here, we compiled a list of 11 016 unique structures of small-molecule ligands bound to proteins – 6444 of which have experimental binding affinity – representing 750 873 protein–ligand atomic interactions, and analyzed the frequency, geometry and impact of each interaction type. We find that hydrophobic interactions are generally enriched in high-efficiency ligands, but polar interactions are over-represented in fragment inhibitors. While most observations extracted from the PDB will be familiar to seasoned medicinal chemists, less expected findings, such as the high number of C–H⋯O hydrogen bonds or the relatively frequent amide–π stacking between the backbone amide of proteins and aromatic rings of ligands, uncover underused ligand design strategies.},
  file         = {Full Text PDF:https\://pubs.rsc.org/en/content/articlepdf/2017/md/c7md00381a:application/pdf;Supplementary Information PDF:https\://www.rsc.org/suppdata/c7/md/c7md00381a/c7md00381a1.pdf:application/pdf},
  publisher    = {The Royal Society of Chemistry},
}

 
@TechReport{Shlens2014,
  author      = {Shlens, Jonathon},
  date        = {2014-04},
  institution = {arXiv},
  title       = {A {Tutorial} on {Principal} {Component} {Analysis}},
  doi         = {10.48550/arXiv.1404.1100},
  note        = {arXiv:1404.1100 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/1404.1100},
  urldate     = {2024-05-11},
  abstract    = {Principal component analysis (PCA) is a mainstay of modern data analysis - a black box that is widely used but (sometimes) poorly understood. The goal of this paper is to dispel the magic behind this black box. This manuscript focuses on building a solid intuition for how and why principal component analysis works. This manuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind PCA. This tutorial does not shy away from explaining the ideas informally, nor does it shy away from the mathematics. The hope is that by addressing both aspects, readers of all levels will be able to gain a better understanding of PCA as well as the when, the how and the why of applying this technique.},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1404.1100.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

 
@Article{Chawla2002,
  author       = {Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
  date         = {2002-06},
  journaltitle = {Journal of Artificial Intelligence Research},
  title        = {{SMOTE}: {Synthetic} {Minority} {Over}-sampling {Technique}},
  doi          = {10.1613/jair.953},
  issn         = {1076-9757},
  note         = {arXiv:1106.1813 [cs]},
  pages        = {321--357},
  url          = {http://arxiv.org/abs/1106.1813},
  urldate      = {2024-05-11},
  volume       = {16},
  abstract     = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
  file         = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1106.1813.pdf:application/pdf},
  keywords     = {Computer Science - Artificial Intelligence},
  shorttitle   = {{SMOTE}},
}

 
@Article{Cunningham2022,
  author       = {Cunningham, Padraig and Delany, Sarah Jane},
  date         = {2022-07},
  journaltitle = {ACM Computing Surveys},
  title        = {k-{Nearest} {Neighbour} {Classifiers}: 2nd {Edition} (with {Python} examples)},
  doi          = {10.1145/3459665},
  issn         = {0360-0300, 1557-7341},
  note         = {arXiv:2004.04523 [cs, stat]},
  number       = {6},
  pages        = {1--25},
  url          = {http://arxiv.org/abs/2004.04523},
  urldate      = {2024-05-12},
  volume       = {54},
  abstract     = {Perhaps the most straightforward classifier in the arsenal or machine learning techniques is the Nearest Neighbour Classifier -- classification is achieved by identifying the nearest neighbours to a query example and using those neighbours to determine the class of the query. This approach to classification is of particular importance because issues of poor run-time performance is not such a problem these days with the computational power that is available. This paper presents an overview of techniques for Nearest Neighbour classification focusing on; mechanisms for assessing similarity (distance), computational issues in identifying nearest neighbours and mechanisms for reducing the dimension of the data. This paper is the second edition of a paper previously published as a technical report. Sections on similarity measures for time-series, retrieval speed-up and intrinsic dimensionality have been added. An Appendix is included providing access to Python code for the key methods.},
  annotation   = {Comment: 22 pages, 15 figures: An updated edition of an older tutorial on kNN},
  file         = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2004.04523.pdf:application/pdf},
  keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
  shorttitle   = {k-{Nearest} {Neighbour} {Classifiers}},
}

 
@TechReport{Huang2020,
  author      = {Huang, Kexin and Fu, Tianfan and Khan, Dawood and Abid, Ali and Abdalla, Ali and Abid, Abubakar and Glass, Lucas M. and Zitnik, Marinka and Xiao, Cao and Sun, Jimeng},
  date        = {2020-10},
  institution = {arXiv},
  title       = {{MolDesigner}: {Interactive} {Design} of {Efficacious} {Drugs} with {Deep} {Learning}},
  doi         = {10.48550/arXiv.2010.03951},
  note        = {arXiv:2010.03951 [cs, q-bio] type: article},
  url         = {http://arxiv.org/abs/2010.03951},
  urldate     = {2024-05-14},
  abstract    = {The efficacy of a drug depends on its binding affinity to the therapeutic target and pharmacokinetics. Deep learning (DL) has demonstrated remarkable progress in predicting drug efficacy. We develop MolDesigner, a human-in-the-loop web user-interface (UI), to assist drug developers leverage DL predictions to design more effective drugs. A developer can draw a drug molecule in the interface. In the backend, more than 17 state-of-the-art DL models generate predictions on important indices that are crucial for a drug's efficacy. Based on these predictions, drug developers can edit the drug molecule and reiterate until satisfaction. MolDesigner can make predictions in real-time with a latency of less than a second.},
  annotation  = {Comment: NeurIPS 2020 Demonstration Track},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2010.03951.pdf:application/pdf},
  keywords    = {Quantitative Biology - Quantitative Methods, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
  shorttitle  = {{MolDesigner}},
}

 
@TechReport{Mamidala2023,
  author      = {Mamidala, Srilekha},
  date        = {2023-09},
  institution = {arXiv},
  title       = {{NeuroCADR}: {Drug} {Repurposing} to {Reveal} {Novel} {Anti}-{Epileptic} {Drug} {Candidates} {Through} an {Integrated} {Computational} {Approach}},
  doi         = {10.48550/arXiv.2309.13047},
  note        = {arXiv:2309.13047 [cs, q-bio] type: article},
  url         = {http://arxiv.org/abs/2309.13047},
  urldate     = {2024-05-14},
  abstract    = {Drug repurposing is an emerging approach for drug discovery involving the reassignment of existing drugs for novel purposes. An alternative to the traditional de novo process of drug development, repurposed drugs are faster, cheaper, and less failure prone than drugs developed from traditional methods. Recently, drug repurposing has been performed in silico, in which databases of drugs and chemical information are used to determine interactions between target proteins and drug molecules to identify potential drug candidates. A proposed algorithm is NeuroCADR, a novel system for drug repurposing via a multi-pronged approach consisting of k-nearest neighbor algorithms (KNN), random forest classification, and decision trees. Data was sourced from several databases consisting of interactions between diseases, symptoms, genes, and affiliated drug molecules, which were then compiled into datasets expressed in binary. The proposed method displayed a high level of accuracy, outperforming nearly all in silico approaches. NeuroCADR was performed on epilepsy, a condition characterized by seizures, periods of time with bursts of uncontrolled electrical activity in brain cells. Existing drugs for epilepsy can be ineffective and expensive, revealing a need for new antiepileptic drugs. NeuroCADR identified novel drug candidates for epilepsy that can be further approved through clinical trials. The algorithm has the potential to determine possible drug combinations to prescribe a patient based on a patient's prior medical history. This project examines NeuroCADR, a novel approach to computational drug repurposing capable of revealing potential drug candidates in neurological diseases such as epilepsy.},
  annotation  = {Comment: 8 pages, 5 figures},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2309.13047.pdf:application/pdf},
  keywords    = {Quantitative Biology - Biomolecules, Computer Science - Machine Learning, Quantitative Biology - Quantitative Methods},
  shorttitle  = {{NeuroCADR}},
}

 
@TechReport{Abadi2016,
  author      = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  date        = {2016-05},
  institution = {arXiv},
  title       = {{TensorFlow}: {A} system for large-scale machine learning},
  doi         = {10.48550/arXiv.1605.08695},
  note        = {arXiv:1605.08695 [cs] type: article},
  url         = {http://arxiv.org/abs/1605.08695},
  urldate     = {2024-05-14},
  abstract    = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
  annotation  = {Comment: 18 pages, 9 figures; v2 has a spelling correction in the metadata},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1605.08695.pdf:application/pdf},
  keywords    = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Artificial Intelligence},
  shorttitle  = {{TensorFlow}},
}

 
@Article{Schmidhuber2015,
  author       = {Schmidhuber, Juergen},
  date         = {2015-01},
  journaltitle = {Neural Networks},
  title        = {Deep {Learning} in {Neural} {Networks}: {An} {Overview}},
  doi          = {10.1016/j.neunet.2014.09.003},
  issn         = {08936080},
  note         = {arXiv:1404.7828 [cs]},
  pages        = {85--117},
  url          = {http://arxiv.org/abs/1404.7828},
  urldate      = {2024-05-18},
  volume       = {61},
  abstract     = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  annotation   = {Comment: 88 pages, 888 references},
  file         = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1404.7828.pdf:application/pdf},
  keywords     = {Computer Science - Neural and Evolutionary Computing, Computer Science - Machine Learning},
  shorttitle   = {Deep {Learning} in {Neural} {Networks}},
}

 
@Article{McCulloch1943,
  author       = {McCulloch, Warren S. and Pitts, Walter},
  date         = {1943-12},
  journaltitle = {The bulletin of mathematical biophysics},
  title        = {A logical calculus of the ideas immanent in nervous activity},
  doi          = {10.1007/BF02478259},
  issn         = {1522-9602},
  language     = {en},
  number       = {4},
  pages        = {115--133},
  url          = {https://doi.org/10.1007/BF02478259},
  urldate      = {2024-05-18},
  volume       = {5},
  abstract     = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
  file         = {Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2FBF02478259.pdf:application/pdf},
  keywords     = {Nervous Activity, Excitatory Synapse, Inhibitory Synapse, Temporal Summation, Spatial Summation},
}

 
@Book{Archdeacon1994,
  author     = {Archdeacon, Thomas J.},
  date       = {1994},
  title      = {Correlation and regression analysis: a historian's guide},
  isbn       = {9780299136505},
  language   = {eng},
  location   = {Madison, Wis.},
  note       = {OCLC: 27266095},
  publisher  = {University of Wisconsin Press},
  abstract   = {This practical introduction to the use of correlation and regression analysis concentrates on the kinds of analysis that form the broad range of methods used in the social sciences. The text introduces statistical techniques and contains practical examples from scholarly works.},
  keywords   = {Analyse de régression, Canonical correlation (Statistics), Correlation (Statistics), Corrélation (Statistique), Corrélation canonique (Statistique), Geschichte, Geschichtswissenschaft, Histoire Méthodes statistiques, History Statistical methods, Korrelationsanalyse, Regression Analysis, Regression analysis, Regressionsanalyse, Statistik, correlation},
  shorttitle = {Correlation and regression analysis},
}

 
@TechReport{Janocha2017,
  author      = {Janocha, Katarzyna and Czarnecki, Wojciech Marian},
  date        = {2017-02},
  institution = {arXiv},
  title       = {On {Loss} {Functions} for {Deep} {Neural} {Networks} in {Classification}},
  doi         = {10.48550/arXiv.1702.05659},
  note        = {arXiv:1702.05659 [cs] type: article},
  url         = {http://arxiv.org/abs/1702.05659},
  urldate     = {2024-05-18},
  abstract    = {Deep neural networks are currently among the most commonly used classifiers. Despite easily achieving very good performance, one of the best selling points of these models is their modular design - one can conveniently adapt their architecture to specific needs, change connectivity patterns, attach specialised layers, experiment with a large amount of activation functions, normalisation schemes and many others. While one can find impressively wide spread of various configurations of almost every aspect of the deep nets, one element is, in authors' opinion, underrepresented - while solving classification problems, vast majority of papers and applications simply use log loss. In this paper we try to investigate how particular choices of loss functions affect deep models and their learning dynamics, as well as resulting classifiers robustness to various effects. We perform experiments on classical datasets, as well as provide some additional, theoretical insights into the problem. In particular we show that L1 and L2 losses are, quite surprisingly, justified classification objectives for deep nets, by providing probabilistic interpretation in terms of expected misclassification. We also introduce two losses which are not typically used as deep nets objectives and show that they are viable alternatives to the existing ones.},
  annotation  = {Comment: Presented at Theoretical Foundations of Machine Learning 2017 (TFML 2017)},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1702.05659.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning},
}

 
@TechReport{Zhang2019,
  author      = {Zhang, Jiawei},
  date        = {2019-03},
  institution = {arXiv},
  title       = {Gradient {Descent} based {Optimization} {Algorithms} for {Deep} {Learning} {Models} {Training}},
  doi         = {10.48550/arXiv.1903.03614},
  note        = {arXiv:1903.03614 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/1903.03614},
  urldate     = {2024-05-18},
  abstract    = {In this paper, we aim at providing an introduction to the gradient descent based optimization algorithms for learning deep neural network models. Deep learning models involving multiple nonlinear projection layers are very challenging to train. Nowadays, most of the deep learning model training still relies on the back propagation algorithm actually. In back propagation, the model variables will be updated iteratively until convergence with gradient descent based optimization algorithms. Besides the conventional vanilla gradient descent algorithm, many gradient descent variants have also been proposed in recent years to improve the learning performance, including Momentum, Adagrad, Adam, Gadam, etc., which will all be introduced in this paper respectively.},
  annotation  = {Comment: arXiv admin note: text overlap with arXiv:1805.07500},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1903.03614.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
}

 
@Misc{Raschka2024,
  author       = {Raschka, Sebastian},
  date         = {2024-05},
  title        = {How to compute gradients with backpropagation for arbitrary loss and activation functions?},
  language     = {en},
  url          = {https://sebastianraschka.com/faq/docs/backprop-arbitrary.html},
  urldate      = {2024-05-18},
  abstract     = {Backpropagation is basically “just” clever trick to compute gradients in multilayer neural networks efficiently. Or in other words, backprop is about computi...},
  journaltitle = {Sebastian Raschka, PhD},
}

 
@Book{InternationalWorkshoponArtificialNeuralNetworks1995Torremolinos1995,
  author       = {International Workshop on Artificial Neural Networks (1995 : Torremolinos, Spain)},
  date         = {1995},
  title        = {From natural to artificial neural computation : {International} {Workshop} on {Artificial} {Neural} {Networks}, {Malaga}-{Torremolinos}, {Spain}, {June} 7-9, 1995 : proceedings},
  isbn         = {9783540594970 9780387594972},
  language     = {eng},
  publisher    = {Berlin ; New York : Springer-Verlag},
  url          = {http://archive.org/details/fromnaturaltoart1995inte},
  urldate      = {2024-05-18},
  abstract     = {xviii, 1150 pages : 24 cm; Includes bibliographical references and index; Are There Universal Principles of Brain Computation? / S. Grossberg -- Modeling Cortical Networks / L. Menendez de la Prida -- Cooperative Organization of Connectivity Patterns and Receptive Fields in the Visual Pathway: Application to Adaptive Thresholding / J. Mira, A. Manjarres, S. Ros, A.E. Delgado and J.R. Alvarez -- Neurobiological Inspiration for the Architecture and Functioning of Cooperating Neural Networks / F. Alexandre and F. Guyot -- Synaptic Modulation Based Artificial Neural Networks / R.J. Duro, J. Santos and A. Gomez -- Self-Organization of Cortical Receptive Fields and Columnar Structures in a Hebb Trained Neural Network / M. Stetter, M. Kussinger, A. Schels, E. Seeger and E.W. Lang -- An Analytical Solution of the Compartmental Model for Use in Local Learning in Artificial Neural Networks / J. Hoekstra and M. Maouli -- Should ANN be ANGN? / J.G. Wallace and K. Bluff -- Modeling Retinal High and Low Contrast Sensitivity Filters / T. Lourens},
  collaborator = {{Internet Archive}},
  keywords     = {Neural networks (Computer science) -- Congresses},
  shorttitle   = {From natural to artificial neural computation},
}

 
@Article{Zhang2021,
  author       = {Zhang, Xiaoge and Srinivasan, Prabhakar and Mahadevan, Sankaran},
  date         = {2021-06},
  journaltitle = {Safety Science},
  title        = {Sequential {Deep} {Learning} from {NTSB} {Reports} for {Aviation} {Safety} {Prognosis}},
  doi          = {10.1016/j.ssci.2021.105390},
  volume       = {142},
  abstract     = {In this paper, we apply a set of data-mining and sequential deep learning techniques to accident investigation reports published by the National Transportation Safety Board (NTSB) in support of the prognosis of adverse events. Our focus is on learning with text data that describes the sequences of events. NTSB creates post-hoc investigation reports which contain raw text narratives of their investigation and their corresponding concise event sequences. Classification models are developed for passenger air carriers, that take either an observed sequence of events or the corresponding raw text narrative as input and make predictions regarding whether an accident or an incident is the likely outcome, whether the aircraft would be damaged or not and whether any fatalities are likely or not. The classification models are developed using Word Embedding and the Long Short-term Memory (LSTM) neural network. The proposed methodology is implemented in two steps: (i) transform the NTSB data extracts into labeled dataset for building supervised machine learning models; and (ii) develop deep learning (DL) models for performing prognosis of adverse events like accidents, aircraft damage or fatalities. We also develop a prototype for an interactive query interface for end-users to test various scenarios including complete or partial event sequences or narratives and get predictions regarding the adverse events. The development of sequential deep learning models facilitates safety professionals in auditing, reviewing, and analyzing accident investigation reports, performing what-if scenario analyses to quantify the contributions of various hazardous events to the occurrence of aviation accidents/incidents.},
  file         = {Full Text PDF:https\://www.researchgate.net/profile/Xiaoge-Zhang-3/publication/352647580_Sequential_Deep_Learning_from_NTSB_Reports_for_Aviation_Safety_Prognosis/links/60d219a945851566d5837ecb/Sequential-Deep-Learning-from-NTSB-Reports-for-Aviation-Safety-Prognosis.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/352647580_Sequential_Deep_Learning_from_NTSB_Reports_for_Aviation_Safety_Prognosis:},
}

 
@TechReport{Dubey2022,
  author      = {Dubey, Shiv Ram and Singh, Satish Kumar and Chaudhuri, Bidyut Baran},
  date        = {2022-06},
  institution = {arXiv},
  title       = {Activation {Functions} in {Deep} {Learning}: {A} {Comprehensive} {Survey} and {Benchmark}},
  doi         = {10.48550/arXiv.2109.14545},
  note        = {arXiv:2109.14545 [cs] type: article},
  url         = {http://arxiv.org/abs/2109.14545},
  urldate     = {2024-05-18},
  abstract    = {Neural networks have shown tremendous growth in recent years to solve numerous problems. Various types of neural networks have been introduced to deal with different types of problems. However, the main goal of any neural network is to transform the non-linearly separable input data into more linearly separable abstract features using a hierarchy of layers. These layers are combinations of linear and nonlinear functions. The most popular and common non-linearity layers are activation functions (AFs), such as Logistic Sigmoid, Tanh, ReLU, ELU, Swish and Mish. In this paper, a comprehensive overview and survey is presented for AFs in neural networks for deep learning. Different classes of AFs such as Logistic Sigmoid and Tanh based, ReLU based, ELU based, and Learning based are covered. Several characteristics of AFs such as output range, monotonicity, and smoothness are also pointed out. A performance comparison is also performed among 18 state-of-the-art AFs with different networks on different types of data. The insights of AFs are presented to benefit the researchers for doing further research and practitioners to select among different choices. The code used for experimental comparison is released at: {\textbackslash}url\{https://github.com/shivram1987/ActivationFunctions\}.},
  annotation  = {Comment: Accepted in Neurocomputing, Elsevier},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2109.14545.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
  shorttitle  = {Activation {Functions} in {Deep} {Learning}},
}

 
@Article{Zhang2016,
  author       = {Zhang, Na and Zhao, Hongtao},
  date         = {2016-08},
  journaltitle = {Bioorganic \& Medicinal Chemistry Letters},
  title        = {Enriching screening libraries with bioactive fragment space},
  doi          = {10.1016/j.bmcl.2016.06.013},
  issn         = {1464-3405},
  language     = {eng},
  number       = {15},
  pages        = {3594--3597},
  volume       = {26},
  abstract     = {By deconvoluting 238,073 bioactive molecules in the ChEMBL library into extended Murcko ring systems, we identified a set of 2245 ring systems present in at least 10 molecules. These ring systems belong to 2221 clusters by ECFP4 fingerprints with a minimum intracluster similarity of 0.8. Their overlap with ring systems in commercial libraries was further quantified. Our findings suggest that success of a small fragment library is driven by the convergence of effective coverage of bioactive ring systems (e.g., 10\% coverage by 1000 fragments vs. 40\% by 2million HTS compounds), high enrichment of bioactive ring systems, and low molecular complexity enhancing the probability of a match with the protein targets. Reconciling with the previous studies, bioactive ring systems are underrepresented in screening libraries. As such, we propose a library of virtual fragments with key functionalities via fragmentation of bioactive molecules. Its utility is exemplified by a prospective application on protein kinase CK2, resulting in the discovery of a series of novel inhibitors with the most potent compound having an IC50 of 0.5μM and a ligand efficiency of 0.41kcal/mol per heavy atom.},
  file         = {PubMed entry:http\://www.ncbi.nlm.nih.gov/pubmed/27311891:text/html},
  keywords     = {Casein Kinase II, Dose-Response Relationship, Drug, Drug Evaluation, Preclinical, Humans, Molecular Structure, Protein Kinase Inhibitors, Small Molecule Libraries, Structure-Activity Relationship, CK2, Fragment library, Fragment-based drug discovery, Kinase inhibitors},
  pmid         = {27311891},
}

 
@Article{Trott2010,
  author       = {Trott, Oleg and Olson, Arthur J.},
  date         = {2010},
  journaltitle = {Journal of Computational Chemistry},
  title        = {{AutoDock} {Vina}: {Improving} the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading},
  doi          = {10.1002/jcc.21334},
  issn         = {1096-987X},
  language     = {en},
  number       = {2},
  pages        = {455--461},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.21334},
  urldate      = {2024-05-20},
  volume       = {31},
  abstract     = {AutoDock Vina, a new program for molecular docking and virtual screening, is presented. AutoDock Vina achieves an approximately two orders of magnitude speed-up compared with the molecular docking software previously developed in our lab (AutoDock 4), while also significantly improving the accuracy of the binding mode predictions, judging by our tests on the training set used in AutoDock 4 development. Further speed-up is achieved from parallelism, by using multithreading on multicore machines. AutoDock Vina automatically calculates the grid maps and clusters the results in a way transparent to the user. © 2009 Wiley Periodicals, Inc. J Comput Chem 2010},
  copyright    = {Copyright © 2009 Wiley Periodicals, Inc.},
  file         = {Full Text PDF:https\://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jcc.21334:application/pdf},
  keywords     = {AutoDock, molecular docking, virtual screening, computer-aided drug design, multithreading, scoring function},
  shorttitle   = {{AutoDock} {Vina}},
}

 
@InProceedings{Korb2006,
  author     = {Korb, Oliver and Stützle, Thomas and Exner, Thomas E.},
  booktitle  = {Ant {Colony} {Optimization} and {Swarm} {Intelligence}},
  date       = {2006},
  title      = {{PLANTS}: {Application} of {Ant} {Colony} {Optimization} to {Structure}-{Based} {Drug} {Design}},
  doi        = {10.1007/11839088_22},
  editor     = {Dorigo, Marco and Gambardella, Luca Maria and Birattari, Mauro and Martinoli, Alcherio and Poli, Riccardo and Stützle, Thomas},
  isbn       = {9783540384830},
  language   = {en},
  location   = {Berlin, Heidelberg},
  pages      = {247--258},
  publisher  = {Springer},
  abstract   = {A central part of the rational drug development process is the prediction of the complex structure of a small ligand with a protein, the so-called protein-ligand docking problem, used in virtual screening of large databases and lead optimization. In the work presented here, we introduce a new docking algorithm called PLANTS (Protein-Ligand ANTSystem), which is based on ant colony optimization. An artificial ant colony is employed to find a minimum energy conformation of the ligand in the protein’s binding site. We present the effectiveness of PLANTS for several parameter settings as well as a direct comparison to a state-of-the-art program called GOLD, which is based on a genetic algorithm. Last but not least, results for a virtual screening on the protein target factor Xa are presented.},
  file       = {Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2F11839088_22.pdf:application/pdf},
  shorttitle = {{PLANTS}},
}

 
@Article{Morris2009,
  author       = {Morris, Garrett M. and Huey, Ruth and Lindstrom, William and Sanner, Michel F. and Belew, Richard K. and Goodsell, David S. and Olson, Arthur J.},
  date         = {2009-12},
  journaltitle = {Journal of computational chemistry},
  title        = {{AutoDock4} and {AutoDockTools4}: {Automated} {Docking} with {Selective} {Receptor} {Flexibility}},
  doi          = {10.1002/jcc.21256},
  issn         = {0192-8651},
  number       = {16},
  pages        = {2785--2791},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2760638/},
  urldate      = {2024-05-20},
  volume       = {30},
  abstract     = {We describe the testing and release of AutoDock4 and the accompanying graphical user interface AutoDockTools. AutoDock4 incorporates limited flexibility in the receptor. Several tests are reported here, including a redocking experiment with 188 diverse ligand-protein complexes and a cross-docking experiment using flexible sidechains in 87 HIV protease complexes. We also report its utility in analysis of covalently-bound ligands, using both a grid-based docking method and a modification of the flexible sidechain technique.},
  file         = {PubMed Central Link:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC2760638/:text/html;PubMed Central Full Text PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC2760638/pdf/nihms101620.pdf:application/pdf},
  pmcid        = {PMC2760638},
  pmid         = {19399780},
  shorttitle   = {{AutoDock4} and {AutoDockTools4}},
}

 
@Article{RuizCarmona2014,
  author       = {Ruiz-Carmona, Sergio and Alvarez-Garcia, Daniel and Foloppe, Nicolas and Garmendia-Doval, A. Beatriz and Juhos, Szilveszter and Schmidtke, Peter and Barril, Xavier and Hubbard, Roderick E. and Morley, S. David},
  date         = {2014-04},
  journaltitle = {PLoS Computational Biology},
  title        = {{rDock}: {A} {Fast}, {Versatile} and {Open} {Source} {Program} for {Docking} {Ligands} to {Proteins} and {Nucleic} {Acids}},
  doi          = {10.1371/journal.pcbi.1003571},
  issn         = {1553-734X},
  number       = {4},
  pages        = {e1003571},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3983074/},
  urldate      = {2024-05-20},
  volume       = {10},
  abstract     = {Identification of chemical compounds with specific biological activities is an important step in both chemical biology and drug discovery. When the structure of the intended target is available, one approach is to use molecular docking programs to assess the chemical complementarity of small molecules with the target; such calculations provide a qualitative measure of affinity that can be used in virtual screening (VS) to rank order a list of compounds according to their potential to be active. rDock is a molecular docking program developed at Vernalis for high-throughput VS (HTVS) applications. Evolved from RiboDock, the program can be used against proteins and nucleic acids, is designed to be computationally very efficient and allows the user to incorporate additional constraints and information as a bias to guide docking. This article provides an overview of the program structure and features and compares rDock to two reference programs, AutoDock Vina (open source) and Schrödinger's Glide (commercial). In terms of computational speed for VS, rDock is faster than Vina and comparable to Glide. For binding mode prediction, rDock and Vina are superior to Glide. The VS performance of rDock is significantly better than Vina, but inferior to Glide for most systems unless pharmacophore constraints are used; in that case rDock and Glide are of equal performance. The program is released under the Lesser General Public License and is freely available for download, together with the manuals, example files and the complete test sets, at http://rdock.sourceforge.net/},
  file         = {PubMed Central Link:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC3983074/:text/html;PubMed Central Full Text PDF:https\://www.ncbi.nlm.nih.gov/pmc/articles/PMC3983074/pdf/pcbi.1003571.pdf:application/pdf},
  pmcid        = {PMC3983074},
  pmid         = {24722481},
  shorttitle   = {{rDock}},
}

@Comment{jabref-meta: databaseType:biblatex;}
