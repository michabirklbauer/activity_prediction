{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from pyMLaux import plot_history, evaluate_classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/bac/activity_prediction/implementation/'\n",
    "data_dir = base_dir + 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load & prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code needs to be adapted for each protein-ligand complex individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data_raw_mdi = pd.read_csv(data_dir+\"ACHE/ache_mdi.csv\")\n",
    "nn_data_raw_per = pd.read_csv(data_dir+\"ACHE/ache_per.csv\")\n",
    "nn_data_raw = pd.read_csv(data_dir+\"ACHE/ache.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {'inactive':0,'active':1}\n",
    "\n",
    "nn_data_per = {'data': np.array(nn_data_raw_per.iloc[:, 2:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_per.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_per.columns[2:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_mdi = {'data': np.array(nn_data_raw_mdi.iloc[:, 2:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_mdi.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_mdi.columns[2:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_base = {'data': np.array(nn_data_raw.iloc[:, 2:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw.columns[2:-1],\n",
    "             'target_names': ['inactive', 'active']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train- and test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(nn_data_base['data'], nn_data_base['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_mdi, X_test_mdi, y_train_mdi, y_test_mdi = train_test_split(nn_data_mdi['data'], nn_data_mdi['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_per, X_test_per, y_train_per, y_test_per = train_test_split(nn_data_per['data'], nn_data_per['target'],\n",
    "                                                    test_size=0.3, random_state=4232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and apply neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_base['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_base.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_per = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_per['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_per.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_mdi = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_mdi['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_mdi.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 19:19:28.048101: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-09 19:19:28.559640: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fa3f83222b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-09 19:19:28.559685: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-04-09 19:19:28.569982: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-09 19:19:28.593735: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712683168.664373   31051 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 2s - loss: 2.2234 - accuracy: 0.3405 - val_loss: 2.1252 - val_accuracy: 0.4965 - 2s/epoch - 51ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 2.0598 - accuracy: 0.5223 - val_loss: 1.9725 - val_accuracy: 0.5532 - 302ms/epoch - 8ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 1.8848 - accuracy: 0.5633 - val_loss: 1.7988 - val_accuracy: 0.5532 - 282ms/epoch - 8ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 1.7188 - accuracy: 0.5918 - val_loss: 1.6304 - val_accuracy: 0.5532 - 287ms/epoch - 8ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 1.5984 - accuracy: 0.5651 - val_loss: 1.4800 - val_accuracy: 0.5532 - 257ms/epoch - 7ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 1.4264 - accuracy: 0.5882 - val_loss: 1.3046 - val_accuracy: 0.5603 - 253ms/epoch - 7ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 1.2827 - accuracy: 0.6025 - val_loss: 1.0723 - val_accuracy: 0.6099 - 256ms/epoch - 7ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 1.0579 - accuracy: 0.6631 - val_loss: 0.8544 - val_accuracy: 0.6950 - 261ms/epoch - 7ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.8952 - accuracy: 0.6988 - val_loss: 0.7338 - val_accuracy: 0.7376 - 244ms/epoch - 7ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.8185 - accuracy: 0.6684 - val_loss: 0.6776 - val_accuracy: 0.7447 - 258ms/epoch - 7ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.8058 - accuracy: 0.6791 - val_loss: 0.6457 - val_accuracy: 0.7447 - 259ms/epoch - 7ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.7659 - accuracy: 0.6845 - val_loss: 0.6219 - val_accuracy: 0.7305 - 272ms/epoch - 8ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.7424 - accuracy: 0.7005 - val_loss: 0.6042 - val_accuracy: 0.7518 - 254ms/epoch - 7ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.7177 - accuracy: 0.7041 - val_loss: 0.5901 - val_accuracy: 0.7376 - 254ms/epoch - 7ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.6940 - accuracy: 0.7005 - val_loss: 0.5784 - val_accuracy: 0.7518 - 268ms/epoch - 7ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.6622 - accuracy: 0.7148 - val_loss: 0.5674 - val_accuracy: 0.7589 - 293ms/epoch - 8ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.6363 - accuracy: 0.7326 - val_loss: 0.5584 - val_accuracy: 0.7660 - 308ms/epoch - 9ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.6454 - accuracy: 0.7255 - val_loss: 0.5509 - val_accuracy: 0.7660 - 286ms/epoch - 8ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.5825 - accuracy: 0.7576 - val_loss: 0.5450 - val_accuracy: 0.7589 - 300ms/epoch - 8ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.5858 - accuracy: 0.7576 - val_loss: 0.5402 - val_accuracy: 0.7589 - 301ms/epoch - 8ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.6208 - accuracy: 0.7201 - val_loss: 0.5347 - val_accuracy: 0.7660 - 254ms/epoch - 7ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.6207 - accuracy: 0.7237 - val_loss: 0.5318 - val_accuracy: 0.7589 - 263ms/epoch - 7ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.5874 - accuracy: 0.7522 - val_loss: 0.5276 - val_accuracy: 0.7589 - 261ms/epoch - 7ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.6014 - accuracy: 0.7219 - val_loss: 0.5237 - val_accuracy: 0.7589 - 252ms/epoch - 7ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.6154 - accuracy: 0.7308 - val_loss: 0.5243 - val_accuracy: 0.7589 - 240ms/epoch - 7ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.6072 - accuracy: 0.7362 - val_loss: 0.5212 - val_accuracy: 0.7660 - 239ms/epoch - 7ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.5897 - accuracy: 0.7433 - val_loss: 0.5195 - val_accuracy: 0.7660 - 253ms/epoch - 7ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.5385 - accuracy: 0.7718 - val_loss: 0.5148 - val_accuracy: 0.7660 - 243ms/epoch - 7ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.5618 - accuracy: 0.7540 - val_loss: 0.5118 - val_accuracy: 0.7660 - 233ms/epoch - 6ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.5644 - accuracy: 0.7487 - val_loss: 0.5084 - val_accuracy: 0.7518 - 247ms/epoch - 7ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.5717 - accuracy: 0.7362 - val_loss: 0.5067 - val_accuracy: 0.7730 - 245ms/epoch - 7ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.5521 - accuracy: 0.7558 - val_loss: 0.5064 - val_accuracy: 0.7660 - 236ms/epoch - 7ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.5672 - accuracy: 0.7611 - val_loss: 0.5040 - val_accuracy: 0.7730 - 250ms/epoch - 7ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.5370 - accuracy: 0.7701 - val_loss: 0.5025 - val_accuracy: 0.7660 - 248ms/epoch - 7ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.5361 - accuracy: 0.7487 - val_loss: 0.5004 - val_accuracy: 0.7660 - 236ms/epoch - 7ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.5174 - accuracy: 0.7897 - val_loss: 0.4980 - val_accuracy: 0.7730 - 250ms/epoch - 7ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.5779 - accuracy: 0.7308 - val_loss: 0.4961 - val_accuracy: 0.7660 - 253ms/epoch - 7ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.5227 - accuracy: 0.7629 - val_loss: 0.4950 - val_accuracy: 0.7660 - 235ms/epoch - 7ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.5152 - accuracy: 0.7790 - val_loss: 0.4927 - val_accuracy: 0.7660 - 215ms/epoch - 6ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4904 - accuracy: 0.7790 - val_loss: 0.4910 - val_accuracy: 0.7660 - 123ms/epoch - 3ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.5353 - accuracy: 0.7647 - val_loss: 0.4903 - val_accuracy: 0.7660 - 123ms/epoch - 3ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.5223 - accuracy: 0.7665 - val_loss: 0.4894 - val_accuracy: 0.7660 - 119ms/epoch - 3ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.5279 - accuracy: 0.7611 - val_loss: 0.4876 - val_accuracy: 0.7660 - 119ms/epoch - 3ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4938 - accuracy: 0.7843 - val_loss: 0.4872 - val_accuracy: 0.7447 - 122ms/epoch - 3ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.5139 - accuracy: 0.7932 - val_loss: 0.4852 - val_accuracy: 0.7660 - 124ms/epoch - 3ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.5215 - accuracy: 0.7558 - val_loss: 0.4844 - val_accuracy: 0.7660 - 118ms/epoch - 3ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.5208 - accuracy: 0.7879 - val_loss: 0.4831 - val_accuracy: 0.7589 - 127ms/epoch - 4ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.5122 - accuracy: 0.7701 - val_loss: 0.4813 - val_accuracy: 0.7730 - 127ms/epoch - 4ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.5265 - accuracy: 0.7843 - val_loss: 0.4787 - val_accuracy: 0.7660 - 132ms/epoch - 4ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4820 - accuracy: 0.7790 - val_loss: 0.4763 - val_accuracy: 0.7660 - 123ms/epoch - 3ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4615 - accuracy: 0.8111 - val_loss: 0.4748 - val_accuracy: 0.7589 - 152ms/epoch - 4ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4498 - accuracy: 0.8075 - val_loss: 0.4732 - val_accuracy: 0.7589 - 128ms/epoch - 4ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4871 - accuracy: 0.7807 - val_loss: 0.4734 - val_accuracy: 0.7660 - 152ms/epoch - 4ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4910 - accuracy: 0.7754 - val_loss: 0.4708 - val_accuracy: 0.7518 - 240ms/epoch - 7ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4491 - accuracy: 0.7879 - val_loss: 0.4709 - val_accuracy: 0.7518 - 257ms/epoch - 7ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4972 - accuracy: 0.7736 - val_loss: 0.4729 - val_accuracy: 0.7730 - 247ms/epoch - 7ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4752 - accuracy: 0.7736 - val_loss: 0.4706 - val_accuracy: 0.7518 - 245ms/epoch - 7ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4798 - accuracy: 0.7914 - val_loss: 0.4706 - val_accuracy: 0.7447 - 254ms/epoch - 7ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4762 - accuracy: 0.8004 - val_loss: 0.4680 - val_accuracy: 0.7730 - 239ms/epoch - 7ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4437 - accuracy: 0.8004 - val_loss: 0.4678 - val_accuracy: 0.7872 - 242ms/epoch - 7ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4614 - accuracy: 0.7932 - val_loss: 0.4664 - val_accuracy: 0.7660 - 253ms/epoch - 7ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4883 - accuracy: 0.7914 - val_loss: 0.4664 - val_accuracy: 0.7730 - 241ms/epoch - 7ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4584 - accuracy: 0.8075 - val_loss: 0.4670 - val_accuracy: 0.7660 - 248ms/epoch - 7ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4423 - accuracy: 0.7950 - val_loss: 0.4666 - val_accuracy: 0.7730 - 232ms/epoch - 6ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4583 - accuracy: 0.7968 - val_loss: 0.4669 - val_accuracy: 0.7872 - 225ms/epoch - 6ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4469 - accuracy: 0.8021 - val_loss: 0.4654 - val_accuracy: 0.7660 - 232ms/epoch - 6ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4325 - accuracy: 0.8039 - val_loss: 0.4655 - val_accuracy: 0.7660 - 250ms/epoch - 7ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4413 - accuracy: 0.8128 - val_loss: 0.4650 - val_accuracy: 0.7801 - 234ms/epoch - 7ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4452 - accuracy: 0.7914 - val_loss: 0.4655 - val_accuracy: 0.7801 - 230ms/epoch - 6ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4514 - accuracy: 0.8182 - val_loss: 0.4641 - val_accuracy: 0.7660 - 259ms/epoch - 7ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4544 - accuracy: 0.7914 - val_loss: 0.4666 - val_accuracy: 0.7589 - 242ms/epoch - 7ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4310 - accuracy: 0.8164 - val_loss: 0.4651 - val_accuracy: 0.7660 - 241ms/epoch - 7ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4020 - accuracy: 0.8271 - val_loss: 0.4641 - val_accuracy: 0.7589 - 235ms/epoch - 7ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4128 - accuracy: 0.8182 - val_loss: 0.4638 - val_accuracy: 0.7589 - 238ms/epoch - 7ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4329 - accuracy: 0.8057 - val_loss: 0.4628 - val_accuracy: 0.7660 - 229ms/epoch - 6ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4675 - accuracy: 0.7914 - val_loss: 0.4627 - val_accuracy: 0.7660 - 129ms/epoch - 4ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4275 - accuracy: 0.8253 - val_loss: 0.4635 - val_accuracy: 0.7660 - 129ms/epoch - 4ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4238 - accuracy: 0.8396 - val_loss: 0.4625 - val_accuracy: 0.7660 - 147ms/epoch - 4ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4209 - accuracy: 0.8164 - val_loss: 0.4632 - val_accuracy: 0.7660 - 127ms/epoch - 4ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4415 - accuracy: 0.8057 - val_loss: 0.4636 - val_accuracy: 0.7660 - 132ms/epoch - 4ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4308 - accuracy: 0.8217 - val_loss: 0.4642 - val_accuracy: 0.7660 - 157ms/epoch - 4ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4306 - accuracy: 0.8164 - val_loss: 0.4647 - val_accuracy: 0.7660 - 154ms/epoch - 4ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4068 - accuracy: 0.8217 - val_loss: 0.4658 - val_accuracy: 0.7801 - 140ms/epoch - 4ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4316 - accuracy: 0.8057 - val_loss: 0.4661 - val_accuracy: 0.7660 - 128ms/epoch - 4ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4105 - accuracy: 0.8271 - val_loss: 0.4664 - val_accuracy: 0.7660 - 125ms/epoch - 3ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.3886 - accuracy: 0.8396 - val_loss: 0.4651 - val_accuracy: 0.7660 - 130ms/epoch - 4ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4083 - accuracy: 0.8217 - val_loss: 0.4654 - val_accuracy: 0.7730 - 123ms/epoch - 3ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4220 - accuracy: 0.8182 - val_loss: 0.4704 - val_accuracy: 0.7518 - 155ms/epoch - 4ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4146 - accuracy: 0.8307 - val_loss: 0.4696 - val_accuracy: 0.7518 - 293ms/epoch - 8ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4220 - accuracy: 0.8324 - val_loss: 0.4670 - val_accuracy: 0.7589 - 271ms/epoch - 8ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.3722 - accuracy: 0.8467 - val_loss: 0.4680 - val_accuracy: 0.7589 - 247ms/epoch - 7ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4064 - accuracy: 0.8378 - val_loss: 0.4702 - val_accuracy: 0.7447 - 240ms/epoch - 7ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4083 - accuracy: 0.8146 - val_loss: 0.4702 - val_accuracy: 0.7518 - 263ms/epoch - 7ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.3954 - accuracy: 0.8449 - val_loss: 0.4700 - val_accuracy: 0.7589 - 235ms/epoch - 7ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4004 - accuracy: 0.8342 - val_loss: 0.4691 - val_accuracy: 0.7730 - 223ms/epoch - 6ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.3890 - accuracy: 0.8485 - val_loss: 0.4733 - val_accuracy: 0.7376 - 229ms/epoch - 6ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4195 - accuracy: 0.8111 - val_loss: 0.4756 - val_accuracy: 0.7376 - 232ms/epoch - 6ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.4115 - accuracy: 0.8093 - val_loss: 0.4690 - val_accuracy: 0.7589 - 213ms/epoch - 6ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.3646 - accuracy: 0.8538 - val_loss: 0.4723 - val_accuracy: 0.7518 - 222ms/epoch - 6ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.3590 - accuracy: 0.8556 - val_loss: 0.4708 - val_accuracy: 0.7589 - 221ms/epoch - 6ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.4109 - accuracy: 0.8200 - val_loss: 0.4714 - val_accuracy: 0.7518 - 238ms/epoch - 7ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.3881 - accuracy: 0.8235 - val_loss: 0.4707 - val_accuracy: 0.7589 - 265ms/epoch - 7ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.3869 - accuracy: 0.8431 - val_loss: 0.4717 - val_accuracy: 0.7660 - 232ms/epoch - 6ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.3756 - accuracy: 0.8467 - val_loss: 0.4721 - val_accuracy: 0.7589 - 231ms/epoch - 6ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.4030 - accuracy: 0.8307 - val_loss: 0.4726 - val_accuracy: 0.7660 - 239ms/epoch - 7ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3938 - accuracy: 0.8342 - val_loss: 0.4753 - val_accuracy: 0.7447 - 251ms/epoch - 7ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3950 - accuracy: 0.8503 - val_loss: 0.4765 - val_accuracy: 0.7518 - 239ms/epoch - 7ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3739 - accuracy: 0.8396 - val_loss: 0.4755 - val_accuracy: 0.7447 - 217ms/epoch - 6ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3732 - accuracy: 0.8449 - val_loss: 0.4756 - val_accuracy: 0.7589 - 227ms/epoch - 6ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3822 - accuracy: 0.8449 - val_loss: 0.4771 - val_accuracy: 0.7518 - 242ms/epoch - 7ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3308 - accuracy: 0.8770 - val_loss: 0.4785 - val_accuracy: 0.7589 - 270ms/epoch - 8ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3816 - accuracy: 0.8324 - val_loss: 0.4755 - val_accuracy: 0.7589 - 224ms/epoch - 6ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3628 - accuracy: 0.8520 - val_loss: 0.4785 - val_accuracy: 0.7518 - 227ms/epoch - 6ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3858 - accuracy: 0.8378 - val_loss: 0.4775 - val_accuracy: 0.7447 - 219ms/epoch - 6ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3778 - accuracy: 0.8414 - val_loss: 0.4799 - val_accuracy: 0.7518 - 218ms/epoch - 6ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3801 - accuracy: 0.8449 - val_loss: 0.4809 - val_accuracy: 0.7518 - 215ms/epoch - 6ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3441 - accuracy: 0.8610 - val_loss: 0.4850 - val_accuracy: 0.7518 - 212ms/epoch - 6ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3452 - accuracy: 0.8520 - val_loss: 0.4814 - val_accuracy: 0.7447 - 241ms/epoch - 7ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3616 - accuracy: 0.8592 - val_loss: 0.4834 - val_accuracy: 0.7447 - 237ms/epoch - 7ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3756 - accuracy: 0.8610 - val_loss: 0.4853 - val_accuracy: 0.7447 - 269ms/epoch - 7ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3722 - accuracy: 0.8307 - val_loss: 0.4859 - val_accuracy: 0.7376 - 238ms/epoch - 7ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3607 - accuracy: 0.8449 - val_loss: 0.4858 - val_accuracy: 0.7305 - 230ms/epoch - 6ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3447 - accuracy: 0.8663 - val_loss: 0.4824 - val_accuracy: 0.7447 - 127ms/epoch - 4ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3680 - accuracy: 0.8396 - val_loss: 0.4795 - val_accuracy: 0.7518 - 130ms/epoch - 4ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3619 - accuracy: 0.8414 - val_loss: 0.4801 - val_accuracy: 0.7447 - 131ms/epoch - 4ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3530 - accuracy: 0.8538 - val_loss: 0.4810 - val_accuracy: 0.7447 - 127ms/epoch - 4ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3740 - accuracy: 0.8485 - val_loss: 0.4796 - val_accuracy: 0.7518 - 124ms/epoch - 3ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3543 - accuracy: 0.8414 - val_loss: 0.4807 - val_accuracy: 0.7518 - 121ms/epoch - 3ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3704 - accuracy: 0.8360 - val_loss: 0.4813 - val_accuracy: 0.7518 - 136ms/epoch - 4ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3682 - accuracy: 0.8574 - val_loss: 0.4854 - val_accuracy: 0.7447 - 129ms/epoch - 4ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3654 - accuracy: 0.8485 - val_loss: 0.4843 - val_accuracy: 0.7447 - 133ms/epoch - 4ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3286 - accuracy: 0.8538 - val_loss: 0.4847 - val_accuracy: 0.7518 - 129ms/epoch - 4ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3886 - accuracy: 0.8324 - val_loss: 0.4843 - val_accuracy: 0.7589 - 133ms/epoch - 4ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3393 - accuracy: 0.8645 - val_loss: 0.4860 - val_accuracy: 0.7518 - 185ms/epoch - 5ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3408 - accuracy: 0.8663 - val_loss: 0.4891 - val_accuracy: 0.7518 - 159ms/epoch - 4ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3308 - accuracy: 0.8610 - val_loss: 0.4888 - val_accuracy: 0.7447 - 281ms/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3465 - accuracy: 0.8592 - val_loss: 0.4928 - val_accuracy: 0.7376 - 257ms/epoch - 7ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3192 - accuracy: 0.8734 - val_loss: 0.4918 - val_accuracy: 0.7376 - 263ms/epoch - 7ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3458 - accuracy: 0.8485 - val_loss: 0.4856 - val_accuracy: 0.7518 - 241ms/epoch - 7ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3134 - accuracy: 0.8859 - val_loss: 0.4901 - val_accuracy: 0.7447 - 241ms/epoch - 7ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3184 - accuracy: 0.8663 - val_loss: 0.4928 - val_accuracy: 0.7518 - 251ms/epoch - 7ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3510 - accuracy: 0.8485 - val_loss: 0.4933 - val_accuracy: 0.7447 - 242ms/epoch - 7ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3802 - accuracy: 0.8574 - val_loss: 0.4907 - val_accuracy: 0.7447 - 283ms/epoch - 8ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3661 - accuracy: 0.8520 - val_loss: 0.4907 - val_accuracy: 0.7518 - 256ms/epoch - 7ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3461 - accuracy: 0.8467 - val_loss: 0.4912 - val_accuracy: 0.7518 - 252ms/epoch - 7ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3613 - accuracy: 0.8449 - val_loss: 0.4918 - val_accuracy: 0.7447 - 242ms/epoch - 7ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3492 - accuracy: 0.8627 - val_loss: 0.4894 - val_accuracy: 0.7447 - 224ms/epoch - 6ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3215 - accuracy: 0.8681 - val_loss: 0.4934 - val_accuracy: 0.7447 - 329ms/epoch - 9ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3322 - accuracy: 0.8574 - val_loss: 0.4980 - val_accuracy: 0.7447 - 279ms/epoch - 8ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3303 - accuracy: 0.8574 - val_loss: 0.4975 - val_accuracy: 0.7447 - 264ms/epoch - 7ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 2.3095 - accuracy: 0.0695 - val_loss: 2.1436 - val_accuracy: 0.0284 - 865ms/epoch - 24ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 2.0536 - accuracy: 0.1444 - val_loss: 1.8937 - val_accuracy: 0.2837 - 277ms/epoch - 8ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 1.7988 - accuracy: 0.3904 - val_loss: 1.6147 - val_accuracy: 0.5461 - 267ms/epoch - 7ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 1.5201 - accuracy: 0.5544 - val_loss: 1.3125 - val_accuracy: 0.6099 - 284ms/epoch - 8ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 1.2832 - accuracy: 0.5686 - val_loss: 1.0778 - val_accuracy: 0.6383 - 268ms/epoch - 7ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 1.1269 - accuracy: 0.5829 - val_loss: 0.9192 - val_accuracy: 0.6383 - 263ms/epoch - 7ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.9918 - accuracy: 0.6078 - val_loss: 0.8207 - val_accuracy: 0.6525 - 255ms/epoch - 7ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.9067 - accuracy: 0.6132 - val_loss: 0.7493 - val_accuracy: 0.6809 - 239ms/epoch - 7ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.8467 - accuracy: 0.6417 - val_loss: 0.7004 - val_accuracy: 0.7447 - 247ms/epoch - 7ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.8299 - accuracy: 0.5882 - val_loss: 0.6691 - val_accuracy: 0.7305 - 250ms/epoch - 7ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.7665 - accuracy: 0.6292 - val_loss: 0.6419 - val_accuracy: 0.7021 - 311ms/epoch - 9ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.7696 - accuracy: 0.6061 - val_loss: 0.6224 - val_accuracy: 0.7234 - 262ms/epoch - 7ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.7500 - accuracy: 0.6346 - val_loss: 0.6087 - val_accuracy: 0.7163 - 273ms/epoch - 8ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.6970 - accuracy: 0.6506 - val_loss: 0.5945 - val_accuracy: 0.7234 - 305ms/epoch - 8ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.6998 - accuracy: 0.6221 - val_loss: 0.5814 - val_accuracy: 0.7447 - 303ms/epoch - 8ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.6889 - accuracy: 0.6613 - val_loss: 0.5731 - val_accuracy: 0.7447 - 287ms/epoch - 8ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.6850 - accuracy: 0.6684 - val_loss: 0.5654 - val_accuracy: 0.7447 - 288ms/epoch - 8ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.6910 - accuracy: 0.6578 - val_loss: 0.5579 - val_accuracy: 0.7518 - 251ms/epoch - 7ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.6387 - accuracy: 0.6542 - val_loss: 0.5536 - val_accuracy: 0.7447 - 238ms/epoch - 7ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.6420 - accuracy: 0.6809 - val_loss: 0.5491 - val_accuracy: 0.7518 - 264ms/epoch - 7ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.6625 - accuracy: 0.6560 - val_loss: 0.5446 - val_accuracy: 0.7518 - 274ms/epoch - 8ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.6487 - accuracy: 0.6827 - val_loss: 0.5408 - val_accuracy: 0.7447 - 299ms/epoch - 8ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.6357 - accuracy: 0.6934 - val_loss: 0.5383 - val_accuracy: 0.7234 - 293ms/epoch - 8ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.5725 - accuracy: 0.7237 - val_loss: 0.5347 - val_accuracy: 0.7305 - 276ms/epoch - 8ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.6070 - accuracy: 0.7184 - val_loss: 0.5322 - val_accuracy: 0.7376 - 279ms/epoch - 8ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.5950 - accuracy: 0.7201 - val_loss: 0.5292 - val_accuracy: 0.7376 - 238ms/epoch - 7ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.6147 - accuracy: 0.6934 - val_loss: 0.5268 - val_accuracy: 0.7234 - 292ms/epoch - 8ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.5919 - accuracy: 0.6934 - val_loss: 0.5245 - val_accuracy: 0.7234 - 253ms/epoch - 7ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.5813 - accuracy: 0.7201 - val_loss: 0.5208 - val_accuracy: 0.7234 - 270ms/epoch - 8ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.5812 - accuracy: 0.7273 - val_loss: 0.5191 - val_accuracy: 0.7305 - 248ms/epoch - 7ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.5908 - accuracy: 0.7166 - val_loss: 0.5192 - val_accuracy: 0.7376 - 244ms/epoch - 7ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.5887 - accuracy: 0.7148 - val_loss: 0.5166 - val_accuracy: 0.7376 - 225ms/epoch - 6ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.5469 - accuracy: 0.7540 - val_loss: 0.5145 - val_accuracy: 0.7376 - 209ms/epoch - 6ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.5592 - accuracy: 0.7344 - val_loss: 0.5111 - val_accuracy: 0.7447 - 209ms/epoch - 6ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.5535 - accuracy: 0.7504 - val_loss: 0.5108 - val_accuracy: 0.7376 - 217ms/epoch - 6ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.5592 - accuracy: 0.7647 - val_loss: 0.5102 - val_accuracy: 0.7376 - 231ms/epoch - 6ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.5578 - accuracy: 0.7540 - val_loss: 0.5093 - val_accuracy: 0.7447 - 217ms/epoch - 6ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.5211 - accuracy: 0.7522 - val_loss: 0.5092 - val_accuracy: 0.7305 - 216ms/epoch - 6ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.5414 - accuracy: 0.7576 - val_loss: 0.5079 - val_accuracy: 0.7447 - 213ms/epoch - 6ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.5424 - accuracy: 0.7629 - val_loss: 0.5068 - val_accuracy: 0.7376 - 249ms/epoch - 7ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.5448 - accuracy: 0.7558 - val_loss: 0.5046 - val_accuracy: 0.7447 - 252ms/epoch - 7ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.5295 - accuracy: 0.7629 - val_loss: 0.5015 - val_accuracy: 0.7660 - 235ms/epoch - 7ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.5149 - accuracy: 0.7736 - val_loss: 0.5017 - val_accuracy: 0.7518 - 211ms/epoch - 6ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.5566 - accuracy: 0.7540 - val_loss: 0.4999 - val_accuracy: 0.7730 - 119ms/epoch - 3ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.5313 - accuracy: 0.7558 - val_loss: 0.4980 - val_accuracy: 0.7589 - 136ms/epoch - 4ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.5263 - accuracy: 0.7629 - val_loss: 0.4980 - val_accuracy: 0.7730 - 127ms/epoch - 4ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.5366 - accuracy: 0.7647 - val_loss: 0.4978 - val_accuracy: 0.7730 - 124ms/epoch - 3ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4905 - accuracy: 0.7843 - val_loss: 0.4991 - val_accuracy: 0.7589 - 122ms/epoch - 3ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.5347 - accuracy: 0.7718 - val_loss: 0.4975 - val_accuracy: 0.7660 - 118ms/epoch - 3ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.5001 - accuracy: 0.7843 - val_loss: 0.4958 - val_accuracy: 0.7730 - 124ms/epoch - 3ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.5009 - accuracy: 0.7558 - val_loss: 0.4930 - val_accuracy: 0.7801 - 121ms/epoch - 3ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.5017 - accuracy: 0.7861 - val_loss: 0.4929 - val_accuracy: 0.7872 - 123ms/epoch - 3ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4794 - accuracy: 0.8021 - val_loss: 0.4941 - val_accuracy: 0.7730 - 134ms/epoch - 4ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.5127 - accuracy: 0.8004 - val_loss: 0.4937 - val_accuracy: 0.7660 - 147ms/epoch - 4ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4783 - accuracy: 0.7897 - val_loss: 0.4921 - val_accuracy: 0.7943 - 127ms/epoch - 4ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.5116 - accuracy: 0.7754 - val_loss: 0.4920 - val_accuracy: 0.7943 - 124ms/epoch - 3ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.5023 - accuracy: 0.7968 - val_loss: 0.4928 - val_accuracy: 0.7872 - 141ms/epoch - 4ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4846 - accuracy: 0.8111 - val_loss: 0.4914 - val_accuracy: 0.8014 - 225ms/epoch - 6ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4887 - accuracy: 0.7843 - val_loss: 0.4917 - val_accuracy: 0.7730 - 229ms/epoch - 6ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.5105 - accuracy: 0.7772 - val_loss: 0.4908 - val_accuracy: 0.7943 - 232ms/epoch - 6ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4793 - accuracy: 0.7950 - val_loss: 0.4924 - val_accuracy: 0.7801 - 215ms/epoch - 6ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.5129 - accuracy: 0.7897 - val_loss: 0.4888 - val_accuracy: 0.7943 - 226ms/epoch - 6ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.5105 - accuracy: 0.7754 - val_loss: 0.4900 - val_accuracy: 0.7872 - 221ms/epoch - 6ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4860 - accuracy: 0.7932 - val_loss: 0.4909 - val_accuracy: 0.7801 - 240ms/epoch - 7ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4738 - accuracy: 0.8075 - val_loss: 0.4893 - val_accuracy: 0.8014 - 261ms/epoch - 7ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4760 - accuracy: 0.7986 - val_loss: 0.4899 - val_accuracy: 0.8014 - 218ms/epoch - 6ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4969 - accuracy: 0.7825 - val_loss: 0.4906 - val_accuracy: 0.7943 - 236ms/epoch - 7ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4802 - accuracy: 0.8075 - val_loss: 0.4894 - val_accuracy: 0.7943 - 264ms/epoch - 7ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4795 - accuracy: 0.8093 - val_loss: 0.4897 - val_accuracy: 0.7943 - 234ms/epoch - 7ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4938 - accuracy: 0.7914 - val_loss: 0.4885 - val_accuracy: 0.7943 - 217ms/epoch - 6ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4753 - accuracy: 0.8021 - val_loss: 0.4896 - val_accuracy: 0.7943 - 217ms/epoch - 6ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4672 - accuracy: 0.8004 - val_loss: 0.4906 - val_accuracy: 0.7943 - 228ms/epoch - 6ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4911 - accuracy: 0.7914 - val_loss: 0.4910 - val_accuracy: 0.7801 - 231ms/epoch - 6ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4711 - accuracy: 0.8004 - val_loss: 0.4897 - val_accuracy: 0.8014 - 251ms/epoch - 7ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.5001 - accuracy: 0.7825 - val_loss: 0.4887 - val_accuracy: 0.7872 - 215ms/epoch - 6ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4694 - accuracy: 0.8004 - val_loss: 0.4909 - val_accuracy: 0.7943 - 207ms/epoch - 6ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4745 - accuracy: 0.8075 - val_loss: 0.4918 - val_accuracy: 0.7872 - 224ms/epoch - 6ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4730 - accuracy: 0.7825 - val_loss: 0.4914 - val_accuracy: 0.7872 - 231ms/epoch - 6ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4778 - accuracy: 0.7914 - val_loss: 0.4932 - val_accuracy: 0.7801 - 212ms/epoch - 6ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4962 - accuracy: 0.7825 - val_loss: 0.4916 - val_accuracy: 0.7801 - 214ms/epoch - 6ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4751 - accuracy: 0.8182 - val_loss: 0.4906 - val_accuracy: 0.7872 - 211ms/epoch - 6ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4473 - accuracy: 0.8093 - val_loss: 0.4898 - val_accuracy: 0.7943 - 213ms/epoch - 6ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4743 - accuracy: 0.7914 - val_loss: 0.4910 - val_accuracy: 0.7872 - 248ms/epoch - 7ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4755 - accuracy: 0.7968 - val_loss: 0.4898 - val_accuracy: 0.7943 - 214ms/epoch - 6ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4691 - accuracy: 0.8004 - val_loss: 0.4903 - val_accuracy: 0.7943 - 241ms/epoch - 7ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4803 - accuracy: 0.8075 - val_loss: 0.4905 - val_accuracy: 0.7872 - 239ms/epoch - 7ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4767 - accuracy: 0.7897 - val_loss: 0.4915 - val_accuracy: 0.7801 - 231ms/epoch - 6ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4606 - accuracy: 0.8039 - val_loss: 0.4925 - val_accuracy: 0.7730 - 234ms/epoch - 6ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4790 - accuracy: 0.7843 - val_loss: 0.4916 - val_accuracy: 0.7801 - 131ms/epoch - 4ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4596 - accuracy: 0.8164 - val_loss: 0.4917 - val_accuracy: 0.7801 - 125ms/epoch - 3ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4641 - accuracy: 0.8021 - val_loss: 0.4913 - val_accuracy: 0.7801 - 129ms/epoch - 4ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4693 - accuracy: 0.7897 - val_loss: 0.4903 - val_accuracy: 0.7872 - 127ms/epoch - 4ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4397 - accuracy: 0.8146 - val_loss: 0.4924 - val_accuracy: 0.7730 - 133ms/epoch - 4ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.4570 - accuracy: 0.8039 - val_loss: 0.4916 - val_accuracy: 0.7872 - 128ms/epoch - 4ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4703 - accuracy: 0.7914 - val_loss: 0.4925 - val_accuracy: 0.7730 - 144ms/epoch - 4ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.4514 - accuracy: 0.8111 - val_loss: 0.4936 - val_accuracy: 0.7660 - 151ms/epoch - 4ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4695 - accuracy: 0.8039 - val_loss: 0.4916 - val_accuracy: 0.7872 - 117ms/epoch - 3ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.4888 - accuracy: 0.7790 - val_loss: 0.4902 - val_accuracy: 0.7872 - 125ms/epoch - 3ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.4461 - accuracy: 0.8075 - val_loss: 0.4913 - val_accuracy: 0.7801 - 118ms/epoch - 3ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.4662 - accuracy: 0.8004 - val_loss: 0.4897 - val_accuracy: 0.7943 - 171ms/epoch - 5ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.4550 - accuracy: 0.8128 - val_loss: 0.4899 - val_accuracy: 0.7943 - 150ms/epoch - 4ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.4380 - accuracy: 0.8378 - val_loss: 0.4892 - val_accuracy: 0.7943 - 262ms/epoch - 7ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.4358 - accuracy: 0.8146 - val_loss: 0.4911 - val_accuracy: 0.7730 - 248ms/epoch - 7ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.4567 - accuracy: 0.8164 - val_loss: 0.4915 - val_accuracy: 0.7730 - 269ms/epoch - 7ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.4832 - accuracy: 0.7897 - val_loss: 0.4931 - val_accuracy: 0.7660 - 263ms/epoch - 7ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.4615 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7801 - 254ms/epoch - 7ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.4554 - accuracy: 0.7932 - val_loss: 0.4901 - val_accuracy: 0.7730 - 257ms/epoch - 7ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.4526 - accuracy: 0.8182 - val_loss: 0.4883 - val_accuracy: 0.7943 - 238ms/epoch - 7ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.4553 - accuracy: 0.8146 - val_loss: 0.4896 - val_accuracy: 0.7730 - 238ms/epoch - 7ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.4710 - accuracy: 0.8039 - val_loss: 0.4914 - val_accuracy: 0.7730 - 236ms/epoch - 7ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.4807 - accuracy: 0.8004 - val_loss: 0.4880 - val_accuracy: 0.7943 - 223ms/epoch - 6ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.4600 - accuracy: 0.8004 - val_loss: 0.4864 - val_accuracy: 0.7943 - 215ms/epoch - 6ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.4657 - accuracy: 0.8093 - val_loss: 0.4882 - val_accuracy: 0.7801 - 224ms/epoch - 6ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.4202 - accuracy: 0.8217 - val_loss: 0.4889 - val_accuracy: 0.7943 - 225ms/epoch - 6ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.4413 - accuracy: 0.8057 - val_loss: 0.4893 - val_accuracy: 0.7943 - 313ms/epoch - 9ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.4484 - accuracy: 0.8146 - val_loss: 0.4893 - val_accuracy: 0.7801 - 268ms/epoch - 7ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.4417 - accuracy: 0.8057 - val_loss: 0.4873 - val_accuracy: 0.7872 - 247ms/epoch - 7ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.4399 - accuracy: 0.8093 - val_loss: 0.4883 - val_accuracy: 0.7943 - 243ms/epoch - 7ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.4442 - accuracy: 0.7968 - val_loss: 0.4920 - val_accuracy: 0.7660 - 249ms/epoch - 7ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.4592 - accuracy: 0.7914 - val_loss: 0.4913 - val_accuracy: 0.7872 - 238ms/epoch - 7ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.4475 - accuracy: 0.7950 - val_loss: 0.4908 - val_accuracy: 0.7730 - 236ms/epoch - 7ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.4371 - accuracy: 0.8164 - val_loss: 0.4894 - val_accuracy: 0.7801 - 237ms/epoch - 7ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.4577 - accuracy: 0.8004 - val_loss: 0.4901 - val_accuracy: 0.7801 - 251ms/epoch - 7ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.4372 - accuracy: 0.8164 - val_loss: 0.4895 - val_accuracy: 0.7801 - 262ms/epoch - 7ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.4461 - accuracy: 0.8075 - val_loss: 0.4896 - val_accuracy: 0.7872 - 269ms/epoch - 7ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.4471 - accuracy: 0.8164 - val_loss: 0.4930 - val_accuracy: 0.7801 - 272ms/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.4526 - accuracy: 0.8004 - val_loss: 0.4922 - val_accuracy: 0.7730 - 258ms/epoch - 7ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.4374 - accuracy: 0.8164 - val_loss: 0.4920 - val_accuracy: 0.7801 - 238ms/epoch - 7ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.4379 - accuracy: 0.8057 - val_loss: 0.4920 - val_accuracy: 0.7660 - 254ms/epoch - 7ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.4553 - accuracy: 0.8093 - val_loss: 0.4925 - val_accuracy: 0.7589 - 287ms/epoch - 8ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.4394 - accuracy: 0.8235 - val_loss: 0.4944 - val_accuracy: 0.7801 - 277ms/epoch - 8ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.4394 - accuracy: 0.8200 - val_loss: 0.4942 - val_accuracy: 0.7801 - 281ms/epoch - 8ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.4481 - accuracy: 0.8021 - val_loss: 0.4941 - val_accuracy: 0.7801 - 233ms/epoch - 6ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.4522 - accuracy: 0.8182 - val_loss: 0.4940 - val_accuracy: 0.7730 - 222ms/epoch - 6ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.4568 - accuracy: 0.7968 - val_loss: 0.4952 - val_accuracy: 0.7801 - 222ms/epoch - 6ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.4490 - accuracy: 0.8128 - val_loss: 0.4957 - val_accuracy: 0.7801 - 244ms/epoch - 7ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.4209 - accuracy: 0.8342 - val_loss: 0.4924 - val_accuracy: 0.7660 - 236ms/epoch - 7ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.4256 - accuracy: 0.8057 - val_loss: 0.4948 - val_accuracy: 0.7730 - 225ms/epoch - 6ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.4643 - accuracy: 0.7879 - val_loss: 0.4936 - val_accuracy: 0.7730 - 203ms/epoch - 6ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.4259 - accuracy: 0.8182 - val_loss: 0.4940 - val_accuracy: 0.7589 - 268ms/epoch - 7ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.4273 - accuracy: 0.8253 - val_loss: 0.4957 - val_accuracy: 0.7660 - 290ms/epoch - 8ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.4355 - accuracy: 0.8021 - val_loss: 0.4948 - val_accuracy: 0.7660 - 240ms/epoch - 7ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.4698 - accuracy: 0.7950 - val_loss: 0.4935 - val_accuracy: 0.7730 - 248ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.4372 - accuracy: 0.8235 - val_loss: 0.4937 - val_accuracy: 0.7730 - 243ms/epoch - 7ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.4302 - accuracy: 0.8164 - val_loss: 0.4955 - val_accuracy: 0.7801 - 225ms/epoch - 6ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.4520 - accuracy: 0.7932 - val_loss: 0.4978 - val_accuracy: 0.7801 - 218ms/epoch - 6ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.4434 - accuracy: 0.8004 - val_loss: 0.4964 - val_accuracy: 0.7801 - 226ms/epoch - 6ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.4657 - accuracy: 0.7914 - val_loss: 0.4932 - val_accuracy: 0.7660 - 230ms/epoch - 6ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.4386 - accuracy: 0.8289 - val_loss: 0.4941 - val_accuracy: 0.7730 - 239ms/epoch - 7ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.4455 - accuracy: 0.7897 - val_loss: 0.4956 - val_accuracy: 0.7801 - 285ms/epoch - 8ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 2.1950 - accuracy: 0.2406 - val_loss: 2.0138 - val_accuracy: 0.3050 - 755ms/epoch - 21ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 1.9548 - accuracy: 0.4706 - val_loss: 1.8380 - val_accuracy: 0.4610 - 279ms/epoch - 8ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 1.8058 - accuracy: 0.5561 - val_loss: 1.6720 - val_accuracy: 0.5461 - 271ms/epoch - 8ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 1.6900 - accuracy: 0.5472 - val_loss: 1.5223 - val_accuracy: 0.6028 - 246ms/epoch - 7ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 1.5165 - accuracy: 0.5882 - val_loss: 1.3696 - val_accuracy: 0.5887 - 236ms/epoch - 7ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 1.4243 - accuracy: 0.5579 - val_loss: 1.2234 - val_accuracy: 0.5957 - 265ms/epoch - 7ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 1.3036 - accuracy: 0.5865 - val_loss: 1.0958 - val_accuracy: 0.6170 - 250ms/epoch - 7ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 1.2102 - accuracy: 0.5936 - val_loss: 0.9775 - val_accuracy: 0.6383 - 249ms/epoch - 7ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 1.1060 - accuracy: 0.6043 - val_loss: 0.8732 - val_accuracy: 0.6525 - 234ms/epoch - 7ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 1.0657 - accuracy: 0.6292 - val_loss: 0.8102 - val_accuracy: 0.6809 - 251ms/epoch - 7ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.9276 - accuracy: 0.6684 - val_loss: 0.7585 - val_accuracy: 0.6950 - 250ms/epoch - 7ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.9180 - accuracy: 0.6506 - val_loss: 0.7187 - val_accuracy: 0.7021 - 255ms/epoch - 7ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.8927 - accuracy: 0.6578 - val_loss: 0.6903 - val_accuracy: 0.7092 - 242ms/epoch - 7ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.8597 - accuracy: 0.6613 - val_loss: 0.6641 - val_accuracy: 0.6809 - 252ms/epoch - 7ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.8825 - accuracy: 0.6649 - val_loss: 0.6489 - val_accuracy: 0.6879 - 251ms/epoch - 7ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.8596 - accuracy: 0.6578 - val_loss: 0.6317 - val_accuracy: 0.6879 - 249ms/epoch - 7ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.8180 - accuracy: 0.6916 - val_loss: 0.6177 - val_accuracy: 0.6738 - 243ms/epoch - 7ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.7655 - accuracy: 0.6988 - val_loss: 0.6075 - val_accuracy: 0.6879 - 267ms/epoch - 7ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.7211 - accuracy: 0.7005 - val_loss: 0.5998 - val_accuracy: 0.7305 - 278ms/epoch - 8ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.7260 - accuracy: 0.6934 - val_loss: 0.5947 - val_accuracy: 0.7305 - 240ms/epoch - 7ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.6842 - accuracy: 0.7326 - val_loss: 0.5857 - val_accuracy: 0.7234 - 230ms/epoch - 6ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.6706 - accuracy: 0.7291 - val_loss: 0.5769 - val_accuracy: 0.7234 - 256ms/epoch - 7ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.6849 - accuracy: 0.7201 - val_loss: 0.5721 - val_accuracy: 0.7376 - 247ms/epoch - 7ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.6483 - accuracy: 0.7380 - val_loss: 0.5684 - val_accuracy: 0.7234 - 226ms/epoch - 6ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.6185 - accuracy: 0.7558 - val_loss: 0.5630 - val_accuracy: 0.7163 - 224ms/epoch - 6ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.5951 - accuracy: 0.7522 - val_loss: 0.5592 - val_accuracy: 0.7305 - 245ms/epoch - 7ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.6254 - accuracy: 0.7112 - val_loss: 0.5568 - val_accuracy: 0.7305 - 262ms/epoch - 7ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.5949 - accuracy: 0.7398 - val_loss: 0.5531 - val_accuracy: 0.7234 - 248ms/epoch - 7ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.6051 - accuracy: 0.7504 - val_loss: 0.5510 - val_accuracy: 0.7305 - 241ms/epoch - 7ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.5985 - accuracy: 0.7344 - val_loss: 0.5470 - val_accuracy: 0.7234 - 247ms/epoch - 7ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.5905 - accuracy: 0.7380 - val_loss: 0.5439 - val_accuracy: 0.7163 - 242ms/epoch - 7ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.5424 - accuracy: 0.7754 - val_loss: 0.5413 - val_accuracy: 0.7163 - 270ms/epoch - 7ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.5791 - accuracy: 0.7415 - val_loss: 0.5392 - val_accuracy: 0.7163 - 269ms/epoch - 7ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.5635 - accuracy: 0.7451 - val_loss: 0.5371 - val_accuracy: 0.7234 - 251ms/epoch - 7ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.5565 - accuracy: 0.7308 - val_loss: 0.5349 - val_accuracy: 0.7305 - 259ms/epoch - 7ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.5675 - accuracy: 0.7255 - val_loss: 0.5342 - val_accuracy: 0.7305 - 232ms/epoch - 6ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.5355 - accuracy: 0.7611 - val_loss: 0.5327 - val_accuracy: 0.7305 - 243ms/epoch - 7ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.5063 - accuracy: 0.7665 - val_loss: 0.5299 - val_accuracy: 0.7305 - 132ms/epoch - 4ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.5381 - accuracy: 0.7415 - val_loss: 0.5284 - val_accuracy: 0.7305 - 159ms/epoch - 4ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.5313 - accuracy: 0.7540 - val_loss: 0.5270 - val_accuracy: 0.7305 - 131ms/epoch - 4ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.5189 - accuracy: 0.7683 - val_loss: 0.5254 - val_accuracy: 0.7305 - 139ms/epoch - 4ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.5059 - accuracy: 0.7558 - val_loss: 0.5241 - val_accuracy: 0.7376 - 132ms/epoch - 4ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.5198 - accuracy: 0.7665 - val_loss: 0.5226 - val_accuracy: 0.7376 - 160ms/epoch - 4ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.5090 - accuracy: 0.7594 - val_loss: 0.5222 - val_accuracy: 0.7376 - 130ms/epoch - 4ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.5166 - accuracy: 0.7701 - val_loss: 0.5201 - val_accuracy: 0.7234 - 121ms/epoch - 3ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.5055 - accuracy: 0.7790 - val_loss: 0.5194 - val_accuracy: 0.7163 - 155ms/epoch - 4ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.5317 - accuracy: 0.7772 - val_loss: 0.5171 - val_accuracy: 0.7234 - 147ms/epoch - 4ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.5281 - accuracy: 0.7433 - val_loss: 0.5168 - val_accuracy: 0.7376 - 126ms/epoch - 3ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4968 - accuracy: 0.7772 - val_loss: 0.5154 - val_accuracy: 0.7305 - 153ms/epoch - 4ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.5319 - accuracy: 0.7504 - val_loss: 0.5136 - val_accuracy: 0.7305 - 221ms/epoch - 6ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4994 - accuracy: 0.7825 - val_loss: 0.5129 - val_accuracy: 0.7305 - 334ms/epoch - 9ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4779 - accuracy: 0.7932 - val_loss: 0.5122 - val_accuracy: 0.7305 - 332ms/epoch - 9ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4873 - accuracy: 0.7825 - val_loss: 0.5113 - val_accuracy: 0.7305 - 312ms/epoch - 9ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4905 - accuracy: 0.7825 - val_loss: 0.5116 - val_accuracy: 0.7376 - 317ms/epoch - 9ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4999 - accuracy: 0.7914 - val_loss: 0.5117 - val_accuracy: 0.7376 - 251ms/epoch - 7ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4870 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7234 - 246ms/epoch - 7ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4995 - accuracy: 0.7807 - val_loss: 0.5085 - val_accuracy: 0.7447 - 266ms/epoch - 7ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.5037 - accuracy: 0.7772 - val_loss: 0.5079 - val_accuracy: 0.7447 - 254ms/epoch - 7ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4935 - accuracy: 0.7807 - val_loss: 0.5070 - val_accuracy: 0.7518 - 274ms/epoch - 8ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4808 - accuracy: 0.7932 - val_loss: 0.5057 - val_accuracy: 0.7376 - 261ms/epoch - 7ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4731 - accuracy: 0.8057 - val_loss: 0.5050 - val_accuracy: 0.7376 - 237ms/epoch - 7ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4828 - accuracy: 0.7825 - val_loss: 0.5041 - val_accuracy: 0.7518 - 252ms/epoch - 7ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4946 - accuracy: 0.7683 - val_loss: 0.5040 - val_accuracy: 0.7447 - 248ms/epoch - 7ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4808 - accuracy: 0.7843 - val_loss: 0.5040 - val_accuracy: 0.7447 - 256ms/epoch - 7ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4922 - accuracy: 0.7701 - val_loss: 0.5038 - val_accuracy: 0.7447 - 245ms/epoch - 7ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4766 - accuracy: 0.7718 - val_loss: 0.5020 - val_accuracy: 0.7518 - 247ms/epoch - 7ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4798 - accuracy: 0.7843 - val_loss: 0.5009 - val_accuracy: 0.7447 - 265ms/epoch - 7ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4651 - accuracy: 0.7825 - val_loss: 0.5014 - val_accuracy: 0.7376 - 283ms/epoch - 8ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4706 - accuracy: 0.7772 - val_loss: 0.5010 - val_accuracy: 0.7447 - 261ms/epoch - 7ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4545 - accuracy: 0.8021 - val_loss: 0.5006 - val_accuracy: 0.7518 - 283ms/epoch - 8ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4939 - accuracy: 0.7701 - val_loss: 0.5015 - val_accuracy: 0.7447 - 234ms/epoch - 7ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4615 - accuracy: 0.7897 - val_loss: 0.5004 - val_accuracy: 0.7447 - 261ms/epoch - 7ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4660 - accuracy: 0.7897 - val_loss: 0.5006 - val_accuracy: 0.7447 - 259ms/epoch - 7ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4829 - accuracy: 0.7683 - val_loss: 0.5008 - val_accuracy: 0.7447 - 252ms/epoch - 7ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4762 - accuracy: 0.7790 - val_loss: 0.5005 - val_accuracy: 0.7589 - 251ms/epoch - 7ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4561 - accuracy: 0.8021 - val_loss: 0.5006 - val_accuracy: 0.7660 - 231ms/epoch - 6ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4735 - accuracy: 0.7861 - val_loss: 0.4999 - val_accuracy: 0.7589 - 274ms/epoch - 8ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4501 - accuracy: 0.8004 - val_loss: 0.5009 - val_accuracy: 0.7589 - 255ms/epoch - 7ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4529 - accuracy: 0.7825 - val_loss: 0.5010 - val_accuracy: 0.7589 - 244ms/epoch - 7ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4737 - accuracy: 0.7986 - val_loss: 0.5012 - val_accuracy: 0.7518 - 244ms/epoch - 7ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4725 - accuracy: 0.7861 - val_loss: 0.5000 - val_accuracy: 0.7589 - 233ms/epoch - 6ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4798 - accuracy: 0.7861 - val_loss: 0.5001 - val_accuracy: 0.7518 - 235ms/epoch - 7ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4620 - accuracy: 0.7772 - val_loss: 0.5001 - val_accuracy: 0.7518 - 269ms/epoch - 7ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4750 - accuracy: 0.7772 - val_loss: 0.4999 - val_accuracy: 0.7589 - 241ms/epoch - 7ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4636 - accuracy: 0.7879 - val_loss: 0.4990 - val_accuracy: 0.7660 - 262ms/epoch - 7ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4587 - accuracy: 0.7986 - val_loss: 0.4990 - val_accuracy: 0.7801 - 245ms/epoch - 7ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4667 - accuracy: 0.8057 - val_loss: 0.4977 - val_accuracy: 0.7730 - 262ms/epoch - 7ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4687 - accuracy: 0.7897 - val_loss: 0.4990 - val_accuracy: 0.7801 - 234ms/epoch - 7ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4624 - accuracy: 0.7932 - val_loss: 0.4980 - val_accuracy: 0.7660 - 234ms/epoch - 6ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4662 - accuracy: 0.7879 - val_loss: 0.4979 - val_accuracy: 0.7589 - 223ms/epoch - 6ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4777 - accuracy: 0.7843 - val_loss: 0.4979 - val_accuracy: 0.7589 - 245ms/epoch - 7ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4699 - accuracy: 0.7807 - val_loss: 0.4985 - val_accuracy: 0.7660 - 244ms/epoch - 7ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4344 - accuracy: 0.7879 - val_loss: 0.5006 - val_accuracy: 0.7660 - 253ms/epoch - 7ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.4515 - accuracy: 0.7914 - val_loss: 0.4997 - val_accuracy: 0.7589 - 234ms/epoch - 6ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4430 - accuracy: 0.7879 - val_loss: 0.5004 - val_accuracy: 0.7660 - 241ms/epoch - 7ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.4478 - accuracy: 0.8004 - val_loss: 0.4995 - val_accuracy: 0.7660 - 245ms/epoch - 7ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4675 - accuracy: 0.7790 - val_loss: 0.4983 - val_accuracy: 0.7872 - 241ms/epoch - 7ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.4530 - accuracy: 0.7879 - val_loss: 0.5000 - val_accuracy: 0.7589 - 253ms/epoch - 7ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.4373 - accuracy: 0.8004 - val_loss: 0.4992 - val_accuracy: 0.7660 - 261ms/epoch - 7ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.4342 - accuracy: 0.7843 - val_loss: 0.4986 - val_accuracy: 0.7730 - 248ms/epoch - 7ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.4697 - accuracy: 0.7879 - val_loss: 0.4976 - val_accuracy: 0.7730 - 254ms/epoch - 7ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.4365 - accuracy: 0.8075 - val_loss: 0.4974 - val_accuracy: 0.7660 - 244ms/epoch - 7ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.4439 - accuracy: 0.8004 - val_loss: 0.4965 - val_accuracy: 0.7801 - 255ms/epoch - 7ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.4359 - accuracy: 0.8021 - val_loss: 0.4963 - val_accuracy: 0.7872 - 246ms/epoch - 7ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.4440 - accuracy: 0.8004 - val_loss: 0.4977 - val_accuracy: 0.7801 - 237ms/epoch - 7ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.4408 - accuracy: 0.7968 - val_loss: 0.4970 - val_accuracy: 0.7730 - 249ms/epoch - 7ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.4510 - accuracy: 0.8039 - val_loss: 0.4962 - val_accuracy: 0.7872 - 253ms/epoch - 7ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.4293 - accuracy: 0.8021 - val_loss: 0.4961 - val_accuracy: 0.7872 - 249ms/epoch - 7ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.4513 - accuracy: 0.8021 - val_loss: 0.4971 - val_accuracy: 0.7872 - 251ms/epoch - 7ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.4296 - accuracy: 0.8093 - val_loss: 0.4970 - val_accuracy: 0.7872 - 242ms/epoch - 7ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.4270 - accuracy: 0.8093 - val_loss: 0.4981 - val_accuracy: 0.7801 - 252ms/epoch - 7ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.4386 - accuracy: 0.8075 - val_loss: 0.4990 - val_accuracy: 0.7730 - 245ms/epoch - 7ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.4292 - accuracy: 0.8253 - val_loss: 0.4991 - val_accuracy: 0.7660 - 244ms/epoch - 7ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.4579 - accuracy: 0.7825 - val_loss: 0.4983 - val_accuracy: 0.7589 - 230ms/epoch - 6ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.4462 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7660 - 242ms/epoch - 7ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.4385 - accuracy: 0.8004 - val_loss: 0.4986 - val_accuracy: 0.7730 - 232ms/epoch - 6ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.4367 - accuracy: 0.8021 - val_loss: 0.4983 - val_accuracy: 0.7872 - 258ms/epoch - 7ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.4626 - accuracy: 0.7790 - val_loss: 0.4987 - val_accuracy: 0.7872 - 268ms/epoch - 7ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.4193 - accuracy: 0.8111 - val_loss: 0.5005 - val_accuracy: 0.7589 - 276ms/epoch - 8ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.4354 - accuracy: 0.7932 - val_loss: 0.5030 - val_accuracy: 0.7589 - 274ms/epoch - 8ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.4264 - accuracy: 0.8093 - val_loss: 0.4993 - val_accuracy: 0.7660 - 251ms/epoch - 7ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.4300 - accuracy: 0.7968 - val_loss: 0.4989 - val_accuracy: 0.7872 - 282ms/epoch - 8ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.4310 - accuracy: 0.8146 - val_loss: 0.4998 - val_accuracy: 0.7660 - 247ms/epoch - 7ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.4268 - accuracy: 0.8057 - val_loss: 0.4983 - val_accuracy: 0.7730 - 240ms/epoch - 7ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.4339 - accuracy: 0.7968 - val_loss: 0.4992 - val_accuracy: 0.7660 - 263ms/epoch - 7ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.4130 - accuracy: 0.8004 - val_loss: 0.4977 - val_accuracy: 0.7872 - 240ms/epoch - 7ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.4310 - accuracy: 0.8111 - val_loss: 0.5012 - val_accuracy: 0.7660 - 224ms/epoch - 6ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.4444 - accuracy: 0.7807 - val_loss: 0.5020 - val_accuracy: 0.7589 - 131ms/epoch - 4ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.4326 - accuracy: 0.7861 - val_loss: 0.5001 - val_accuracy: 0.7730 - 141ms/epoch - 4ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.4362 - accuracy: 0.8111 - val_loss: 0.5001 - val_accuracy: 0.7801 - 129ms/epoch - 4ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.4235 - accuracy: 0.8021 - val_loss: 0.4999 - val_accuracy: 0.7872 - 139ms/epoch - 4ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.4575 - accuracy: 0.7861 - val_loss: 0.5010 - val_accuracy: 0.7660 - 130ms/epoch - 4ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.4708 - accuracy: 0.7825 - val_loss: 0.4962 - val_accuracy: 0.7589 - 160ms/epoch - 4ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.4343 - accuracy: 0.7843 - val_loss: 0.4969 - val_accuracy: 0.7801 - 139ms/epoch - 4ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.4318 - accuracy: 0.8093 - val_loss: 0.4967 - val_accuracy: 0.7730 - 126ms/epoch - 3ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3960 - accuracy: 0.8235 - val_loss: 0.4991 - val_accuracy: 0.7660 - 173ms/epoch - 5ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.4210 - accuracy: 0.7879 - val_loss: 0.4986 - val_accuracy: 0.7660 - 134ms/epoch - 4ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.4970 - val_accuracy: 0.7660 - 134ms/epoch - 4ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.4343 - accuracy: 0.7843 - val_loss: 0.4976 - val_accuracy: 0.7730 - 140ms/epoch - 4ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.4390 - accuracy: 0.7914 - val_loss: 0.4969 - val_accuracy: 0.7589 - 212ms/epoch - 6ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.4075 - accuracy: 0.8182 - val_loss: 0.4991 - val_accuracy: 0.7660 - 278ms/epoch - 8ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.4228 - accuracy: 0.8146 - val_loss: 0.4982 - val_accuracy: 0.7660 - 264ms/epoch - 7ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.4135 - accuracy: 0.8093 - val_loss: 0.5005 - val_accuracy: 0.7730 - 248ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.4576 - accuracy: 0.7718 - val_loss: 0.4982 - val_accuracy: 0.7801 - 288ms/epoch - 8ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.4036 - accuracy: 0.8093 - val_loss: 0.4970 - val_accuracy: 0.7730 - 242ms/epoch - 7ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.4205 - accuracy: 0.8217 - val_loss: 0.4982 - val_accuracy: 0.7801 - 251ms/epoch - 7ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.4223 - accuracy: 0.8039 - val_loss: 0.4983 - val_accuracy: 0.7660 - 227ms/epoch - 6ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.4245 - accuracy: 0.8057 - val_loss: 0.4995 - val_accuracy: 0.7660 - 232ms/epoch - 6ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.4065 - accuracy: 0.7950 - val_loss: 0.5001 - val_accuracy: 0.7730 - 237ms/epoch - 7ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5003 - val_accuracy: 0.7660 - 217ms/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "history_base = model_base.fit(x=X_train_base, y=y_train_base, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_per = model_per.fit(x=X_train_per, y=y_train_per, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_mdi = model_mdi.fit(x=X_train_mdi, y=y_train_mdi, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Testdata using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "---------Base-Prediction----------\n",
      "[[ 96  41]\n",
      " [ 29 135]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR):  70.073% (96 of 137)\n",
      "    Specificity (TNR):  82.317% (135 of 164)\n",
      "    Precision:          76.800% (96 of 125)\n",
      "    Neg. pred. value:   76.705% (135 of 176)\n",
      "Class active:\n",
      "    Sensitivity (TPR):  82.317% (135 of 164)\n",
      "    Specificity (TNR):  70.073% (96 of 137)\n",
      "    Precision:          76.705% (135 of 176)\n",
      "    Neg. pred. value:   76.800% (96 of 125)\n",
      "\n",
      "Overall accuracy:   76.744% (231 of 301)\n",
      "Balanced accuracy:  76.195%\n",
      "---------Permutation-FeatureSelection-Prediction----------\n",
      "[[ 93  44]\n",
      " [ 30 134]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR):  67.883% (93 of 137)\n",
      "    Specificity (TNR):  81.707% (134 of 164)\n",
      "    Precision:          75.610% (93 of 123)\n",
      "    Neg. pred. value:   75.281% (134 of 178)\n",
      "Class active:\n",
      "    Sensitivity (TPR):  81.707% (134 of 164)\n",
      "    Specificity (TNR):  67.883% (93 of 137)\n",
      "    Precision:          75.281% (134 of 178)\n",
      "    Neg. pred. value:   75.610% (93 of 123)\n",
      "\n",
      "Overall accuracy:   75.415% (227 of 301)\n",
      "Balanced accuracy:  74.795%\n",
      "---------MDI-FeatureSelection-Prediction----------\n",
      "[[ 87  50]\n",
      " [ 30 134]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR):  63.504% (87 of 137)\n",
      "    Specificity (TNR):  81.707% (134 of 164)\n",
      "    Precision:          74.359% (87 of 117)\n",
      "    Neg. pred. value:   72.826% (134 of 184)\n",
      "Class active:\n",
      "    Sensitivity (TPR):  81.707% (134 of 164)\n",
      "    Specificity (TNR):  63.504% (87 of 137)\n",
      "    Precision:          72.826% (134 of 184)\n",
      "    Neg. pred. value:   74.359% (87 of 117)\n",
      "\n",
      "Overall accuracy:   73.422% (221 of 301)\n",
      "Balanced accuracy:  72.605%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 87,  50],\n",
       "       [ 30, 134]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_base = model_base.predict(X_test_base)\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "\n",
    "print(\"---------Base-Prediction----------\")\n",
    "evaluate_classification_result(y_test_base,pred_base,classes=nn_data_base[\"target_names\"])\n",
    "print(\"---------Permutation-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_per,pred_per,classes=nn_data_per[\"target_names\"])\n",
    "print(\"---------MDI-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_mdi,pred_mdi,classes=nn_data_mdi[\"target_names\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activity_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
