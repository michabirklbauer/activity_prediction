{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 20:58:44.700281: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-06 20:58:44.775182: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-06 20:58:44.775229: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-06 20:58:44.776687: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-06 20:58:44.790723: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 20:58:47.282919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from pyMLaux import plot_history, evaluate_classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dynamic path\n",
    "base_dir = Path(os.getcwd()) / \"implementation\"\n",
    "data_dir = base_dir / \"data/source/\"\n",
    "result_dir = base_dir / \"data/results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load & prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code needs to be adapted for each protein-ligand complex individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data_raw_mdi = pd.read_csv(data_dir/\"ACHE/ache_mdi.csv\")\n",
    "nn_data_raw_per = pd.read_csv(data_dir/\"ACHE/ache_per.csv\")\n",
    "nn_data_raw = pd.read_csv(data_dir/\"ACHE/ache.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {'inactive':0,'active':1}\n",
    "\n",
    "nn_data_per = {'data': np.array(nn_data_raw_per.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_per.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_per.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_mdi = {'data': np.array(nn_data_raw_mdi.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_mdi.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_mdi.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_base = {'data': np.array(nn_data_raw.iloc[:, 2:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw.columns[2:-1],\n",
    "             'target_names': ['inactive', 'active']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train- and test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(nn_data_base['data'], nn_data_base['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_mdi, X_test_mdi, y_train_mdi, y_test_mdi = train_test_split(nn_data_mdi['data'], nn_data_mdi['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_per, X_test_per, y_train_per, y_test_per = train_test_split(nn_data_per['data'], nn_data_per['target'],\n",
    "                                                    test_size=0.3, random_state=4232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and apply neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 20:58:51.946604: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.041520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.041647: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.051628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.051903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.051967: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.473770: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.474515: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.479836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-06 20:58:52.480210: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 20:58:52.480287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model_base = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_base['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_base.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_per = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_per['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_per.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_mdi = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_mdi['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_mdi.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 20:58:55.342910: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-06 20:58:57.020475: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f958c8ea7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-06 20:58:57.020697: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-05-06 20:58:57.049484: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-06 20:58:57.150183: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715021937.498027   15962 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 5s - loss: 0.7061 - accuracy: 0.5579 - val_loss: 0.6779 - val_accuracy: 0.5816 - 5s/epoch - 146ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 1s - loss: 0.6641 - accuracy: 0.6168 - val_loss: 0.6533 - val_accuracy: 0.6099 - 621ms/epoch - 17ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 1s - loss: 0.6338 - accuracy: 0.6471 - val_loss: 0.6355 - val_accuracy: 0.6454 - 585ms/epoch - 16ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 1s - loss: 0.6100 - accuracy: 0.6791 - val_loss: 0.6205 - val_accuracy: 0.6383 - 683ms/epoch - 19ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 1s - loss: 0.5902 - accuracy: 0.7077 - val_loss: 0.6081 - val_accuracy: 0.6596 - 707ms/epoch - 20ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 1s - loss: 0.5744 - accuracy: 0.7237 - val_loss: 0.5976 - val_accuracy: 0.6738 - 719ms/epoch - 20ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 1s - loss: 0.5593 - accuracy: 0.7398 - val_loss: 0.5881 - val_accuracy: 0.6809 - 692ms/epoch - 19ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 1s - loss: 0.5463 - accuracy: 0.7683 - val_loss: 0.5794 - val_accuracy: 0.7163 - 650ms/epoch - 18ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 1s - loss: 0.5341 - accuracy: 0.7807 - val_loss: 0.5712 - val_accuracy: 0.7376 - 639ms/epoch - 18ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 1s - loss: 0.5232 - accuracy: 0.7879 - val_loss: 0.5644 - val_accuracy: 0.7447 - 706ms/epoch - 20ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 1s - loss: 0.5135 - accuracy: 0.7879 - val_loss: 0.5585 - val_accuracy: 0.7447 - 700ms/epoch - 19ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 1s - loss: 0.5049 - accuracy: 0.7914 - val_loss: 0.5531 - val_accuracy: 0.7447 - 761ms/epoch - 21ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 1s - loss: 0.4974 - accuracy: 0.7897 - val_loss: 0.5477 - val_accuracy: 0.7589 - 717ms/epoch - 20ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 1s - loss: 0.4908 - accuracy: 0.7879 - val_loss: 0.5432 - val_accuracy: 0.7518 - 723ms/epoch - 20ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 1s - loss: 0.4846 - accuracy: 0.7932 - val_loss: 0.5394 - val_accuracy: 0.7518 - 730ms/epoch - 20ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 1s - loss: 0.4788 - accuracy: 0.7968 - val_loss: 0.5352 - val_accuracy: 0.7730 - 751ms/epoch - 21ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 1s - loss: 0.4736 - accuracy: 0.7932 - val_loss: 0.5313 - val_accuracy: 0.7660 - 687ms/epoch - 19ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 1s - loss: 0.4684 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7730 - 730ms/epoch - 20ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 1s - loss: 0.4633 - accuracy: 0.8057 - val_loss: 0.5245 - val_accuracy: 0.7589 - 761ms/epoch - 21ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 1s - loss: 0.4589 - accuracy: 0.8075 - val_loss: 0.5216 - val_accuracy: 0.7447 - 868ms/epoch - 24ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 1s - loss: 0.4546 - accuracy: 0.8057 - val_loss: 0.5186 - val_accuracy: 0.7730 - 937ms/epoch - 26ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 1s - loss: 0.4506 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7660 - 885ms/epoch - 25ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 1s - loss: 0.4471 - accuracy: 0.8039 - val_loss: 0.5135 - val_accuracy: 0.7660 - 757ms/epoch - 21ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 1s - loss: 0.4435 - accuracy: 0.8057 - val_loss: 0.5110 - val_accuracy: 0.7660 - 670ms/epoch - 19ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 1s - loss: 0.4399 - accuracy: 0.8075 - val_loss: 0.5088 - val_accuracy: 0.7730 - 661ms/epoch - 18ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 1s - loss: 0.4370 - accuracy: 0.8093 - val_loss: 0.5065 - val_accuracy: 0.7730 - 709ms/epoch - 20ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 1s - loss: 0.4342 - accuracy: 0.8146 - val_loss: 0.5044 - val_accuracy: 0.7730 - 737ms/epoch - 20ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 1s - loss: 0.4316 - accuracy: 0.8146 - val_loss: 0.5029 - val_accuracy: 0.7730 - 611ms/epoch - 17ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 1s - loss: 0.4294 - accuracy: 0.8182 - val_loss: 0.5015 - val_accuracy: 0.7730 - 644ms/epoch - 18ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 1s - loss: 0.4262 - accuracy: 0.8164 - val_loss: 0.4995 - val_accuracy: 0.7730 - 692ms/epoch - 19ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 1s - loss: 0.4239 - accuracy: 0.8164 - val_loss: 0.4979 - val_accuracy: 0.7730 - 732ms/epoch - 20ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 1s - loss: 0.4217 - accuracy: 0.8182 - val_loss: 0.4969 - val_accuracy: 0.7730 - 675ms/epoch - 19ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 1s - loss: 0.4199 - accuracy: 0.8253 - val_loss: 0.4966 - val_accuracy: 0.7730 - 733ms/epoch - 20ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 1s - loss: 0.4179 - accuracy: 0.8235 - val_loss: 0.4947 - val_accuracy: 0.7730 - 799ms/epoch - 22ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 1s - loss: 0.4160 - accuracy: 0.8235 - val_loss: 0.4933 - val_accuracy: 0.7730 - 764ms/epoch - 21ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 1s - loss: 0.4140 - accuracy: 0.8235 - val_loss: 0.4917 - val_accuracy: 0.7730 - 671ms/epoch - 19ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 1s - loss: 0.4124 - accuracy: 0.8271 - val_loss: 0.4914 - val_accuracy: 0.7730 - 648ms/epoch - 18ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 1s - loss: 0.4106 - accuracy: 0.8253 - val_loss: 0.4900 - val_accuracy: 0.7730 - 665ms/epoch - 18ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 1s - loss: 0.4089 - accuracy: 0.8324 - val_loss: 0.4883 - val_accuracy: 0.7730 - 621ms/epoch - 17ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4074 - accuracy: 0.8253 - val_loss: 0.4879 - val_accuracy: 0.7730 - 474ms/epoch - 13ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4063 - accuracy: 0.8271 - val_loss: 0.4861 - val_accuracy: 0.7801 - 438ms/epoch - 12ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4050 - accuracy: 0.8289 - val_loss: 0.4847 - val_accuracy: 0.7801 - 403ms/epoch - 11ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4036 - accuracy: 0.8324 - val_loss: 0.4839 - val_accuracy: 0.7801 - 366ms/epoch - 10ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4020 - accuracy: 0.8324 - val_loss: 0.4826 - val_accuracy: 0.7801 - 320ms/epoch - 9ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4009 - accuracy: 0.8289 - val_loss: 0.4817 - val_accuracy: 0.7801 - 326ms/epoch - 9ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.3992 - accuracy: 0.8342 - val_loss: 0.4812 - val_accuracy: 0.7730 - 322ms/epoch - 9ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.3978 - accuracy: 0.8289 - val_loss: 0.4802 - val_accuracy: 0.7730 - 315ms/epoch - 9ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.3969 - accuracy: 0.8271 - val_loss: 0.4791 - val_accuracy: 0.7730 - 318ms/epoch - 9ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 1s - loss: 0.3954 - accuracy: 0.8307 - val_loss: 0.4782 - val_accuracy: 0.7730 - 588ms/epoch - 16ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 1s - loss: 0.3942 - accuracy: 0.8289 - val_loss: 0.4775 - val_accuracy: 0.7730 - 604ms/epoch - 17ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 1s - loss: 0.3931 - accuracy: 0.8289 - val_loss: 0.4769 - val_accuracy: 0.7730 - 812ms/epoch - 23ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 1s - loss: 0.3919 - accuracy: 0.8307 - val_loss: 0.4758 - val_accuracy: 0.7730 - 912ms/epoch - 25ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 1s - loss: 0.3911 - accuracy: 0.8324 - val_loss: 0.4765 - val_accuracy: 0.7730 - 708ms/epoch - 20ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 1s - loss: 0.3902 - accuracy: 0.8307 - val_loss: 0.4754 - val_accuracy: 0.7730 - 641ms/epoch - 18ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 1s - loss: 0.3891 - accuracy: 0.8342 - val_loss: 0.4746 - val_accuracy: 0.7730 - 660ms/epoch - 18ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 1s - loss: 0.3881 - accuracy: 0.8342 - val_loss: 0.4740 - val_accuracy: 0.7730 - 671ms/epoch - 19ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 1s - loss: 0.3871 - accuracy: 0.8378 - val_loss: 0.4736 - val_accuracy: 0.7730 - 594ms/epoch - 16ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 1s - loss: 0.3864 - accuracy: 0.8360 - val_loss: 0.4722 - val_accuracy: 0.7801 - 654ms/epoch - 18ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 1s - loss: 0.3852 - accuracy: 0.8360 - val_loss: 0.4717 - val_accuracy: 0.7730 - 750ms/epoch - 21ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 1s - loss: 0.3842 - accuracy: 0.8360 - val_loss: 0.4715 - val_accuracy: 0.7730 - 613ms/epoch - 17ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 1s - loss: 0.3834 - accuracy: 0.8378 - val_loss: 0.4709 - val_accuracy: 0.7730 - 750ms/epoch - 21ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 1s - loss: 0.3827 - accuracy: 0.8378 - val_loss: 0.4703 - val_accuracy: 0.7730 - 688ms/epoch - 19ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 1s - loss: 0.3818 - accuracy: 0.8360 - val_loss: 0.4703 - val_accuracy: 0.7730 - 804ms/epoch - 22ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 1s - loss: 0.3810 - accuracy: 0.8378 - val_loss: 0.4700 - val_accuracy: 0.7730 - 905ms/epoch - 25ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 1s - loss: 0.3799 - accuracy: 0.8378 - val_loss: 0.4685 - val_accuracy: 0.7730 - 763ms/epoch - 21ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 1s - loss: 0.3796 - accuracy: 0.8378 - val_loss: 0.4681 - val_accuracy: 0.7730 - 725ms/epoch - 20ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 1s - loss: 0.3783 - accuracy: 0.8342 - val_loss: 0.4679 - val_accuracy: 0.7730 - 708ms/epoch - 20ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 1s - loss: 0.3776 - accuracy: 0.8378 - val_loss: 0.4675 - val_accuracy: 0.7730 - 805ms/epoch - 22ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 1s - loss: 0.3768 - accuracy: 0.8378 - val_loss: 0.4672 - val_accuracy: 0.7730 - 614ms/epoch - 17ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 1s - loss: 0.3763 - accuracy: 0.8396 - val_loss: 0.4667 - val_accuracy: 0.7730 - 688ms/epoch - 19ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 1s - loss: 0.3759 - accuracy: 0.8396 - val_loss: 0.4661 - val_accuracy: 0.7801 - 656ms/epoch - 18ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 1s - loss: 0.3745 - accuracy: 0.8431 - val_loss: 0.4655 - val_accuracy: 0.7730 - 663ms/epoch - 18ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 1s - loss: 0.3741 - accuracy: 0.8378 - val_loss: 0.4650 - val_accuracy: 0.7801 - 616ms/epoch - 17ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 1s - loss: 0.3733 - accuracy: 0.8396 - val_loss: 0.4645 - val_accuracy: 0.7730 - 669ms/epoch - 19ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 1s - loss: 0.3726 - accuracy: 0.8431 - val_loss: 0.4635 - val_accuracy: 0.7801 - 739ms/epoch - 21ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 1s - loss: 0.3720 - accuracy: 0.8378 - val_loss: 0.4628 - val_accuracy: 0.7801 - 612ms/epoch - 17ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 1s - loss: 0.3714 - accuracy: 0.8414 - val_loss: 0.4625 - val_accuracy: 0.7801 - 684ms/epoch - 19ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 1s - loss: 0.3711 - accuracy: 0.8414 - val_loss: 0.4623 - val_accuracy: 0.7801 - 647ms/epoch - 18ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 1s - loss: 0.3700 - accuracy: 0.8414 - val_loss: 0.4619 - val_accuracy: 0.7801 - 668ms/epoch - 19ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 1s - loss: 0.3695 - accuracy: 0.8431 - val_loss: 0.4616 - val_accuracy: 0.7801 - 658ms/epoch - 18ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 1s - loss: 0.3688 - accuracy: 0.8396 - val_loss: 0.4610 - val_accuracy: 0.7730 - 685ms/epoch - 19ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 1s - loss: 0.3681 - accuracy: 0.8414 - val_loss: 0.4608 - val_accuracy: 0.7730 - 737ms/epoch - 20ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 1s - loss: 0.3681 - accuracy: 0.8378 - val_loss: 0.4603 - val_accuracy: 0.7801 - 665ms/epoch - 18ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 1s - loss: 0.3671 - accuracy: 0.8378 - val_loss: 0.4603 - val_accuracy: 0.7801 - 713ms/epoch - 20ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 1s - loss: 0.3666 - accuracy: 0.8360 - val_loss: 0.4601 - val_accuracy: 0.7730 - 749ms/epoch - 21ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 1s - loss: 0.3659 - accuracy: 0.8360 - val_loss: 0.4596 - val_accuracy: 0.7801 - 661ms/epoch - 18ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 1s - loss: 0.3654 - accuracy: 0.8396 - val_loss: 0.4591 - val_accuracy: 0.7801 - 701ms/epoch - 19ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 1s - loss: 0.3650 - accuracy: 0.8360 - val_loss: 0.4579 - val_accuracy: 0.7730 - 707ms/epoch - 20ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 1s - loss: 0.3644 - accuracy: 0.8360 - val_loss: 0.4582 - val_accuracy: 0.7730 - 686ms/epoch - 19ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 1s - loss: 0.3639 - accuracy: 0.8396 - val_loss: 0.4575 - val_accuracy: 0.7801 - 687ms/epoch - 19ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 1s - loss: 0.3634 - accuracy: 0.8431 - val_loss: 0.4565 - val_accuracy: 0.7872 - 710ms/epoch - 20ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 1s - loss: 0.3631 - accuracy: 0.8449 - val_loss: 0.4565 - val_accuracy: 0.7801 - 720ms/epoch - 20ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 1s - loss: 0.3623 - accuracy: 0.8431 - val_loss: 0.4565 - val_accuracy: 0.7801 - 759ms/epoch - 21ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 1s - loss: 0.3618 - accuracy: 0.8431 - val_loss: 0.4561 - val_accuracy: 0.7801 - 666ms/epoch - 18ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 1s - loss: 0.3616 - accuracy: 0.8467 - val_loss: 0.4560 - val_accuracy: 0.7872 - 695ms/epoch - 19ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 1s - loss: 0.3609 - accuracy: 0.8431 - val_loss: 0.4558 - val_accuracy: 0.7872 - 680ms/epoch - 19ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 1s - loss: 0.3606 - accuracy: 0.8467 - val_loss: 0.4563 - val_accuracy: 0.7801 - 767ms/epoch - 21ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 1s - loss: 0.3600 - accuracy: 0.8449 - val_loss: 0.4556 - val_accuracy: 0.7872 - 769ms/epoch - 21ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 1s - loss: 0.3597 - accuracy: 0.8503 - val_loss: 0.4555 - val_accuracy: 0.7872 - 706ms/epoch - 20ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 1s - loss: 0.3592 - accuracy: 0.8485 - val_loss: 0.4563 - val_accuracy: 0.7660 - 737ms/epoch - 20ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 1s - loss: 0.3588 - accuracy: 0.8485 - val_loss: 0.4559 - val_accuracy: 0.7660 - 677ms/epoch - 19ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 1s - loss: 0.3582 - accuracy: 0.8485 - val_loss: 0.4557 - val_accuracy: 0.7589 - 715ms/epoch - 20ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 1s - loss: 0.3578 - accuracy: 0.8485 - val_loss: 0.4552 - val_accuracy: 0.7801 - 697ms/epoch - 19ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 1s - loss: 0.3573 - accuracy: 0.8485 - val_loss: 0.4553 - val_accuracy: 0.7730 - 661ms/epoch - 18ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 1s - loss: 0.3569 - accuracy: 0.8467 - val_loss: 0.4552 - val_accuracy: 0.7589 - 789ms/epoch - 22ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 1s - loss: 0.3569 - accuracy: 0.8449 - val_loss: 0.4558 - val_accuracy: 0.7589 - 620ms/epoch - 17ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 1s - loss: 0.3564 - accuracy: 0.8431 - val_loss: 0.4552 - val_accuracy: 0.7660 - 600ms/epoch - 17ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 1s - loss: 0.3558 - accuracy: 0.8449 - val_loss: 0.4547 - val_accuracy: 0.7660 - 551ms/epoch - 15ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 1s - loss: 0.3562 - accuracy: 0.8503 - val_loss: 0.4539 - val_accuracy: 0.7872 - 528ms/epoch - 15ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3550 - accuracy: 0.8503 - val_loss: 0.4544 - val_accuracy: 0.7730 - 493ms/epoch - 14ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3545 - accuracy: 0.8520 - val_loss: 0.4539 - val_accuracy: 0.7872 - 428ms/epoch - 12ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3543 - accuracy: 0.8503 - val_loss: 0.4559 - val_accuracy: 0.7589 - 393ms/epoch - 11ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3540 - accuracy: 0.8520 - val_loss: 0.4547 - val_accuracy: 0.7730 - 397ms/epoch - 11ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3535 - accuracy: 0.8520 - val_loss: 0.4548 - val_accuracy: 0.7730 - 401ms/epoch - 11ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3533 - accuracy: 0.8538 - val_loss: 0.4536 - val_accuracy: 0.7801 - 370ms/epoch - 10ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3529 - accuracy: 0.8503 - val_loss: 0.4539 - val_accuracy: 0.7730 - 407ms/epoch - 11ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 1s - loss: 0.3523 - accuracy: 0.8520 - val_loss: 0.4532 - val_accuracy: 0.7801 - 589ms/epoch - 16ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 1s - loss: 0.3520 - accuracy: 0.8538 - val_loss: 0.4531 - val_accuracy: 0.7801 - 746ms/epoch - 21ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 1s - loss: 0.3516 - accuracy: 0.8538 - val_loss: 0.4536 - val_accuracy: 0.7801 - 745ms/epoch - 21ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 1s - loss: 0.3516 - accuracy: 0.8538 - val_loss: 0.4537 - val_accuracy: 0.7801 - 774ms/epoch - 22ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 1s - loss: 0.3508 - accuracy: 0.8520 - val_loss: 0.4535 - val_accuracy: 0.7801 - 701ms/epoch - 19ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 1s - loss: 0.3506 - accuracy: 0.8538 - val_loss: 0.4535 - val_accuracy: 0.7801 - 689ms/epoch - 19ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 1s - loss: 0.3502 - accuracy: 0.8538 - val_loss: 0.4533 - val_accuracy: 0.7801 - 645ms/epoch - 18ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 1s - loss: 0.3498 - accuracy: 0.8538 - val_loss: 0.4533 - val_accuracy: 0.7801 - 750ms/epoch - 21ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 1s - loss: 0.3497 - accuracy: 0.8520 - val_loss: 0.4528 - val_accuracy: 0.7801 - 737ms/epoch - 20ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 1s - loss: 0.3490 - accuracy: 0.8538 - val_loss: 0.4521 - val_accuracy: 0.7801 - 695ms/epoch - 19ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 1s - loss: 0.3487 - accuracy: 0.8520 - val_loss: 0.4523 - val_accuracy: 0.7801 - 681ms/epoch - 19ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 1s - loss: 0.3487 - accuracy: 0.8520 - val_loss: 0.4518 - val_accuracy: 0.7801 - 762ms/epoch - 21ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 1s - loss: 0.3480 - accuracy: 0.8520 - val_loss: 0.4519 - val_accuracy: 0.7801 - 673ms/epoch - 19ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 1s - loss: 0.3479 - accuracy: 0.8503 - val_loss: 0.4526 - val_accuracy: 0.7801 - 736ms/epoch - 20ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 1s - loss: 0.3476 - accuracy: 0.8449 - val_loss: 0.4536 - val_accuracy: 0.7589 - 769ms/epoch - 21ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 1s - loss: 0.3478 - accuracy: 0.8485 - val_loss: 0.4532 - val_accuracy: 0.7801 - 795ms/epoch - 22ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 1s - loss: 0.3469 - accuracy: 0.8485 - val_loss: 0.4525 - val_accuracy: 0.7801 - 733ms/epoch - 20ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 1s - loss: 0.3468 - accuracy: 0.8556 - val_loss: 0.4515 - val_accuracy: 0.7801 - 913ms/epoch - 25ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 1s - loss: 0.3462 - accuracy: 0.8520 - val_loss: 0.4519 - val_accuracy: 0.7801 - 761ms/epoch - 21ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 1s - loss: 0.3461 - accuracy: 0.8520 - val_loss: 0.4517 - val_accuracy: 0.7801 - 625ms/epoch - 17ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 1s - loss: 0.3456 - accuracy: 0.8556 - val_loss: 0.4513 - val_accuracy: 0.7801 - 683ms/epoch - 19ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 1s - loss: 0.3453 - accuracy: 0.8467 - val_loss: 0.4520 - val_accuracy: 0.7801 - 699ms/epoch - 19ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 1s - loss: 0.3451 - accuracy: 0.8538 - val_loss: 0.4509 - val_accuracy: 0.7801 - 707ms/epoch - 20ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 1s - loss: 0.3447 - accuracy: 0.8556 - val_loss: 0.4508 - val_accuracy: 0.7801 - 697ms/epoch - 19ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 1s - loss: 0.3443 - accuracy: 0.8538 - val_loss: 0.4511 - val_accuracy: 0.7801 - 696ms/epoch - 19ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 1s - loss: 0.3442 - accuracy: 0.8503 - val_loss: 0.4511 - val_accuracy: 0.7801 - 631ms/epoch - 18ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 1s - loss: 0.3440 - accuracy: 0.8520 - val_loss: 0.4507 - val_accuracy: 0.7801 - 742ms/epoch - 21ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 1s - loss: 0.3437 - accuracy: 0.8503 - val_loss: 0.4511 - val_accuracy: 0.7801 - 738ms/epoch - 20ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 1s - loss: 0.3432 - accuracy: 0.8538 - val_loss: 0.4515 - val_accuracy: 0.7801 - 734ms/epoch - 20ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 1s - loss: 0.3429 - accuracy: 0.8520 - val_loss: 0.4516 - val_accuracy: 0.7801 - 722ms/epoch - 20ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 1s - loss: 0.3426 - accuracy: 0.8520 - val_loss: 0.4517 - val_accuracy: 0.7801 - 696ms/epoch - 19ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 1s - loss: 0.3427 - accuracy: 0.8538 - val_loss: 0.4525 - val_accuracy: 0.7801 - 700ms/epoch - 19ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 1s - loss: 0.3420 - accuracy: 0.8520 - val_loss: 0.4521 - val_accuracy: 0.7801 - 717ms/epoch - 20ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 1s - loss: 0.3417 - accuracy: 0.8538 - val_loss: 0.4516 - val_accuracy: 0.7801 - 751ms/epoch - 21ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 3s - loss: 0.7793 - accuracy: 0.5419 - val_loss: 0.7959 - val_accuracy: 0.5319 - 3s/epoch - 86ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 1s - loss: 0.7360 - accuracy: 0.5615 - val_loss: 0.7605 - val_accuracy: 0.5248 - 790ms/epoch - 22ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 1s - loss: 0.7044 - accuracy: 0.5775 - val_loss: 0.7321 - val_accuracy: 0.5461 - 719ms/epoch - 20ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 1s - loss: 0.6781 - accuracy: 0.5971 - val_loss: 0.7111 - val_accuracy: 0.5532 - 747ms/epoch - 21ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 1s - loss: 0.6569 - accuracy: 0.6257 - val_loss: 0.6928 - val_accuracy: 0.5816 - 759ms/epoch - 21ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 1s - loss: 0.6388 - accuracy: 0.6435 - val_loss: 0.6781 - val_accuracy: 0.6170 - 747ms/epoch - 21ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 1s - loss: 0.6230 - accuracy: 0.6613 - val_loss: 0.6651 - val_accuracy: 0.6454 - 816ms/epoch - 23ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 1s - loss: 0.6084 - accuracy: 0.6791 - val_loss: 0.6537 - val_accuracy: 0.6738 - 811ms/epoch - 23ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 1s - loss: 0.5955 - accuracy: 0.6863 - val_loss: 0.6425 - val_accuracy: 0.6950 - 778ms/epoch - 22ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 1s - loss: 0.5837 - accuracy: 0.7112 - val_loss: 0.6319 - val_accuracy: 0.6809 - 732ms/epoch - 20ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 1s - loss: 0.5724 - accuracy: 0.7219 - val_loss: 0.6222 - val_accuracy: 0.6879 - 729ms/epoch - 20ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 1s - loss: 0.5619 - accuracy: 0.7344 - val_loss: 0.6133 - val_accuracy: 0.6738 - 717ms/epoch - 20ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 1s - loss: 0.5518 - accuracy: 0.7594 - val_loss: 0.6052 - val_accuracy: 0.6809 - 803ms/epoch - 22ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 1s - loss: 0.5429 - accuracy: 0.7701 - val_loss: 0.5973 - val_accuracy: 0.6950 - 975ms/epoch - 27ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 1s - loss: 0.5345 - accuracy: 0.7807 - val_loss: 0.5903 - val_accuracy: 0.7021 - 936ms/epoch - 26ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 1s - loss: 0.5269 - accuracy: 0.7914 - val_loss: 0.5837 - val_accuracy: 0.7021 - 650ms/epoch - 18ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 1s - loss: 0.5201 - accuracy: 0.7932 - val_loss: 0.5779 - val_accuracy: 0.7021 - 712ms/epoch - 20ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 1s - loss: 0.5137 - accuracy: 0.7897 - val_loss: 0.5720 - val_accuracy: 0.7092 - 786ms/epoch - 22ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 1s - loss: 0.5076 - accuracy: 0.7897 - val_loss: 0.5669 - val_accuracy: 0.7092 - 661ms/epoch - 18ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 1s - loss: 0.5017 - accuracy: 0.7914 - val_loss: 0.5619 - val_accuracy: 0.7092 - 602ms/epoch - 17ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 1s - loss: 0.4967 - accuracy: 0.7986 - val_loss: 0.5573 - val_accuracy: 0.7305 - 689ms/epoch - 19ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 1s - loss: 0.4917 - accuracy: 0.8021 - val_loss: 0.5535 - val_accuracy: 0.7376 - 675ms/epoch - 19ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 1s - loss: 0.4872 - accuracy: 0.8021 - val_loss: 0.5495 - val_accuracy: 0.7376 - 562ms/epoch - 16ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4830 - accuracy: 0.8021 - val_loss: 0.5449 - val_accuracy: 0.7234 - 473ms/epoch - 13ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4792 - accuracy: 0.8004 - val_loss: 0.5413 - val_accuracy: 0.7376 - 410ms/epoch - 11ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4754 - accuracy: 0.8075 - val_loss: 0.5380 - val_accuracy: 0.7376 - 393ms/epoch - 11ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4717 - accuracy: 0.8021 - val_loss: 0.5345 - val_accuracy: 0.7376 - 377ms/epoch - 10ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4683 - accuracy: 0.8111 - val_loss: 0.5317 - val_accuracy: 0.7376 - 346ms/epoch - 10ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4651 - accuracy: 0.8111 - val_loss: 0.5283 - val_accuracy: 0.7376 - 357ms/epoch - 10ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4620 - accuracy: 0.8093 - val_loss: 0.5257 - val_accuracy: 0.7376 - 290ms/epoch - 8ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4593 - accuracy: 0.8093 - val_loss: 0.5230 - val_accuracy: 0.7376 - 313ms/epoch - 9ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4564 - accuracy: 0.8093 - val_loss: 0.5205 - val_accuracy: 0.7376 - 291ms/epoch - 8ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4541 - accuracy: 0.8075 - val_loss: 0.5184 - val_accuracy: 0.7376 - 319ms/epoch - 9ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4519 - accuracy: 0.8128 - val_loss: 0.5163 - val_accuracy: 0.7376 - 346ms/epoch - 10ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4496 - accuracy: 0.8111 - val_loss: 0.5143 - val_accuracy: 0.7447 - 323ms/epoch - 9ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4470 - accuracy: 0.8128 - val_loss: 0.5120 - val_accuracy: 0.7447 - 304ms/epoch - 8ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4452 - accuracy: 0.8075 - val_loss: 0.5101 - val_accuracy: 0.7447 - 297ms/epoch - 8ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4429 - accuracy: 0.8075 - val_loss: 0.5084 - val_accuracy: 0.7518 - 301ms/epoch - 8ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4411 - accuracy: 0.8111 - val_loss: 0.5069 - val_accuracy: 0.7518 - 332ms/epoch - 9ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4392 - accuracy: 0.8146 - val_loss: 0.5054 - val_accuracy: 0.7518 - 321ms/epoch - 9ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4374 - accuracy: 0.8146 - val_loss: 0.5040 - val_accuracy: 0.7518 - 304ms/epoch - 8ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4361 - accuracy: 0.8146 - val_loss: 0.5028 - val_accuracy: 0.7518 - 297ms/epoch - 8ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4348 - accuracy: 0.8164 - val_loss: 0.5023 - val_accuracy: 0.7518 - 290ms/epoch - 8ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4332 - accuracy: 0.8164 - val_loss: 0.5009 - val_accuracy: 0.7518 - 295ms/epoch - 8ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4319 - accuracy: 0.8164 - val_loss: 0.4999 - val_accuracy: 0.7518 - 290ms/epoch - 8ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4304 - accuracy: 0.8128 - val_loss: 0.4992 - val_accuracy: 0.7518 - 295ms/epoch - 8ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4295 - accuracy: 0.8217 - val_loss: 0.4976 - val_accuracy: 0.7518 - 289ms/epoch - 8ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4277 - accuracy: 0.8164 - val_loss: 0.4966 - val_accuracy: 0.7518 - 293ms/epoch - 8ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4265 - accuracy: 0.8128 - val_loss: 0.4958 - val_accuracy: 0.7518 - 310ms/epoch - 9ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4256 - accuracy: 0.8128 - val_loss: 0.4947 - val_accuracy: 0.7518 - 285ms/epoch - 8ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4242 - accuracy: 0.8146 - val_loss: 0.4935 - val_accuracy: 0.7660 - 309ms/epoch - 9ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4231 - accuracy: 0.8146 - val_loss: 0.4927 - val_accuracy: 0.7660 - 288ms/epoch - 8ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4221 - accuracy: 0.8164 - val_loss: 0.4917 - val_accuracy: 0.7660 - 317ms/epoch - 9ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4210 - accuracy: 0.8217 - val_loss: 0.4905 - val_accuracy: 0.7660 - 294ms/epoch - 8ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4200 - accuracy: 0.8217 - val_loss: 0.4898 - val_accuracy: 0.7660 - 305ms/epoch - 8ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4191 - accuracy: 0.8235 - val_loss: 0.4891 - val_accuracy: 0.7660 - 279ms/epoch - 8ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4183 - accuracy: 0.8235 - val_loss: 0.4887 - val_accuracy: 0.7660 - 290ms/epoch - 8ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4172 - accuracy: 0.8271 - val_loss: 0.4872 - val_accuracy: 0.7660 - 285ms/epoch - 8ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4170 - accuracy: 0.8235 - val_loss: 0.4879 - val_accuracy: 0.7589 - 284ms/epoch - 8ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4161 - accuracy: 0.8217 - val_loss: 0.4874 - val_accuracy: 0.7589 - 295ms/epoch - 8ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4152 - accuracy: 0.8217 - val_loss: 0.4863 - val_accuracy: 0.7660 - 315ms/epoch - 9ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4146 - accuracy: 0.8182 - val_loss: 0.4861 - val_accuracy: 0.7660 - 296ms/epoch - 8ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4136 - accuracy: 0.8217 - val_loss: 0.4857 - val_accuracy: 0.7660 - 291ms/epoch - 8ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4128 - accuracy: 0.8235 - val_loss: 0.4854 - val_accuracy: 0.7660 - 292ms/epoch - 8ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4123 - accuracy: 0.8253 - val_loss: 0.4849 - val_accuracy: 0.7660 - 320ms/epoch - 9ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4115 - accuracy: 0.8253 - val_loss: 0.4846 - val_accuracy: 0.7660 - 288ms/epoch - 8ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4112 - accuracy: 0.8235 - val_loss: 0.4833 - val_accuracy: 0.7730 - 292ms/epoch - 8ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4104 - accuracy: 0.8235 - val_loss: 0.4830 - val_accuracy: 0.7730 - 321ms/epoch - 9ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4097 - accuracy: 0.8271 - val_loss: 0.4823 - val_accuracy: 0.7730 - 308ms/epoch - 9ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4092 - accuracy: 0.8271 - val_loss: 0.4822 - val_accuracy: 0.7730 - 288ms/epoch - 8ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4087 - accuracy: 0.8289 - val_loss: 0.4820 - val_accuracy: 0.7660 - 294ms/epoch - 8ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4080 - accuracy: 0.8271 - val_loss: 0.4820 - val_accuracy: 0.7660 - 291ms/epoch - 8ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4075 - accuracy: 0.8271 - val_loss: 0.4807 - val_accuracy: 0.7730 - 312ms/epoch - 9ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4071 - accuracy: 0.8271 - val_loss: 0.4806 - val_accuracy: 0.7660 - 299ms/epoch - 8ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4064 - accuracy: 0.8271 - val_loss: 0.4806 - val_accuracy: 0.7660 - 301ms/epoch - 8ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4060 - accuracy: 0.8271 - val_loss: 0.4802 - val_accuracy: 0.7660 - 298ms/epoch - 8ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4055 - accuracy: 0.8271 - val_loss: 0.4790 - val_accuracy: 0.7660 - 274ms/epoch - 8ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4050 - accuracy: 0.8289 - val_loss: 0.4791 - val_accuracy: 0.7660 - 303ms/epoch - 8ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4046 - accuracy: 0.8289 - val_loss: 0.4788 - val_accuracy: 0.7660 - 286ms/epoch - 8ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4042 - accuracy: 0.8307 - val_loss: 0.4784 - val_accuracy: 0.7660 - 269ms/epoch - 7ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4036 - accuracy: 0.8307 - val_loss: 0.4787 - val_accuracy: 0.7660 - 276ms/epoch - 8ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4040 - accuracy: 0.8324 - val_loss: 0.4790 - val_accuracy: 0.7589 - 259ms/epoch - 7ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4032 - accuracy: 0.8307 - val_loss: 0.4787 - val_accuracy: 0.7589 - 307ms/epoch - 9ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4028 - accuracy: 0.8324 - val_loss: 0.4782 - val_accuracy: 0.7660 - 295ms/epoch - 8ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4023 - accuracy: 0.8324 - val_loss: 0.4784 - val_accuracy: 0.7660 - 273ms/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4023 - accuracy: 0.8324 - val_loss: 0.4791 - val_accuracy: 0.7589 - 278ms/epoch - 8ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4017 - accuracy: 0.8307 - val_loss: 0.4789 - val_accuracy: 0.7589 - 284ms/epoch - 8ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4014 - accuracy: 0.8324 - val_loss: 0.4793 - val_accuracy: 0.7589 - 280ms/epoch - 8ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4011 - accuracy: 0.8342 - val_loss: 0.4784 - val_accuracy: 0.7589 - 278ms/epoch - 8ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4005 - accuracy: 0.8378 - val_loss: 0.4780 - val_accuracy: 0.7660 - 296ms/epoch - 8ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4000 - accuracy: 0.8396 - val_loss: 0.4779 - val_accuracy: 0.7660 - 305ms/epoch - 8ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.3999 - accuracy: 0.8378 - val_loss: 0.4777 - val_accuracy: 0.7660 - 277ms/epoch - 8ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.3995 - accuracy: 0.8396 - val_loss: 0.4778 - val_accuracy: 0.7660 - 270ms/epoch - 8ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.3992 - accuracy: 0.8396 - val_loss: 0.4776 - val_accuracy: 0.7660 - 274ms/epoch - 8ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.3990 - accuracy: 0.8378 - val_loss: 0.4775 - val_accuracy: 0.7660 - 259ms/epoch - 7ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.3987 - accuracy: 0.8396 - val_loss: 0.4770 - val_accuracy: 0.7730 - 274ms/epoch - 8ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.3983 - accuracy: 0.8396 - val_loss: 0.4769 - val_accuracy: 0.7730 - 269ms/epoch - 7ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.3980 - accuracy: 0.8396 - val_loss: 0.4768 - val_accuracy: 0.7730 - 285ms/epoch - 8ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.3977 - accuracy: 0.8396 - val_loss: 0.4769 - val_accuracy: 0.7660 - 275ms/epoch - 8ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.3977 - accuracy: 0.8396 - val_loss: 0.4773 - val_accuracy: 0.7518 - 272ms/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.3973 - accuracy: 0.8360 - val_loss: 0.4779 - val_accuracy: 0.7518 - 275ms/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.3978 - accuracy: 0.8360 - val_loss: 0.4792 - val_accuracy: 0.7589 - 286ms/epoch - 8ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.3970 - accuracy: 0.8342 - val_loss: 0.4782 - val_accuracy: 0.7518 - 287ms/epoch - 8ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8360 - val_loss: 0.4776 - val_accuracy: 0.7589 - 290ms/epoch - 8ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3965 - accuracy: 0.8360 - val_loss: 0.4776 - val_accuracy: 0.7589 - 286ms/epoch - 8ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8360 - val_loss: 0.4778 - val_accuracy: 0.7518 - 291ms/epoch - 8ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3959 - accuracy: 0.8360 - val_loss: 0.4773 - val_accuracy: 0.7660 - 318ms/epoch - 9ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3959 - accuracy: 0.8342 - val_loss: 0.4774 - val_accuracy: 0.7518 - 297ms/epoch - 8ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3955 - accuracy: 0.8396 - val_loss: 0.4766 - val_accuracy: 0.7660 - 301ms/epoch - 8ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3951 - accuracy: 0.8396 - val_loss: 0.4767 - val_accuracy: 0.7660 - 323ms/epoch - 9ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3951 - accuracy: 0.8378 - val_loss: 0.4765 - val_accuracy: 0.7660 - 314ms/epoch - 9ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8378 - val_loss: 0.4768 - val_accuracy: 0.7660 - 321ms/epoch - 9ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3946 - accuracy: 0.8342 - val_loss: 0.4770 - val_accuracy: 0.7589 - 291ms/epoch - 8ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3945 - accuracy: 0.8342 - val_loss: 0.4773 - val_accuracy: 0.7589 - 284ms/epoch - 8ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3947 - accuracy: 0.8324 - val_loss: 0.4780 - val_accuracy: 0.7589 - 326ms/epoch - 9ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3943 - accuracy: 0.8342 - val_loss: 0.4774 - val_accuracy: 0.7589 - 311ms/epoch - 9ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3939 - accuracy: 0.8324 - val_loss: 0.4770 - val_accuracy: 0.7589 - 292ms/epoch - 8ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3937 - accuracy: 0.8342 - val_loss: 0.4769 - val_accuracy: 0.7589 - 334ms/epoch - 9ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3940 - accuracy: 0.8324 - val_loss: 0.4769 - val_accuracy: 0.7589 - 289ms/epoch - 8ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3935 - accuracy: 0.8342 - val_loss: 0.4764 - val_accuracy: 0.7518 - 316ms/epoch - 9ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3932 - accuracy: 0.8342 - val_loss: 0.4761 - val_accuracy: 0.7518 - 299ms/epoch - 8ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3932 - accuracy: 0.8360 - val_loss: 0.4758 - val_accuracy: 0.7518 - 301ms/epoch - 8ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3930 - accuracy: 0.8396 - val_loss: 0.4767 - val_accuracy: 0.7589 - 291ms/epoch - 8ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3931 - accuracy: 0.8378 - val_loss: 0.4767 - val_accuracy: 0.7518 - 309ms/epoch - 9ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3929 - accuracy: 0.8378 - val_loss: 0.4766 - val_accuracy: 0.7589 - 288ms/epoch - 8ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3926 - accuracy: 0.8342 - val_loss: 0.4773 - val_accuracy: 0.7518 - 294ms/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3923 - accuracy: 0.8360 - val_loss: 0.4775 - val_accuracy: 0.7518 - 303ms/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3923 - accuracy: 0.8360 - val_loss: 0.4775 - val_accuracy: 0.7518 - 290ms/epoch - 8ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3919 - accuracy: 0.8342 - val_loss: 0.4776 - val_accuracy: 0.7518 - 279ms/epoch - 8ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3921 - accuracy: 0.8342 - val_loss: 0.4775 - val_accuracy: 0.7518 - 301ms/epoch - 8ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3916 - accuracy: 0.8342 - val_loss: 0.4780 - val_accuracy: 0.7518 - 305ms/epoch - 8ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3915 - accuracy: 0.8342 - val_loss: 0.4783 - val_accuracy: 0.7518 - 329ms/epoch - 9ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3916 - accuracy: 0.8324 - val_loss: 0.4773 - val_accuracy: 0.7518 - 328ms/epoch - 9ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3912 - accuracy: 0.8324 - val_loss: 0.4777 - val_accuracy: 0.7518 - 324ms/epoch - 9ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3910 - accuracy: 0.8324 - val_loss: 0.4775 - val_accuracy: 0.7518 - 295ms/epoch - 8ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3909 - accuracy: 0.8324 - val_loss: 0.4773 - val_accuracy: 0.7518 - 292ms/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3908 - accuracy: 0.8360 - val_loss: 0.4774 - val_accuracy: 0.7518 - 288ms/epoch - 8ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3913 - accuracy: 0.8378 - val_loss: 0.4779 - val_accuracy: 0.7518 - 297ms/epoch - 8ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3907 - accuracy: 0.8360 - val_loss: 0.4766 - val_accuracy: 0.7518 - 306ms/epoch - 8ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3907 - accuracy: 0.8360 - val_loss: 0.4773 - val_accuracy: 0.7518 - 318ms/epoch - 9ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3904 - accuracy: 0.8396 - val_loss: 0.4776 - val_accuracy: 0.7518 - 296ms/epoch - 8ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3902 - accuracy: 0.8342 - val_loss: 0.4774 - val_accuracy: 0.7518 - 318ms/epoch - 9ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3902 - accuracy: 0.8378 - val_loss: 0.4776 - val_accuracy: 0.7518 - 316ms/epoch - 9ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3899 - accuracy: 0.8360 - val_loss: 0.4769 - val_accuracy: 0.7518 - 294ms/epoch - 8ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3900 - accuracy: 0.8360 - val_loss: 0.4771 - val_accuracy: 0.7589 - 289ms/epoch - 8ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3904 - accuracy: 0.8378 - val_loss: 0.4784 - val_accuracy: 0.7589 - 305ms/epoch - 8ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3898 - accuracy: 0.8360 - val_loss: 0.4773 - val_accuracy: 0.7518 - 284ms/epoch - 8ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3896 - accuracy: 0.8360 - val_loss: 0.4766 - val_accuracy: 0.7518 - 299ms/epoch - 8ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3895 - accuracy: 0.8396 - val_loss: 0.4769 - val_accuracy: 0.7518 - 306ms/epoch - 8ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8396 - val_loss: 0.4769 - val_accuracy: 0.7518 - 296ms/epoch - 8ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 0.9267 - accuracy: 0.5686 - val_loss: 0.9190 - val_accuracy: 0.5390 - 699ms/epoch - 19ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.8517 - accuracy: 0.5561 - val_loss: 0.8499 - val_accuracy: 0.5390 - 324ms/epoch - 9ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.7913 - accuracy: 0.5401 - val_loss: 0.7995 - val_accuracy: 0.5319 - 302ms/epoch - 8ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.7507 - accuracy: 0.5508 - val_loss: 0.7660 - val_accuracy: 0.5461 - 305ms/epoch - 8ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.7174 - accuracy: 0.5615 - val_loss: 0.7359 - val_accuracy: 0.5745 - 305ms/epoch - 8ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.6931 - accuracy: 0.5758 - val_loss: 0.7118 - val_accuracy: 0.5816 - 311ms/epoch - 9ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.6712 - accuracy: 0.5918 - val_loss: 0.6972 - val_accuracy: 0.6170 - 325ms/epoch - 9ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.6537 - accuracy: 0.6114 - val_loss: 0.6822 - val_accuracy: 0.6525 - 282ms/epoch - 8ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.6372 - accuracy: 0.6381 - val_loss: 0.6684 - val_accuracy: 0.6454 - 282ms/epoch - 8ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.6231 - accuracy: 0.6560 - val_loss: 0.6574 - val_accuracy: 0.6596 - 303ms/epoch - 8ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.6104 - accuracy: 0.6845 - val_loss: 0.6476 - val_accuracy: 0.6738 - 305ms/epoch - 8ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5984 - accuracy: 0.7023 - val_loss: 0.6368 - val_accuracy: 0.6879 - 285ms/epoch - 8ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5877 - accuracy: 0.7130 - val_loss: 0.6279 - val_accuracy: 0.6950 - 302ms/epoch - 8ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5778 - accuracy: 0.7184 - val_loss: 0.6205 - val_accuracy: 0.6879 - 289ms/epoch - 8ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5684 - accuracy: 0.7273 - val_loss: 0.6121 - val_accuracy: 0.6667 - 292ms/epoch - 8ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.5601 - accuracy: 0.7362 - val_loss: 0.6055 - val_accuracy: 0.6667 - 286ms/epoch - 8ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.5520 - accuracy: 0.7487 - val_loss: 0.5983 - val_accuracy: 0.6667 - 275ms/epoch - 8ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.5445 - accuracy: 0.7504 - val_loss: 0.5924 - val_accuracy: 0.6738 - 280ms/epoch - 8ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.5377 - accuracy: 0.7469 - val_loss: 0.5869 - val_accuracy: 0.6809 - 317ms/epoch - 9ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.5314 - accuracy: 0.7522 - val_loss: 0.5816 - val_accuracy: 0.6809 - 269ms/epoch - 7ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.5253 - accuracy: 0.7504 - val_loss: 0.5763 - val_accuracy: 0.6809 - 282ms/epoch - 8ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.5193 - accuracy: 0.7629 - val_loss: 0.5710 - val_accuracy: 0.6950 - 294ms/epoch - 8ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.5150 - accuracy: 0.7629 - val_loss: 0.5671 - val_accuracy: 0.6879 - 312ms/epoch - 9ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.5107 - accuracy: 0.7576 - val_loss: 0.5631 - val_accuracy: 0.7021 - 334ms/epoch - 9ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.5059 - accuracy: 0.7629 - val_loss: 0.5592 - val_accuracy: 0.7021 - 309ms/epoch - 9ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.5016 - accuracy: 0.7665 - val_loss: 0.5558 - val_accuracy: 0.7021 - 300ms/epoch - 8ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4978 - accuracy: 0.7647 - val_loss: 0.5526 - val_accuracy: 0.7021 - 296ms/epoch - 8ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4936 - accuracy: 0.7736 - val_loss: 0.5490 - val_accuracy: 0.7092 - 304ms/epoch - 8ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4900 - accuracy: 0.7754 - val_loss: 0.5461 - val_accuracy: 0.7092 - 280ms/epoch - 8ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4864 - accuracy: 0.7754 - val_loss: 0.5434 - val_accuracy: 0.7163 - 310ms/epoch - 9ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4834 - accuracy: 0.7772 - val_loss: 0.5413 - val_accuracy: 0.7234 - 287ms/epoch - 8ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4803 - accuracy: 0.7790 - val_loss: 0.5386 - val_accuracy: 0.7234 - 289ms/epoch - 8ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4775 - accuracy: 0.7807 - val_loss: 0.5362 - val_accuracy: 0.7234 - 309ms/epoch - 9ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4750 - accuracy: 0.7843 - val_loss: 0.5337 - val_accuracy: 0.7234 - 290ms/epoch - 8ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4716 - accuracy: 0.7879 - val_loss: 0.5312 - val_accuracy: 0.7234 - 297ms/epoch - 8ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4692 - accuracy: 0.7879 - val_loss: 0.5289 - val_accuracy: 0.7234 - 299ms/epoch - 8ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4670 - accuracy: 0.7861 - val_loss: 0.5266 - val_accuracy: 0.7234 - 317ms/epoch - 9ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4646 - accuracy: 0.7879 - val_loss: 0.5247 - val_accuracy: 0.7234 - 299ms/epoch - 8ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4624 - accuracy: 0.7861 - val_loss: 0.5229 - val_accuracy: 0.7234 - 289ms/epoch - 8ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4602 - accuracy: 0.7879 - val_loss: 0.5211 - val_accuracy: 0.7376 - 333ms/epoch - 9ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4579 - accuracy: 0.7879 - val_loss: 0.5198 - val_accuracy: 0.7376 - 307ms/epoch - 9ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4559 - accuracy: 0.7843 - val_loss: 0.5181 - val_accuracy: 0.7518 - 314ms/epoch - 9ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4541 - accuracy: 0.7932 - val_loss: 0.5160 - val_accuracy: 0.7518 - 295ms/epoch - 8ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4521 - accuracy: 0.7897 - val_loss: 0.5145 - val_accuracy: 0.7518 - 297ms/epoch - 8ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4504 - accuracy: 0.7914 - val_loss: 0.5123 - val_accuracy: 0.7447 - 281ms/epoch - 8ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4490 - accuracy: 0.7897 - val_loss: 0.5108 - val_accuracy: 0.7518 - 286ms/epoch - 8ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4474 - accuracy: 0.7950 - val_loss: 0.5091 - val_accuracy: 0.7518 - 295ms/epoch - 8ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4456 - accuracy: 0.7932 - val_loss: 0.5079 - val_accuracy: 0.7518 - 271ms/epoch - 8ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4440 - accuracy: 0.7968 - val_loss: 0.5069 - val_accuracy: 0.7660 - 319ms/epoch - 9ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4427 - accuracy: 0.7968 - val_loss: 0.5057 - val_accuracy: 0.7589 - 291ms/epoch - 8ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4411 - accuracy: 0.7968 - val_loss: 0.5041 - val_accuracy: 0.7660 - 270ms/epoch - 8ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4398 - accuracy: 0.8004 - val_loss: 0.5030 - val_accuracy: 0.7730 - 261ms/epoch - 7ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4388 - accuracy: 0.8004 - val_loss: 0.5023 - val_accuracy: 0.7589 - 295ms/epoch - 8ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4373 - accuracy: 0.8039 - val_loss: 0.5010 - val_accuracy: 0.7589 - 287ms/epoch - 8ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4360 - accuracy: 0.8021 - val_loss: 0.5003 - val_accuracy: 0.7589 - 278ms/epoch - 8ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4350 - accuracy: 0.8039 - val_loss: 0.4989 - val_accuracy: 0.7730 - 286ms/epoch - 8ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4335 - accuracy: 0.8004 - val_loss: 0.4983 - val_accuracy: 0.7660 - 285ms/epoch - 8ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4326 - accuracy: 0.8075 - val_loss: 0.4976 - val_accuracy: 0.7660 - 280ms/epoch - 8ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4316 - accuracy: 0.8057 - val_loss: 0.4968 - val_accuracy: 0.7660 - 280ms/epoch - 8ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4304 - accuracy: 0.8039 - val_loss: 0.4958 - val_accuracy: 0.7589 - 303ms/epoch - 8ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4295 - accuracy: 0.8057 - val_loss: 0.4953 - val_accuracy: 0.7660 - 275ms/epoch - 8ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4287 - accuracy: 0.8057 - val_loss: 0.4943 - val_accuracy: 0.7518 - 280ms/epoch - 8ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4275 - accuracy: 0.8057 - val_loss: 0.4935 - val_accuracy: 0.7589 - 310ms/epoch - 9ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4267 - accuracy: 0.8075 - val_loss: 0.4927 - val_accuracy: 0.7660 - 303ms/epoch - 8ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4259 - accuracy: 0.8075 - val_loss: 0.4921 - val_accuracy: 0.7660 - 306ms/epoch - 9ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4249 - accuracy: 0.8075 - val_loss: 0.4916 - val_accuracy: 0.7660 - 330ms/epoch - 9ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4241 - accuracy: 0.8093 - val_loss: 0.4909 - val_accuracy: 0.7660 - 340ms/epoch - 9ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4231 - accuracy: 0.8057 - val_loss: 0.4904 - val_accuracy: 0.7660 - 347ms/epoch - 10ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4225 - accuracy: 0.8111 - val_loss: 0.4904 - val_accuracy: 0.7660 - 337ms/epoch - 9ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4219 - accuracy: 0.8093 - val_loss: 0.4912 - val_accuracy: 0.7660 - 383ms/epoch - 11ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4211 - accuracy: 0.8057 - val_loss: 0.4897 - val_accuracy: 0.7660 - 355ms/epoch - 10ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4201 - accuracy: 0.8093 - val_loss: 0.4892 - val_accuracy: 0.7660 - 312ms/epoch - 9ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4194 - accuracy: 0.8111 - val_loss: 0.4884 - val_accuracy: 0.7660 - 344ms/epoch - 10ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4187 - accuracy: 0.8111 - val_loss: 0.4878 - val_accuracy: 0.7660 - 339ms/epoch - 9ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4181 - accuracy: 0.8111 - val_loss: 0.4879 - val_accuracy: 0.7660 - 314ms/epoch - 9ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4172 - accuracy: 0.8111 - val_loss: 0.4863 - val_accuracy: 0.7589 - 317ms/epoch - 9ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4170 - accuracy: 0.8093 - val_loss: 0.4863 - val_accuracy: 0.7589 - 303ms/epoch - 8ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4162 - accuracy: 0.8075 - val_loss: 0.4855 - val_accuracy: 0.7518 - 323ms/epoch - 9ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4157 - accuracy: 0.8057 - val_loss: 0.4851 - val_accuracy: 0.7589 - 308ms/epoch - 9ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4150 - accuracy: 0.8057 - val_loss: 0.4846 - val_accuracy: 0.7589 - 311ms/epoch - 9ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4143 - accuracy: 0.8093 - val_loss: 0.4842 - val_accuracy: 0.7589 - 271ms/epoch - 8ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4140 - accuracy: 0.8075 - val_loss: 0.4837 - val_accuracy: 0.7589 - 294ms/epoch - 8ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4134 - accuracy: 0.8128 - val_loss: 0.4830 - val_accuracy: 0.7518 - 311ms/epoch - 9ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4132 - accuracy: 0.8128 - val_loss: 0.4827 - val_accuracy: 0.7518 - 278ms/epoch - 8ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4122 - accuracy: 0.8128 - val_loss: 0.4822 - val_accuracy: 0.7518 - 288ms/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4120 - accuracy: 0.8093 - val_loss: 0.4824 - val_accuracy: 0.7518 - 325ms/epoch - 9ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4110 - accuracy: 0.8235 - val_loss: 0.4804 - val_accuracy: 0.7518 - 289ms/epoch - 8ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4107 - accuracy: 0.8128 - val_loss: 0.4804 - val_accuracy: 0.7518 - 274ms/epoch - 8ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4101 - accuracy: 0.8182 - val_loss: 0.4802 - val_accuracy: 0.7518 - 271ms/epoch - 8ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4098 - accuracy: 0.8200 - val_loss: 0.4796 - val_accuracy: 0.7518 - 311ms/epoch - 9ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4096 - accuracy: 0.8200 - val_loss: 0.4793 - val_accuracy: 0.7518 - 289ms/epoch - 8ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4090 - accuracy: 0.8200 - val_loss: 0.4792 - val_accuracy: 0.7518 - 277ms/epoch - 8ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4088 - accuracy: 0.8200 - val_loss: 0.4785 - val_accuracy: 0.7518 - 274ms/epoch - 8ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.4081 - accuracy: 0.8235 - val_loss: 0.4785 - val_accuracy: 0.7518 - 267ms/epoch - 7ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4077 - accuracy: 0.8200 - val_loss: 0.4794 - val_accuracy: 0.7447 - 293ms/epoch - 8ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.4080 - accuracy: 0.8164 - val_loss: 0.4803 - val_accuracy: 0.7589 - 302ms/epoch - 8ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4071 - accuracy: 0.8200 - val_loss: 0.4790 - val_accuracy: 0.7518 - 307ms/epoch - 9ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.4066 - accuracy: 0.8235 - val_loss: 0.4785 - val_accuracy: 0.7518 - 277ms/epoch - 8ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.4063 - accuracy: 0.8235 - val_loss: 0.4786 - val_accuracy: 0.7518 - 280ms/epoch - 8ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.4063 - accuracy: 0.8235 - val_loss: 0.4788 - val_accuracy: 0.7447 - 285ms/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.4057 - accuracy: 0.8217 - val_loss: 0.4786 - val_accuracy: 0.7518 - 270ms/epoch - 7ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.4053 - accuracy: 0.8217 - val_loss: 0.4784 - val_accuracy: 0.7447 - 276ms/epoch - 8ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.4049 - accuracy: 0.8235 - val_loss: 0.4787 - val_accuracy: 0.7447 - 295ms/epoch - 8ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.4045 - accuracy: 0.8217 - val_loss: 0.4788 - val_accuracy: 0.7376 - 270ms/epoch - 7ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.4041 - accuracy: 0.8253 - val_loss: 0.4785 - val_accuracy: 0.7447 - 309ms/epoch - 9ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.4038 - accuracy: 0.8235 - val_loss: 0.4787 - val_accuracy: 0.7376 - 282ms/epoch - 8ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.4035 - accuracy: 0.8253 - val_loss: 0.4773 - val_accuracy: 0.7518 - 316ms/epoch - 9ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.4033 - accuracy: 0.8217 - val_loss: 0.4771 - val_accuracy: 0.7447 - 287ms/epoch - 8ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.4032 - accuracy: 0.8217 - val_loss: 0.4774 - val_accuracy: 0.7518 - 287ms/epoch - 8ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.4027 - accuracy: 0.8217 - val_loss: 0.4769 - val_accuracy: 0.7447 - 304ms/epoch - 8ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.4024 - accuracy: 0.8200 - val_loss: 0.4768 - val_accuracy: 0.7518 - 281ms/epoch - 8ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.4024 - accuracy: 0.8217 - val_loss: 0.4767 - val_accuracy: 0.7447 - 318ms/epoch - 9ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.4020 - accuracy: 0.8217 - val_loss: 0.4770 - val_accuracy: 0.7518 - 278ms/epoch - 8ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.4017 - accuracy: 0.8217 - val_loss: 0.4764 - val_accuracy: 0.7447 - 273ms/epoch - 8ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.4012 - accuracy: 0.8235 - val_loss: 0.4768 - val_accuracy: 0.7518 - 315ms/epoch - 9ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.4012 - accuracy: 0.8217 - val_loss: 0.4774 - val_accuracy: 0.7447 - 287ms/epoch - 8ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.4010 - accuracy: 0.8200 - val_loss: 0.4770 - val_accuracy: 0.7447 - 308ms/epoch - 9ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.4007 - accuracy: 0.8200 - val_loss: 0.4769 - val_accuracy: 0.7447 - 317ms/epoch - 9ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.4006 - accuracy: 0.8235 - val_loss: 0.4770 - val_accuracy: 0.7447 - 314ms/epoch - 9ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.4001 - accuracy: 0.8235 - val_loss: 0.4766 - val_accuracy: 0.7447 - 295ms/epoch - 8ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.4004 - accuracy: 0.8217 - val_loss: 0.4772 - val_accuracy: 0.7447 - 312ms/epoch - 9ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3997 - accuracy: 0.8217 - val_loss: 0.4774 - val_accuracy: 0.7376 - 315ms/epoch - 9ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3995 - accuracy: 0.8253 - val_loss: 0.4773 - val_accuracy: 0.7376 - 317ms/epoch - 9ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3995 - accuracy: 0.8253 - val_loss: 0.4770 - val_accuracy: 0.7376 - 287ms/epoch - 8ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3994 - accuracy: 0.8200 - val_loss: 0.4776 - val_accuracy: 0.7376 - 322ms/epoch - 9ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3992 - accuracy: 0.8200 - val_loss: 0.4777 - val_accuracy: 0.7447 - 277ms/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3988 - accuracy: 0.8200 - val_loss: 0.4770 - val_accuracy: 0.7376 - 287ms/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3987 - accuracy: 0.8253 - val_loss: 0.4768 - val_accuracy: 0.7376 - 319ms/epoch - 9ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3982 - accuracy: 0.8235 - val_loss: 0.4766 - val_accuracy: 0.7447 - 264ms/epoch - 7ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3982 - accuracy: 0.8235 - val_loss: 0.4764 - val_accuracy: 0.7447 - 276ms/epoch - 8ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3979 - accuracy: 0.8253 - val_loss: 0.4765 - val_accuracy: 0.7447 - 284ms/epoch - 8ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3978 - accuracy: 0.8253 - val_loss: 0.4765 - val_accuracy: 0.7376 - 280ms/epoch - 8ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3976 - accuracy: 0.8200 - val_loss: 0.4763 - val_accuracy: 0.7376 - 294ms/epoch - 8ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8217 - val_loss: 0.4756 - val_accuracy: 0.7447 - 302ms/epoch - 8ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3973 - accuracy: 0.8235 - val_loss: 0.4749 - val_accuracy: 0.7447 - 268ms/epoch - 7ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3971 - accuracy: 0.8200 - val_loss: 0.4749 - val_accuracy: 0.7447 - 292ms/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3970 - accuracy: 0.8235 - val_loss: 0.4748 - val_accuracy: 0.7518 - 286ms/epoch - 8ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3967 - accuracy: 0.8235 - val_loss: 0.4749 - val_accuracy: 0.7447 - 303ms/epoch - 8ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8182 - val_loss: 0.4750 - val_accuracy: 0.7589 - 303ms/epoch - 8ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8200 - val_loss: 0.4749 - val_accuracy: 0.7518 - 317ms/epoch - 9ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3962 - accuracy: 0.8217 - val_loss: 0.4748 - val_accuracy: 0.7518 - 307ms/epoch - 9ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8182 - val_loss: 0.4750 - val_accuracy: 0.7518 - 304ms/epoch - 8ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3960 - accuracy: 0.8182 - val_loss: 0.4750 - val_accuracy: 0.7589 - 296ms/epoch - 8ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8200 - val_loss: 0.4749 - val_accuracy: 0.7518 - 291ms/epoch - 8ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8217 - val_loss: 0.4753 - val_accuracy: 0.7589 - 293ms/epoch - 8ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3954 - accuracy: 0.8217 - val_loss: 0.4746 - val_accuracy: 0.7660 - 329ms/epoch - 9ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3956 - accuracy: 0.8217 - val_loss: 0.4749 - val_accuracy: 0.7589 - 296ms/epoch - 8ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3953 - accuracy: 0.8200 - val_loss: 0.4750 - val_accuracy: 0.7589 - 326ms/epoch - 9ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8217 - val_loss: 0.4747 - val_accuracy: 0.7660 - 348ms/epoch - 10ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8217 - val_loss: 0.4752 - val_accuracy: 0.7589 - 304ms/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "history_base = model_base.fit(x=X_train_base, y=y_train_base, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_per = model_per.fit(x=X_train_per, y=y_train_per, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_mdi = model_mdi.fit(x=X_train_mdi, y=y_train_mdi, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(result_dir/\"ACHE/val/ache_val.csv\",sep=\",\",index_col=\"Index\")\n",
    "df.loc[len(df[\"Name\"])] = [\"fe_rf_per_nn\",0.7518]\n",
    "df.to_csv(result_dir/\"ACHE/val/ache_val.csv\",sep=\",\",index=\"Index\")\n",
    "\n",
    "df = pd.read_csv(result_dir/\"ACHE/val/ache_val.csv\",sep=\",\",index_col=\"Index\")\n",
    "df.loc[len(df[\"Name\"])] = [\"fe_rf_mdi_nn\",0.7589]\n",
    "df.to_csv(result_dir/\"ACHE/val/ache_val.csv\",sep=\",\",index=\"Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Testdata using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "---------Base-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------Permutation-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------MDI-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[137,   0],\n",
       "       [164,   0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_base = model_base.predict(X_test_base)\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "\n",
    "print(\"---------Base-Prediction----------\")\n",
    "evaluate_classification_result(y_test_base,pred_base,classes=nn_data_base[\"target_names\"])\n",
    "print(\"---------Permutation-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_per,pred_per,classes=nn_data_per[\"target_names\"])\n",
    "print(\"---------MDI-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_mdi,pred_mdi,classes=nn_data_mdi[\"target_names\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_base = model_base.predict(X_test_base)\n",
    "classes_base = [1 if i > 0.5  else 0 for i in pred_base]\n",
    "\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "classes_per = [1 if i > 0.5  else 0 for i in pred_per]\n",
    "\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "classes_mdi = [1 if i > 0.5  else 0 for i in pred_mdi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_per.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_per):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_per\n",
    "result_df[\"PRED\"] = classes_per\n",
    "\n",
    "result_df.to_csv(result_dir/\"ACHE/fe_rf_per_nn.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_mdi.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_mdi):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_mdi\n",
    "result_df[\"PRED\"] = classes_mdi\n",
    "\n",
    "result_df.to_csv(result_dir / \"ACHE/fe_rf_mdi_nn.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activity_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
