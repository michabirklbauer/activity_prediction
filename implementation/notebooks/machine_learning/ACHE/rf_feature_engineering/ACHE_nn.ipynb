{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from pyMLaux import plot_history, evaluate_classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/bac/activity_prediction/implementation/'\n",
    "data_dir = base_dir + 'data/source/'\n",
    "result_dir = base_dir + 'data/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load & prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code needs to be adapted for each protein-ligand complex individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data_raw_mdi = pd.read_csv(data_dir+\"ACHE/ache_mdi.csv\")\n",
    "nn_data_raw_per = pd.read_csv(data_dir+\"ACHE/ache_per.csv\")\n",
    "nn_data_raw = pd.read_csv(data_dir+\"ACHE/ache.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {'inactive':0,'active':1}\n",
    "\n",
    "nn_data_per = {'data': np.array(nn_data_raw_per.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_per.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_per.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_mdi = {'data': np.array(nn_data_raw_mdi.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_mdi.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_mdi.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_base = {'data': np.array(nn_data_raw.iloc[:, 2:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw.columns[2:-1],\n",
    "             'target_names': ['inactive', 'active']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train- and test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(nn_data_base['data'], nn_data_base['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_mdi, X_test_mdi, y_train_mdi, y_test_mdi = train_test_split(nn_data_mdi['data'], nn_data_mdi['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_per, X_test_per, y_train_per, y_test_per = train_test_split(nn_data_per['data'], nn_data_per['target'],\n",
    "                                                    test_size=0.3, random_state=4232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and apply neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_base['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_base.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_per = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_per['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_per.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_mdi = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_mdi['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_mdi.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 1s - loss: 0.7169 - accuracy: 0.5223 - val_loss: 0.7031 - val_accuracy: 0.5319 - 795ms/epoch - 22ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.6873 - accuracy: 0.5597 - val_loss: 0.6836 - val_accuracy: 0.5887 - 179ms/epoch - 5ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.6622 - accuracy: 0.5847 - val_loss: 0.6651 - val_accuracy: 0.5957 - 178ms/epoch - 5ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.6387 - accuracy: 0.6310 - val_loss: 0.6490 - val_accuracy: 0.6383 - 193ms/epoch - 5ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.6194 - accuracy: 0.6863 - val_loss: 0.6351 - val_accuracy: 0.6454 - 198ms/epoch - 5ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.6009 - accuracy: 0.7023 - val_loss: 0.6232 - val_accuracy: 0.6667 - 231ms/epoch - 6ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.5847 - accuracy: 0.7201 - val_loss: 0.6122 - val_accuracy: 0.6879 - 211ms/epoch - 6ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.5716 - accuracy: 0.7451 - val_loss: 0.6025 - val_accuracy: 0.7021 - 174ms/epoch - 5ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.5585 - accuracy: 0.7647 - val_loss: 0.5943 - val_accuracy: 0.7021 - 183ms/epoch - 5ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.5472 - accuracy: 0.7683 - val_loss: 0.5872 - val_accuracy: 0.7021 - 188ms/epoch - 5ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5369 - accuracy: 0.7665 - val_loss: 0.5800 - val_accuracy: 0.7092 - 192ms/epoch - 5ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5271 - accuracy: 0.7647 - val_loss: 0.5726 - val_accuracy: 0.7234 - 192ms/epoch - 5ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5180 - accuracy: 0.7701 - val_loss: 0.5668 - val_accuracy: 0.7163 - 193ms/epoch - 5ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5100 - accuracy: 0.7772 - val_loss: 0.5606 - val_accuracy: 0.7163 - 205ms/epoch - 6ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5022 - accuracy: 0.7736 - val_loss: 0.5551 - val_accuracy: 0.7163 - 191ms/epoch - 5ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.4950 - accuracy: 0.7736 - val_loss: 0.5503 - val_accuracy: 0.7305 - 180ms/epoch - 5ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.4890 - accuracy: 0.7772 - val_loss: 0.5458 - val_accuracy: 0.7234 - 201ms/epoch - 6ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.4832 - accuracy: 0.7861 - val_loss: 0.5417 - val_accuracy: 0.7305 - 216ms/epoch - 6ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.4776 - accuracy: 0.7861 - val_loss: 0.5377 - val_accuracy: 0.7305 - 189ms/epoch - 5ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.4721 - accuracy: 0.7879 - val_loss: 0.5341 - val_accuracy: 0.7305 - 181ms/epoch - 5ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.4674 - accuracy: 0.7932 - val_loss: 0.5305 - val_accuracy: 0.7376 - 197ms/epoch - 5ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4631 - accuracy: 0.7968 - val_loss: 0.5269 - val_accuracy: 0.7376 - 179ms/epoch - 5ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4590 - accuracy: 0.7968 - val_loss: 0.5243 - val_accuracy: 0.7447 - 180ms/epoch - 5ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4551 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7447 - 197ms/epoch - 5ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4514 - accuracy: 0.8075 - val_loss: 0.5185 - val_accuracy: 0.7447 - 176ms/epoch - 5ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4478 - accuracy: 0.8128 - val_loss: 0.5161 - val_accuracy: 0.7518 - 165ms/epoch - 5ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4445 - accuracy: 0.8128 - val_loss: 0.5130 - val_accuracy: 0.7589 - 171ms/epoch - 5ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4412 - accuracy: 0.8111 - val_loss: 0.5112 - val_accuracy: 0.7589 - 171ms/epoch - 5ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4389 - accuracy: 0.8111 - val_loss: 0.5096 - val_accuracy: 0.7660 - 166ms/epoch - 5ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4362 - accuracy: 0.8128 - val_loss: 0.5076 - val_accuracy: 0.7660 - 183ms/epoch - 5ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4333 - accuracy: 0.8128 - val_loss: 0.5054 - val_accuracy: 0.7660 - 170ms/epoch - 5ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4307 - accuracy: 0.8182 - val_loss: 0.5037 - val_accuracy: 0.7660 - 211ms/epoch - 6ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4282 - accuracy: 0.8200 - val_loss: 0.5019 - val_accuracy: 0.7660 - 186ms/epoch - 5ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4256 - accuracy: 0.8217 - val_loss: 0.4998 - val_accuracy: 0.7660 - 169ms/epoch - 5ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4236 - accuracy: 0.8217 - val_loss: 0.4981 - val_accuracy: 0.7660 - 195ms/epoch - 5ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4214 - accuracy: 0.8253 - val_loss: 0.4966 - val_accuracy: 0.7660 - 163ms/epoch - 5ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4198 - accuracy: 0.8217 - val_loss: 0.4951 - val_accuracy: 0.7660 - 149ms/epoch - 4ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4175 - accuracy: 0.8253 - val_loss: 0.4933 - val_accuracy: 0.7660 - 167ms/epoch - 5ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4155 - accuracy: 0.8235 - val_loss: 0.4923 - val_accuracy: 0.7730 - 178ms/epoch - 5ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4137 - accuracy: 0.8235 - val_loss: 0.4906 - val_accuracy: 0.7660 - 162ms/epoch - 4ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4118 - accuracy: 0.8324 - val_loss: 0.4898 - val_accuracy: 0.7730 - 163ms/epoch - 5ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4101 - accuracy: 0.8271 - val_loss: 0.4888 - val_accuracy: 0.7730 - 169ms/epoch - 5ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4090 - accuracy: 0.8289 - val_loss: 0.4875 - val_accuracy: 0.7730 - 160ms/epoch - 4ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4070 - accuracy: 0.8271 - val_loss: 0.4857 - val_accuracy: 0.7730 - 154ms/epoch - 4ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4053 - accuracy: 0.8289 - val_loss: 0.4846 - val_accuracy: 0.7730 - 153ms/epoch - 4ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4036 - accuracy: 0.8307 - val_loss: 0.4830 - val_accuracy: 0.7730 - 153ms/epoch - 4ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4022 - accuracy: 0.8307 - val_loss: 0.4819 - val_accuracy: 0.7730 - 159ms/epoch - 4ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4008 - accuracy: 0.8324 - val_loss: 0.4813 - val_accuracy: 0.7660 - 154ms/epoch - 4ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.3996 - accuracy: 0.8324 - val_loss: 0.4804 - val_accuracy: 0.7660 - 151ms/epoch - 4ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.3980 - accuracy: 0.8342 - val_loss: 0.4795 - val_accuracy: 0.7660 - 161ms/epoch - 4ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8342 - val_loss: 0.4789 - val_accuracy: 0.7660 - 151ms/epoch - 4ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.3955 - accuracy: 0.8360 - val_loss: 0.4779 - val_accuracy: 0.7660 - 157ms/epoch - 4ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.3941 - accuracy: 0.8342 - val_loss: 0.4767 - val_accuracy: 0.7660 - 154ms/epoch - 4ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.3930 - accuracy: 0.8360 - val_loss: 0.4755 - val_accuracy: 0.7660 - 157ms/epoch - 4ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.3921 - accuracy: 0.8360 - val_loss: 0.4752 - val_accuracy: 0.7660 - 161ms/epoch - 4ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.3906 - accuracy: 0.8360 - val_loss: 0.4743 - val_accuracy: 0.7660 - 160ms/epoch - 4ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.3896 - accuracy: 0.8360 - val_loss: 0.4731 - val_accuracy: 0.7660 - 150ms/epoch - 4ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.3885 - accuracy: 0.8360 - val_loss: 0.4722 - val_accuracy: 0.7660 - 155ms/epoch - 4ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.3874 - accuracy: 0.8396 - val_loss: 0.4721 - val_accuracy: 0.7660 - 156ms/epoch - 4ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.3865 - accuracy: 0.8396 - val_loss: 0.4710 - val_accuracy: 0.7660 - 163ms/epoch - 5ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.3857 - accuracy: 0.8378 - val_loss: 0.4699 - val_accuracy: 0.7660 - 155ms/epoch - 4ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.3848 - accuracy: 0.8396 - val_loss: 0.4692 - val_accuracy: 0.7660 - 158ms/epoch - 4ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.3833 - accuracy: 0.8414 - val_loss: 0.4688 - val_accuracy: 0.7660 - 162ms/epoch - 5ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.3824 - accuracy: 0.8414 - val_loss: 0.4669 - val_accuracy: 0.7730 - 159ms/epoch - 4ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.3821 - accuracy: 0.8378 - val_loss: 0.4662 - val_accuracy: 0.7660 - 156ms/epoch - 4ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.3810 - accuracy: 0.8414 - val_loss: 0.4659 - val_accuracy: 0.7660 - 144ms/epoch - 4ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.3801 - accuracy: 0.8396 - val_loss: 0.4657 - val_accuracy: 0.7660 - 148ms/epoch - 4ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.3793 - accuracy: 0.8396 - val_loss: 0.4654 - val_accuracy: 0.7660 - 154ms/epoch - 4ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.3785 - accuracy: 0.8378 - val_loss: 0.4654 - val_accuracy: 0.7730 - 168ms/epoch - 5ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.3783 - accuracy: 0.8378 - val_loss: 0.4644 - val_accuracy: 0.7730 - 157ms/epoch - 4ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.3773 - accuracy: 0.8396 - val_loss: 0.4641 - val_accuracy: 0.7660 - 163ms/epoch - 5ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.3762 - accuracy: 0.8378 - val_loss: 0.4635 - val_accuracy: 0.7660 - 166ms/epoch - 5ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.3755 - accuracy: 0.8378 - val_loss: 0.4637 - val_accuracy: 0.7660 - 156ms/epoch - 4ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.3750 - accuracy: 0.8342 - val_loss: 0.4635 - val_accuracy: 0.7660 - 147ms/epoch - 4ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.3740 - accuracy: 0.8360 - val_loss: 0.4630 - val_accuracy: 0.7660 - 153ms/epoch - 4ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.3733 - accuracy: 0.8378 - val_loss: 0.4626 - val_accuracy: 0.7660 - 169ms/epoch - 5ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.3727 - accuracy: 0.8360 - val_loss: 0.4628 - val_accuracy: 0.7660 - 173ms/epoch - 5ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.3722 - accuracy: 0.8396 - val_loss: 0.4619 - val_accuracy: 0.7660 - 174ms/epoch - 5ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.3714 - accuracy: 0.8414 - val_loss: 0.4620 - val_accuracy: 0.7660 - 194ms/epoch - 5ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.3706 - accuracy: 0.8396 - val_loss: 0.4618 - val_accuracy: 0.7660 - 224ms/epoch - 6ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.3701 - accuracy: 0.8431 - val_loss: 0.4614 - val_accuracy: 0.7660 - 266ms/epoch - 7ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.3694 - accuracy: 0.8414 - val_loss: 0.4609 - val_accuracy: 0.7660 - 239ms/epoch - 7ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.3689 - accuracy: 0.8414 - val_loss: 0.4606 - val_accuracy: 0.7660 - 255ms/epoch - 7ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.3682 - accuracy: 0.8414 - val_loss: 0.4602 - val_accuracy: 0.7660 - 202ms/epoch - 6ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.3675 - accuracy: 0.8449 - val_loss: 0.4596 - val_accuracy: 0.7660 - 207ms/epoch - 6ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.3668 - accuracy: 0.8449 - val_loss: 0.4598 - val_accuracy: 0.7660 - 195ms/epoch - 5ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.3662 - accuracy: 0.8414 - val_loss: 0.4596 - val_accuracy: 0.7660 - 202ms/epoch - 6ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.3660 - accuracy: 0.8378 - val_loss: 0.4598 - val_accuracy: 0.7660 - 199ms/epoch - 6ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.3652 - accuracy: 0.8414 - val_loss: 0.4592 - val_accuracy: 0.7660 - 189ms/epoch - 5ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.3648 - accuracy: 0.8378 - val_loss: 0.4600 - val_accuracy: 0.7660 - 182ms/epoch - 5ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.3642 - accuracy: 0.8414 - val_loss: 0.4594 - val_accuracy: 0.7660 - 189ms/epoch - 5ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.3637 - accuracy: 0.8360 - val_loss: 0.4596 - val_accuracy: 0.7589 - 206ms/epoch - 6ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.3629 - accuracy: 0.8360 - val_loss: 0.4589 - val_accuracy: 0.7660 - 176ms/epoch - 5ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.3628 - accuracy: 0.8414 - val_loss: 0.4573 - val_accuracy: 0.7730 - 175ms/epoch - 5ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.3619 - accuracy: 0.8396 - val_loss: 0.4577 - val_accuracy: 0.7730 - 180ms/epoch - 5ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.3615 - accuracy: 0.8449 - val_loss: 0.4567 - val_accuracy: 0.7730 - 173ms/epoch - 5ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.3612 - accuracy: 0.8467 - val_loss: 0.4566 - val_accuracy: 0.7730 - 174ms/epoch - 5ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.3605 - accuracy: 0.8414 - val_loss: 0.4568 - val_accuracy: 0.7730 - 168ms/epoch - 5ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.3598 - accuracy: 0.8378 - val_loss: 0.4570 - val_accuracy: 0.7730 - 173ms/epoch - 5ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.3594 - accuracy: 0.8378 - val_loss: 0.4564 - val_accuracy: 0.7730 - 195ms/epoch - 5ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.3588 - accuracy: 0.8396 - val_loss: 0.4569 - val_accuracy: 0.7660 - 186ms/epoch - 5ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.3584 - accuracy: 0.8414 - val_loss: 0.4567 - val_accuracy: 0.7660 - 199ms/epoch - 6ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.3579 - accuracy: 0.8414 - val_loss: 0.4564 - val_accuracy: 0.7589 - 194ms/epoch - 5ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.3577 - accuracy: 0.8414 - val_loss: 0.4562 - val_accuracy: 0.7730 - 183ms/epoch - 5ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3571 - accuracy: 0.8414 - val_loss: 0.4568 - val_accuracy: 0.7660 - 176ms/epoch - 5ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3563 - accuracy: 0.8431 - val_loss: 0.4559 - val_accuracy: 0.7730 - 177ms/epoch - 5ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3563 - accuracy: 0.8431 - val_loss: 0.4558 - val_accuracy: 0.7730 - 206ms/epoch - 6ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3556 - accuracy: 0.8431 - val_loss: 0.4555 - val_accuracy: 0.7730 - 215ms/epoch - 6ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3554 - accuracy: 0.8431 - val_loss: 0.4554 - val_accuracy: 0.7730 - 166ms/epoch - 5ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3549 - accuracy: 0.8414 - val_loss: 0.4549 - val_accuracy: 0.7730 - 172ms/epoch - 5ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3544 - accuracy: 0.8414 - val_loss: 0.4550 - val_accuracy: 0.7801 - 166ms/epoch - 5ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3542 - accuracy: 0.8449 - val_loss: 0.4549 - val_accuracy: 0.7730 - 183ms/epoch - 5ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3537 - accuracy: 0.8449 - val_loss: 0.4551 - val_accuracy: 0.7801 - 180ms/epoch - 5ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3532 - accuracy: 0.8449 - val_loss: 0.4553 - val_accuracy: 0.7801 - 191ms/epoch - 5ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3528 - accuracy: 0.8449 - val_loss: 0.4553 - val_accuracy: 0.7801 - 187ms/epoch - 5ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3522 - accuracy: 0.8449 - val_loss: 0.4550 - val_accuracy: 0.7801 - 144ms/epoch - 4ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3520 - accuracy: 0.8431 - val_loss: 0.4550 - val_accuracy: 0.7801 - 153ms/epoch - 4ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3516 - accuracy: 0.8449 - val_loss: 0.4545 - val_accuracy: 0.7801 - 140ms/epoch - 4ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3512 - accuracy: 0.8485 - val_loss: 0.4544 - val_accuracy: 0.7730 - 142ms/epoch - 4ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3508 - accuracy: 0.8485 - val_loss: 0.4537 - val_accuracy: 0.7730 - 147ms/epoch - 4ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3505 - accuracy: 0.8449 - val_loss: 0.4544 - val_accuracy: 0.7801 - 143ms/epoch - 4ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3502 - accuracy: 0.8449 - val_loss: 0.4537 - val_accuracy: 0.7801 - 142ms/epoch - 4ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3502 - accuracy: 0.8467 - val_loss: 0.4537 - val_accuracy: 0.7801 - 148ms/epoch - 4ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3494 - accuracy: 0.8485 - val_loss: 0.4539 - val_accuracy: 0.7801 - 138ms/epoch - 4ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3490 - accuracy: 0.8485 - val_loss: 0.4536 - val_accuracy: 0.7801 - 137ms/epoch - 4ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3487 - accuracy: 0.8503 - val_loss: 0.4538 - val_accuracy: 0.7801 - 142ms/epoch - 4ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3483 - accuracy: 0.8485 - val_loss: 0.4535 - val_accuracy: 0.7801 - 144ms/epoch - 4ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3480 - accuracy: 0.8467 - val_loss: 0.4537 - val_accuracy: 0.7872 - 146ms/epoch - 4ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3481 - accuracy: 0.8485 - val_loss: 0.4534 - val_accuracy: 0.7801 - 139ms/epoch - 4ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3471 - accuracy: 0.8503 - val_loss: 0.4537 - val_accuracy: 0.7872 - 153ms/epoch - 4ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3468 - accuracy: 0.8538 - val_loss: 0.4534 - val_accuracy: 0.7872 - 138ms/epoch - 4ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3464 - accuracy: 0.8503 - val_loss: 0.4536 - val_accuracy: 0.7872 - 142ms/epoch - 4ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3463 - accuracy: 0.8503 - val_loss: 0.4533 - val_accuracy: 0.7943 - 143ms/epoch - 4ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3459 - accuracy: 0.8520 - val_loss: 0.4529 - val_accuracy: 0.7943 - 209ms/epoch - 6ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3456 - accuracy: 0.8503 - val_loss: 0.4538 - val_accuracy: 0.7943 - 231ms/epoch - 6ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3455 - accuracy: 0.8485 - val_loss: 0.4531 - val_accuracy: 0.7943 - 228ms/epoch - 6ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3449 - accuracy: 0.8503 - val_loss: 0.4530 - val_accuracy: 0.7872 - 274ms/epoch - 8ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3453 - accuracy: 0.8467 - val_loss: 0.4519 - val_accuracy: 0.7872 - 286ms/epoch - 8ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3444 - accuracy: 0.8538 - val_loss: 0.4526 - val_accuracy: 0.7943 - 268ms/epoch - 7ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3439 - accuracy: 0.8520 - val_loss: 0.4527 - val_accuracy: 0.7943 - 282ms/epoch - 8ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3437 - accuracy: 0.8503 - val_loss: 0.4519 - val_accuracy: 0.7872 - 252ms/epoch - 7ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3434 - accuracy: 0.8538 - val_loss: 0.4515 - val_accuracy: 0.7943 - 274ms/epoch - 8ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3432 - accuracy: 0.8520 - val_loss: 0.4514 - val_accuracy: 0.7872 - 255ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3427 - accuracy: 0.8538 - val_loss: 0.4520 - val_accuracy: 0.8014 - 232ms/epoch - 6ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3424 - accuracy: 0.8503 - val_loss: 0.4516 - val_accuracy: 0.7943 - 252ms/epoch - 7ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3422 - accuracy: 0.8556 - val_loss: 0.4516 - val_accuracy: 0.7872 - 244ms/epoch - 7ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3423 - accuracy: 0.8520 - val_loss: 0.4511 - val_accuracy: 0.7872 - 238ms/epoch - 7ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3421 - accuracy: 0.8485 - val_loss: 0.4531 - val_accuracy: 0.7943 - 244ms/epoch - 7ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3415 - accuracy: 0.8503 - val_loss: 0.4528 - val_accuracy: 0.7943 - 261ms/epoch - 7ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3419 - accuracy: 0.8467 - val_loss: 0.4537 - val_accuracy: 0.7872 - 250ms/epoch - 7ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 0.6562 - accuracy: 0.6168 - val_loss: 0.6596 - val_accuracy: 0.6099 - 711ms/epoch - 20ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.6358 - accuracy: 0.6310 - val_loss: 0.6459 - val_accuracy: 0.6312 - 294ms/epoch - 8ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.6195 - accuracy: 0.6595 - val_loss: 0.6338 - val_accuracy: 0.6525 - 266ms/epoch - 7ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.6042 - accuracy: 0.6809 - val_loss: 0.6236 - val_accuracy: 0.6738 - 256ms/epoch - 7ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.5900 - accuracy: 0.6988 - val_loss: 0.6132 - val_accuracy: 0.6738 - 266ms/epoch - 7ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.5776 - accuracy: 0.7112 - val_loss: 0.6043 - val_accuracy: 0.6879 - 269ms/epoch - 7ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.5665 - accuracy: 0.7255 - val_loss: 0.5958 - val_accuracy: 0.6950 - 253ms/epoch - 7ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.5554 - accuracy: 0.7344 - val_loss: 0.5884 - val_accuracy: 0.7021 - 254ms/epoch - 7ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.5461 - accuracy: 0.7469 - val_loss: 0.5812 - val_accuracy: 0.6950 - 247ms/epoch - 7ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.5370 - accuracy: 0.7522 - val_loss: 0.5741 - val_accuracy: 0.6950 - 263ms/epoch - 7ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5289 - accuracy: 0.7558 - val_loss: 0.5679 - val_accuracy: 0.6950 - 272ms/epoch - 8ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5211 - accuracy: 0.7683 - val_loss: 0.5622 - val_accuracy: 0.7021 - 260ms/epoch - 7ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5138 - accuracy: 0.7647 - val_loss: 0.5563 - val_accuracy: 0.7021 - 281ms/epoch - 8ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5073 - accuracy: 0.7718 - val_loss: 0.5512 - val_accuracy: 0.7021 - 267ms/epoch - 7ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5010 - accuracy: 0.7736 - val_loss: 0.5462 - val_accuracy: 0.7092 - 257ms/epoch - 7ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.4952 - accuracy: 0.7825 - val_loss: 0.5417 - val_accuracy: 0.7234 - 249ms/epoch - 7ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.4899 - accuracy: 0.7897 - val_loss: 0.5372 - val_accuracy: 0.7163 - 270ms/epoch - 7ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.4857 - accuracy: 0.7986 - val_loss: 0.5339 - val_accuracy: 0.7092 - 243ms/epoch - 7ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.4804 - accuracy: 0.8057 - val_loss: 0.5305 - val_accuracy: 0.7234 - 251ms/epoch - 7ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.4762 - accuracy: 0.8057 - val_loss: 0.5271 - val_accuracy: 0.7234 - 258ms/epoch - 7ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.4721 - accuracy: 0.8057 - val_loss: 0.5246 - val_accuracy: 0.7234 - 251ms/epoch - 7ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4683 - accuracy: 0.8146 - val_loss: 0.5218 - val_accuracy: 0.7376 - 342ms/epoch - 10ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4651 - accuracy: 0.8128 - val_loss: 0.5184 - val_accuracy: 0.7305 - 331ms/epoch - 9ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4616 - accuracy: 0.8182 - val_loss: 0.5162 - val_accuracy: 0.7376 - 291ms/epoch - 8ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4591 - accuracy: 0.8200 - val_loss: 0.5145 - val_accuracy: 0.7447 - 337ms/epoch - 9ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4566 - accuracy: 0.8182 - val_loss: 0.5126 - val_accuracy: 0.7447 - 370ms/epoch - 10ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4536 - accuracy: 0.8200 - val_loss: 0.5102 - val_accuracy: 0.7447 - 359ms/epoch - 10ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4509 - accuracy: 0.8217 - val_loss: 0.5074 - val_accuracy: 0.7447 - 333ms/epoch - 9ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4484 - accuracy: 0.8235 - val_loss: 0.5053 - val_accuracy: 0.7447 - 270ms/epoch - 7ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4461 - accuracy: 0.8235 - val_loss: 0.5039 - val_accuracy: 0.7447 - 262ms/epoch - 7ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4440 - accuracy: 0.8235 - val_loss: 0.5026 - val_accuracy: 0.7518 - 252ms/epoch - 7ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4421 - accuracy: 0.8235 - val_loss: 0.5009 - val_accuracy: 0.7518 - 303ms/epoch - 8ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4399 - accuracy: 0.8253 - val_loss: 0.4990 - val_accuracy: 0.7518 - 359ms/epoch - 10ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4383 - accuracy: 0.8271 - val_loss: 0.4971 - val_accuracy: 0.7518 - 412ms/epoch - 11ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4366 - accuracy: 0.8271 - val_loss: 0.4958 - val_accuracy: 0.7518 - 321ms/epoch - 9ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4351 - accuracy: 0.8271 - val_loss: 0.4953 - val_accuracy: 0.7518 - 285ms/epoch - 8ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4335 - accuracy: 0.8289 - val_loss: 0.4937 - val_accuracy: 0.7518 - 282ms/epoch - 8ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4319 - accuracy: 0.8289 - val_loss: 0.4924 - val_accuracy: 0.7589 - 303ms/epoch - 8ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4306 - accuracy: 0.8307 - val_loss: 0.4920 - val_accuracy: 0.7589 - 240ms/epoch - 7ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4292 - accuracy: 0.8324 - val_loss: 0.4905 - val_accuracy: 0.7589 - 280ms/epoch - 8ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4283 - accuracy: 0.8342 - val_loss: 0.4898 - val_accuracy: 0.7589 - 260ms/epoch - 7ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4268 - accuracy: 0.8378 - val_loss: 0.4884 - val_accuracy: 0.7518 - 281ms/epoch - 8ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4254 - accuracy: 0.8378 - val_loss: 0.4876 - val_accuracy: 0.7518 - 274ms/epoch - 8ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4245 - accuracy: 0.8378 - val_loss: 0.4877 - val_accuracy: 0.7518 - 242ms/epoch - 7ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4235 - accuracy: 0.8235 - val_loss: 0.4873 - val_accuracy: 0.7518 - 243ms/epoch - 7ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4224 - accuracy: 0.8324 - val_loss: 0.4861 - val_accuracy: 0.7518 - 250ms/epoch - 7ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4211 - accuracy: 0.8378 - val_loss: 0.4850 - val_accuracy: 0.7518 - 254ms/epoch - 7ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4201 - accuracy: 0.8360 - val_loss: 0.4844 - val_accuracy: 0.7518 - 251ms/epoch - 7ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4195 - accuracy: 0.8342 - val_loss: 0.4836 - val_accuracy: 0.7589 - 256ms/epoch - 7ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4182 - accuracy: 0.8342 - val_loss: 0.4832 - val_accuracy: 0.7589 - 259ms/epoch - 7ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4175 - accuracy: 0.8342 - val_loss: 0.4831 - val_accuracy: 0.7589 - 254ms/epoch - 7ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4167 - accuracy: 0.8342 - val_loss: 0.4827 - val_accuracy: 0.7589 - 279ms/epoch - 8ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4159 - accuracy: 0.8307 - val_loss: 0.4823 - val_accuracy: 0.7589 - 246ms/epoch - 7ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4151 - accuracy: 0.8289 - val_loss: 0.4813 - val_accuracy: 0.7518 - 249ms/epoch - 7ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4143 - accuracy: 0.8307 - val_loss: 0.4809 - val_accuracy: 0.7518 - 250ms/epoch - 7ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4138 - accuracy: 0.8324 - val_loss: 0.4802 - val_accuracy: 0.7660 - 262ms/epoch - 7ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4131 - accuracy: 0.8271 - val_loss: 0.4799 - val_accuracy: 0.7589 - 253ms/epoch - 7ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4123 - accuracy: 0.8307 - val_loss: 0.4796 - val_accuracy: 0.7589 - 270ms/epoch - 7ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4119 - accuracy: 0.8324 - val_loss: 0.4792 - val_accuracy: 0.7518 - 272ms/epoch - 8ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4111 - accuracy: 0.8324 - val_loss: 0.4782 - val_accuracy: 0.7518 - 442ms/epoch - 12ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4104 - accuracy: 0.8324 - val_loss: 0.4781 - val_accuracy: 0.7518 - 330ms/epoch - 9ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4098 - accuracy: 0.8324 - val_loss: 0.4782 - val_accuracy: 0.7518 - 395ms/epoch - 11ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4091 - accuracy: 0.8378 - val_loss: 0.4774 - val_accuracy: 0.7518 - 454ms/epoch - 13ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4087 - accuracy: 0.8360 - val_loss: 0.4769 - val_accuracy: 0.7518 - 393ms/epoch - 11ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4081 - accuracy: 0.8360 - val_loss: 0.4770 - val_accuracy: 0.7518 - 390ms/epoch - 11ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4077 - accuracy: 0.8360 - val_loss: 0.4768 - val_accuracy: 0.7518 - 459ms/epoch - 13ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4071 - accuracy: 0.8342 - val_loss: 0.4767 - val_accuracy: 0.7518 - 366ms/epoch - 10ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4068 - accuracy: 0.8324 - val_loss: 0.4767 - val_accuracy: 0.7518 - 367ms/epoch - 10ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4062 - accuracy: 0.8324 - val_loss: 0.4764 - val_accuracy: 0.7589 - 371ms/epoch - 10ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4059 - accuracy: 0.8307 - val_loss: 0.4764 - val_accuracy: 0.7589 - 364ms/epoch - 10ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4053 - accuracy: 0.8324 - val_loss: 0.4762 - val_accuracy: 0.7589 - 350ms/epoch - 10ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4048 - accuracy: 0.8289 - val_loss: 0.4756 - val_accuracy: 0.7589 - 372ms/epoch - 10ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4043 - accuracy: 0.8289 - val_loss: 0.4755 - val_accuracy: 0.7589 - 355ms/epoch - 10ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4040 - accuracy: 0.8324 - val_loss: 0.4755 - val_accuracy: 0.7589 - 347ms/epoch - 10ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4036 - accuracy: 0.8342 - val_loss: 0.4750 - val_accuracy: 0.7589 - 351ms/epoch - 10ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4031 - accuracy: 0.8307 - val_loss: 0.4741 - val_accuracy: 0.7518 - 356ms/epoch - 10ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4028 - accuracy: 0.8342 - val_loss: 0.4749 - val_accuracy: 0.7660 - 366ms/epoch - 10ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4029 - accuracy: 0.8324 - val_loss: 0.4745 - val_accuracy: 0.7660 - 361ms/epoch - 10ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4023 - accuracy: 0.8324 - val_loss: 0.4751 - val_accuracy: 0.7660 - 348ms/epoch - 10ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4020 - accuracy: 0.8324 - val_loss: 0.4743 - val_accuracy: 0.7660 - 362ms/epoch - 10ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4014 - accuracy: 0.8342 - val_loss: 0.4742 - val_accuracy: 0.7660 - 329ms/epoch - 9ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4013 - accuracy: 0.8360 - val_loss: 0.4740 - val_accuracy: 0.7518 - 346ms/epoch - 10ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4011 - accuracy: 0.8324 - val_loss: 0.4747 - val_accuracy: 0.7660 - 339ms/epoch - 9ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4006 - accuracy: 0.8342 - val_loss: 0.4737 - val_accuracy: 0.7589 - 358ms/epoch - 10ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4002 - accuracy: 0.8342 - val_loss: 0.4741 - val_accuracy: 0.7589 - 334ms/epoch - 9ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.3999 - accuracy: 0.8342 - val_loss: 0.4739 - val_accuracy: 0.7589 - 352ms/epoch - 10ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.3997 - accuracy: 0.8324 - val_loss: 0.4739 - val_accuracy: 0.7589 - 350ms/epoch - 10ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.3992 - accuracy: 0.8342 - val_loss: 0.4742 - val_accuracy: 0.7589 - 354ms/epoch - 10ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.3989 - accuracy: 0.8342 - val_loss: 0.4743 - val_accuracy: 0.7589 - 336ms/epoch - 9ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.3986 - accuracy: 0.8360 - val_loss: 0.4746 - val_accuracy: 0.7589 - 344ms/epoch - 10ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.3984 - accuracy: 0.8360 - val_loss: 0.4743 - val_accuracy: 0.7589 - 340ms/epoch - 9ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.3980 - accuracy: 0.8360 - val_loss: 0.4740 - val_accuracy: 0.7589 - 381ms/epoch - 11ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.3979 - accuracy: 0.8342 - val_loss: 0.4734 - val_accuracy: 0.7518 - 377ms/epoch - 10ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.3977 - accuracy: 0.8360 - val_loss: 0.4738 - val_accuracy: 0.7518 - 360ms/epoch - 10ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.3974 - accuracy: 0.8378 - val_loss: 0.4738 - val_accuracy: 0.7518 - 351ms/epoch - 10ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.3971 - accuracy: 0.8360 - val_loss: 0.4741 - val_accuracy: 0.7518 - 357ms/epoch - 10ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.3968 - accuracy: 0.8360 - val_loss: 0.4736 - val_accuracy: 0.7518 - 355ms/epoch - 10ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8360 - val_loss: 0.4737 - val_accuracy: 0.7518 - 328ms/epoch - 9ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8360 - val_loss: 0.4752 - val_accuracy: 0.7518 - 342ms/epoch - 9ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.3962 - accuracy: 0.8360 - val_loss: 0.4751 - val_accuracy: 0.7518 - 347ms/epoch - 10ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8360 - val_loss: 0.4746 - val_accuracy: 0.7518 - 333ms/epoch - 9ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8360 - val_loss: 0.4747 - val_accuracy: 0.7518 - 328ms/epoch - 9ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.3957 - accuracy: 0.8360 - val_loss: 0.4740 - val_accuracy: 0.7518 - 347ms/epoch - 10ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8307 - val_loss: 0.4744 - val_accuracy: 0.7730 - 348ms/epoch - 10ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8342 - val_loss: 0.4734 - val_accuracy: 0.7518 - 362ms/epoch - 10ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3950 - accuracy: 0.8360 - val_loss: 0.4734 - val_accuracy: 0.7518 - 345ms/epoch - 10ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3949 - accuracy: 0.8360 - val_loss: 0.4734 - val_accuracy: 0.7518 - 359ms/epoch - 10ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3947 - accuracy: 0.8342 - val_loss: 0.4724 - val_accuracy: 0.7518 - 357ms/epoch - 10ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3945 - accuracy: 0.8342 - val_loss: 0.4727 - val_accuracy: 0.7518 - 362ms/epoch - 10ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3945 - accuracy: 0.8378 - val_loss: 0.4727 - val_accuracy: 0.7518 - 359ms/epoch - 10ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3945 - accuracy: 0.8324 - val_loss: 0.4755 - val_accuracy: 0.7730 - 347ms/epoch - 10ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3939 - accuracy: 0.8324 - val_loss: 0.4746 - val_accuracy: 0.7589 - 356ms/epoch - 10ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3938 - accuracy: 0.8342 - val_loss: 0.4745 - val_accuracy: 0.7589 - 362ms/epoch - 10ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3936 - accuracy: 0.8342 - val_loss: 0.4749 - val_accuracy: 0.7589 - 362ms/epoch - 10ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3934 - accuracy: 0.8342 - val_loss: 0.4738 - val_accuracy: 0.7518 - 367ms/epoch - 10ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3934 - accuracy: 0.8342 - val_loss: 0.4739 - val_accuracy: 0.7518 - 359ms/epoch - 10ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3931 - accuracy: 0.8342 - val_loss: 0.4740 - val_accuracy: 0.7518 - 358ms/epoch - 10ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3930 - accuracy: 0.8324 - val_loss: 0.4738 - val_accuracy: 0.7447 - 348ms/epoch - 10ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3931 - accuracy: 0.8307 - val_loss: 0.4744 - val_accuracy: 0.7518 - 353ms/epoch - 10ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3928 - accuracy: 0.8342 - val_loss: 0.4742 - val_accuracy: 0.7376 - 376ms/epoch - 10ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3928 - accuracy: 0.8307 - val_loss: 0.4743 - val_accuracy: 0.7518 - 378ms/epoch - 10ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3925 - accuracy: 0.8324 - val_loss: 0.4747 - val_accuracy: 0.7518 - 351ms/epoch - 10ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3923 - accuracy: 0.8324 - val_loss: 0.4742 - val_accuracy: 0.7447 - 351ms/epoch - 10ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3923 - accuracy: 0.8342 - val_loss: 0.4741 - val_accuracy: 0.7447 - 365ms/epoch - 10ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3923 - accuracy: 0.8342 - val_loss: 0.4743 - val_accuracy: 0.7447 - 354ms/epoch - 10ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3921 - accuracy: 0.8307 - val_loss: 0.4747 - val_accuracy: 0.7518 - 354ms/epoch - 10ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3918 - accuracy: 0.8360 - val_loss: 0.4750 - val_accuracy: 0.7589 - 355ms/epoch - 10ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3920 - accuracy: 0.8324 - val_loss: 0.4744 - val_accuracy: 0.7447 - 389ms/epoch - 11ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3915 - accuracy: 0.8307 - val_loss: 0.4753 - val_accuracy: 0.7589 - 352ms/epoch - 10ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3914 - accuracy: 0.8324 - val_loss: 0.4754 - val_accuracy: 0.7589 - 360ms/epoch - 10ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3913 - accuracy: 0.8307 - val_loss: 0.4760 - val_accuracy: 0.7589 - 354ms/epoch - 10ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3912 - accuracy: 0.8360 - val_loss: 0.4761 - val_accuracy: 0.7589 - 394ms/epoch - 11ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3910 - accuracy: 0.8378 - val_loss: 0.4763 - val_accuracy: 0.7589 - 346ms/epoch - 10ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3908 - accuracy: 0.8342 - val_loss: 0.4760 - val_accuracy: 0.7589 - 378ms/epoch - 10ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3909 - accuracy: 0.8342 - val_loss: 0.4758 - val_accuracy: 0.7518 - 367ms/epoch - 10ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3907 - accuracy: 0.8324 - val_loss: 0.4760 - val_accuracy: 0.7589 - 366ms/epoch - 10ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3906 - accuracy: 0.8324 - val_loss: 0.4764 - val_accuracy: 0.7589 - 357ms/epoch - 10ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3906 - accuracy: 0.8360 - val_loss: 0.4766 - val_accuracy: 0.7589 - 358ms/epoch - 10ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3903 - accuracy: 0.8360 - val_loss: 0.4767 - val_accuracy: 0.7589 - 354ms/epoch - 10ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3902 - accuracy: 0.8360 - val_loss: 0.4777 - val_accuracy: 0.7589 - 359ms/epoch - 10ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3902 - accuracy: 0.8396 - val_loss: 0.4774 - val_accuracy: 0.7660 - 362ms/epoch - 10ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3902 - accuracy: 0.8396 - val_loss: 0.4773 - val_accuracy: 0.7660 - 351ms/epoch - 10ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3899 - accuracy: 0.8360 - val_loss: 0.4775 - val_accuracy: 0.7660 - 357ms/epoch - 10ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3899 - accuracy: 0.8342 - val_loss: 0.4778 - val_accuracy: 0.7589 - 347ms/epoch - 10ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8378 - val_loss: 0.4775 - val_accuracy: 0.7660 - 358ms/epoch - 10ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8378 - val_loss: 0.4777 - val_accuracy: 0.7660 - 367ms/epoch - 10ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8378 - val_loss: 0.4788 - val_accuracy: 0.7660 - 369ms/epoch - 10ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3894 - accuracy: 0.8396 - val_loss: 0.4773 - val_accuracy: 0.7660 - 356ms/epoch - 10ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3896 - accuracy: 0.8396 - val_loss: 0.4775 - val_accuracy: 0.7660 - 376ms/epoch - 10ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3893 - accuracy: 0.8414 - val_loss: 0.4777 - val_accuracy: 0.7660 - 343ms/epoch - 10ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 0.7750 - accuracy: 0.4742 - val_loss: 0.7774 - val_accuracy: 0.4468 - 759ms/epoch - 21ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.7422 - accuracy: 0.5009 - val_loss: 0.7550 - val_accuracy: 0.4752 - 365ms/epoch - 10ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.7140 - accuracy: 0.5241 - val_loss: 0.7342 - val_accuracy: 0.5177 - 368ms/epoch - 10ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.6886 - accuracy: 0.5490 - val_loss: 0.7149 - val_accuracy: 0.5816 - 359ms/epoch - 10ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.6659 - accuracy: 0.5686 - val_loss: 0.6977 - val_accuracy: 0.6170 - 356ms/epoch - 10ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.6454 - accuracy: 0.6061 - val_loss: 0.6818 - val_accuracy: 0.6454 - 360ms/epoch - 10ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.6262 - accuracy: 0.6346 - val_loss: 0.6675 - val_accuracy: 0.6383 - 342ms/epoch - 9ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.6091 - accuracy: 0.6595 - val_loss: 0.6560 - val_accuracy: 0.6383 - 354ms/epoch - 10ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.5939 - accuracy: 0.6863 - val_loss: 0.6442 - val_accuracy: 0.6383 - 363ms/epoch - 10ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.5825 - accuracy: 0.6988 - val_loss: 0.6359 - val_accuracy: 0.6383 - 358ms/epoch - 10ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5706 - accuracy: 0.7041 - val_loss: 0.6265 - val_accuracy: 0.6383 - 335ms/epoch - 9ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5599 - accuracy: 0.7059 - val_loss: 0.6188 - val_accuracy: 0.6525 - 361ms/epoch - 10ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5499 - accuracy: 0.7184 - val_loss: 0.6110 - val_accuracy: 0.6596 - 349ms/epoch - 10ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5405 - accuracy: 0.7184 - val_loss: 0.6043 - val_accuracy: 0.6738 - 347ms/epoch - 10ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5335 - accuracy: 0.7273 - val_loss: 0.5981 - val_accuracy: 0.6525 - 368ms/epoch - 10ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.5255 - accuracy: 0.7291 - val_loss: 0.5919 - val_accuracy: 0.6667 - 342ms/epoch - 9ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.5182 - accuracy: 0.7380 - val_loss: 0.5864 - val_accuracy: 0.6596 - 357ms/epoch - 10ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.5114 - accuracy: 0.7504 - val_loss: 0.5812 - val_accuracy: 0.6667 - 359ms/epoch - 10ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.5054 - accuracy: 0.7487 - val_loss: 0.5764 - val_accuracy: 0.6738 - 349ms/epoch - 10ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.4997 - accuracy: 0.7576 - val_loss: 0.5721 - val_accuracy: 0.6667 - 394ms/epoch - 11ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.4944 - accuracy: 0.7576 - val_loss: 0.5675 - val_accuracy: 0.6667 - 408ms/epoch - 11ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4896 - accuracy: 0.7594 - val_loss: 0.5638 - val_accuracy: 0.6809 - 405ms/epoch - 11ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4851 - accuracy: 0.7665 - val_loss: 0.5601 - val_accuracy: 0.7021 - 408ms/epoch - 11ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4809 - accuracy: 0.7665 - val_loss: 0.5570 - val_accuracy: 0.7021 - 457ms/epoch - 13ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4772 - accuracy: 0.7683 - val_loss: 0.5534 - val_accuracy: 0.7092 - 382ms/epoch - 11ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4731 - accuracy: 0.7736 - val_loss: 0.5500 - val_accuracy: 0.7092 - 335ms/epoch - 9ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4697 - accuracy: 0.7736 - val_loss: 0.5470 - val_accuracy: 0.7021 - 289ms/epoch - 8ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4666 - accuracy: 0.7754 - val_loss: 0.5441 - val_accuracy: 0.7021 - 281ms/epoch - 8ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4634 - accuracy: 0.7772 - val_loss: 0.5414 - val_accuracy: 0.7021 - 267ms/epoch - 7ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4605 - accuracy: 0.7754 - val_loss: 0.5390 - val_accuracy: 0.7021 - 276ms/epoch - 8ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4579 - accuracy: 0.7790 - val_loss: 0.5366 - val_accuracy: 0.7092 - 295ms/epoch - 8ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4552 - accuracy: 0.7790 - val_loss: 0.5345 - val_accuracy: 0.7021 - 283ms/epoch - 8ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4525 - accuracy: 0.7754 - val_loss: 0.5323 - val_accuracy: 0.7092 - 297ms/epoch - 8ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4507 - accuracy: 0.7772 - val_loss: 0.5306 - val_accuracy: 0.7163 - 273ms/epoch - 8ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4487 - accuracy: 0.7825 - val_loss: 0.5284 - val_accuracy: 0.7163 - 290ms/epoch - 8ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4466 - accuracy: 0.7843 - val_loss: 0.5267 - val_accuracy: 0.7163 - 287ms/epoch - 8ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4447 - accuracy: 0.7825 - val_loss: 0.5248 - val_accuracy: 0.7163 - 276ms/epoch - 8ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4429 - accuracy: 0.7843 - val_loss: 0.5230 - val_accuracy: 0.7234 - 284ms/epoch - 8ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4410 - accuracy: 0.7861 - val_loss: 0.5217 - val_accuracy: 0.7234 - 283ms/epoch - 8ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4394 - accuracy: 0.7861 - val_loss: 0.5200 - val_accuracy: 0.7234 - 289ms/epoch - 8ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4382 - accuracy: 0.7879 - val_loss: 0.5180 - val_accuracy: 0.7305 - 263ms/epoch - 7ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4369 - accuracy: 0.7932 - val_loss: 0.5165 - val_accuracy: 0.7305 - 278ms/epoch - 8ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4353 - accuracy: 0.7897 - val_loss: 0.5152 - val_accuracy: 0.7305 - 288ms/epoch - 8ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4340 - accuracy: 0.7914 - val_loss: 0.5138 - val_accuracy: 0.7305 - 260ms/epoch - 7ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4326 - accuracy: 0.7932 - val_loss: 0.5124 - val_accuracy: 0.7305 - 297ms/epoch - 8ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7376 - 269ms/epoch - 7ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4301 - accuracy: 0.7950 - val_loss: 0.5101 - val_accuracy: 0.7376 - 272ms/epoch - 8ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4289 - accuracy: 0.7968 - val_loss: 0.5090 - val_accuracy: 0.7447 - 266ms/epoch - 7ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4279 - accuracy: 0.7950 - val_loss: 0.5075 - val_accuracy: 0.7376 - 271ms/epoch - 8ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4268 - accuracy: 0.7968 - val_loss: 0.5066 - val_accuracy: 0.7447 - 278ms/epoch - 8ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4261 - accuracy: 0.7968 - val_loss: 0.5059 - val_accuracy: 0.7447 - 288ms/epoch - 8ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7447 - 318ms/epoch - 9ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4239 - accuracy: 0.8039 - val_loss: 0.5038 - val_accuracy: 0.7376 - 298ms/epoch - 8ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4229 - accuracy: 0.8021 - val_loss: 0.5028 - val_accuracy: 0.7447 - 306ms/epoch - 9ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4220 - accuracy: 0.8021 - val_loss: 0.5019 - val_accuracy: 0.7447 - 301ms/epoch - 8ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4212 - accuracy: 0.8004 - val_loss: 0.5009 - val_accuracy: 0.7447 - 299ms/epoch - 8ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4205 - accuracy: 0.8039 - val_loss: 0.5004 - val_accuracy: 0.7447 - 285ms/epoch - 8ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4197 - accuracy: 0.8039 - val_loss: 0.4997 - val_accuracy: 0.7447 - 299ms/epoch - 8ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4197 - accuracy: 0.8075 - val_loss: 0.4989 - val_accuracy: 0.7447 - 320ms/epoch - 9ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4186 - accuracy: 0.7986 - val_loss: 0.4981 - val_accuracy: 0.7447 - 306ms/epoch - 9ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4182 - accuracy: 0.7932 - val_loss: 0.4991 - val_accuracy: 0.7376 - 307ms/epoch - 9ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.4975 - val_accuracy: 0.7447 - 300ms/epoch - 8ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4168 - accuracy: 0.7968 - val_loss: 0.4971 - val_accuracy: 0.7447 - 305ms/epoch - 8ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.4966 - val_accuracy: 0.7447 - 301ms/epoch - 8ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4151 - accuracy: 0.8039 - val_loss: 0.4951 - val_accuracy: 0.7518 - 310ms/epoch - 9ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4145 - accuracy: 0.8021 - val_loss: 0.4945 - val_accuracy: 0.7447 - 293ms/epoch - 8ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4139 - accuracy: 0.8039 - val_loss: 0.4940 - val_accuracy: 0.7518 - 347ms/epoch - 10ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4138 - accuracy: 0.8057 - val_loss: 0.4935 - val_accuracy: 0.7447 - 280ms/epoch - 8ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4131 - accuracy: 0.8039 - val_loss: 0.4929 - val_accuracy: 0.7447 - 311ms/epoch - 9ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4127 - accuracy: 0.8039 - val_loss: 0.4926 - val_accuracy: 0.7447 - 350ms/epoch - 10ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4121 - accuracy: 0.8039 - val_loss: 0.4921 - val_accuracy: 0.7447 - 291ms/epoch - 8ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4116 - accuracy: 0.8075 - val_loss: 0.4914 - val_accuracy: 0.7447 - 280ms/epoch - 8ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4109 - accuracy: 0.8075 - val_loss: 0.4910 - val_accuracy: 0.7376 - 264ms/epoch - 7ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4106 - accuracy: 0.8128 - val_loss: 0.4907 - val_accuracy: 0.7376 - 297ms/epoch - 8ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4099 - accuracy: 0.8093 - val_loss: 0.4903 - val_accuracy: 0.7376 - 283ms/epoch - 8ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4094 - accuracy: 0.8111 - val_loss: 0.4893 - val_accuracy: 0.7376 - 282ms/epoch - 8ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4092 - accuracy: 0.8093 - val_loss: 0.4889 - val_accuracy: 0.7518 - 265ms/epoch - 7ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4083 - accuracy: 0.8111 - val_loss: 0.4887 - val_accuracy: 0.7589 - 283ms/epoch - 8ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4078 - accuracy: 0.8039 - val_loss: 0.4891 - val_accuracy: 0.7589 - 281ms/epoch - 8ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4075 - accuracy: 0.8075 - val_loss: 0.4885 - val_accuracy: 0.7589 - 249ms/epoch - 7ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4071 - accuracy: 0.8111 - val_loss: 0.4885 - val_accuracy: 0.7447 - 281ms/epoch - 8ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4077 - accuracy: 0.8093 - val_loss: 0.4883 - val_accuracy: 0.7447 - 291ms/epoch - 8ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4064 - accuracy: 0.8128 - val_loss: 0.4878 - val_accuracy: 0.7447 - 254ms/epoch - 7ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4065 - accuracy: 0.8111 - val_loss: 0.4883 - val_accuracy: 0.7518 - 256ms/epoch - 7ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4056 - accuracy: 0.8093 - val_loss: 0.4874 - val_accuracy: 0.7518 - 274ms/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4057 - accuracy: 0.8075 - val_loss: 0.4878 - val_accuracy: 0.7518 - 258ms/epoch - 7ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4054 - accuracy: 0.8093 - val_loss: 0.4875 - val_accuracy: 0.7447 - 274ms/epoch - 8ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4051 - accuracy: 0.8146 - val_loss: 0.4859 - val_accuracy: 0.7376 - 272ms/epoch - 8ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4041 - accuracy: 0.8128 - val_loss: 0.4856 - val_accuracy: 0.7305 - 252ms/epoch - 7ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4041 - accuracy: 0.8111 - val_loss: 0.4855 - val_accuracy: 0.7305 - 292ms/epoch - 8ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4040 - accuracy: 0.8111 - val_loss: 0.4847 - val_accuracy: 0.7305 - 267ms/epoch - 7ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4038 - accuracy: 0.8128 - val_loss: 0.4847 - val_accuracy: 0.7305 - 244ms/epoch - 7ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4032 - accuracy: 0.8111 - val_loss: 0.4841 - val_accuracy: 0.7305 - 252ms/epoch - 7ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.4029 - accuracy: 0.8111 - val_loss: 0.4842 - val_accuracy: 0.7305 - 251ms/epoch - 7ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4026 - accuracy: 0.8111 - val_loss: 0.4839 - val_accuracy: 0.7305 - 260ms/epoch - 7ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.4024 - accuracy: 0.8075 - val_loss: 0.4835 - val_accuracy: 0.7305 - 263ms/epoch - 7ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4020 - accuracy: 0.8111 - val_loss: 0.4827 - val_accuracy: 0.7305 - 245ms/epoch - 7ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.4018 - accuracy: 0.8111 - val_loss: 0.4826 - val_accuracy: 0.7305 - 266ms/epoch - 7ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.4014 - accuracy: 0.8111 - val_loss: 0.4824 - val_accuracy: 0.7305 - 256ms/epoch - 7ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.4013 - accuracy: 0.8128 - val_loss: 0.4825 - val_accuracy: 0.7447 - 284ms/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.4011 - accuracy: 0.8146 - val_loss: 0.4821 - val_accuracy: 0.7376 - 289ms/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.4009 - accuracy: 0.8146 - val_loss: 0.4819 - val_accuracy: 0.7376 - 259ms/epoch - 7ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.4007 - accuracy: 0.8128 - val_loss: 0.4814 - val_accuracy: 0.7305 - 255ms/epoch - 7ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.4002 - accuracy: 0.8146 - val_loss: 0.4811 - val_accuracy: 0.7305 - 242ms/epoch - 7ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3999 - accuracy: 0.8164 - val_loss: 0.4811 - val_accuracy: 0.7234 - 241ms/epoch - 7ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3997 - accuracy: 0.8146 - val_loss: 0.4807 - val_accuracy: 0.7305 - 250ms/epoch - 7ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3995 - accuracy: 0.8128 - val_loss: 0.4802 - val_accuracy: 0.7305 - 257ms/epoch - 7ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3997 - accuracy: 0.8164 - val_loss: 0.4807 - val_accuracy: 0.7447 - 243ms/epoch - 7ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.4002 - accuracy: 0.8164 - val_loss: 0.4807 - val_accuracy: 0.7447 - 265ms/epoch - 7ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3993 - accuracy: 0.8146 - val_loss: 0.4800 - val_accuracy: 0.7305 - 258ms/epoch - 7ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3991 - accuracy: 0.8128 - val_loss: 0.4798 - val_accuracy: 0.7305 - 241ms/epoch - 7ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3989 - accuracy: 0.8093 - val_loss: 0.4794 - val_accuracy: 0.7305 - 245ms/epoch - 7ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3985 - accuracy: 0.8128 - val_loss: 0.4794 - val_accuracy: 0.7234 - 255ms/epoch - 7ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3987 - accuracy: 0.8111 - val_loss: 0.4792 - val_accuracy: 0.7305 - 280ms/epoch - 8ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3985 - accuracy: 0.8093 - val_loss: 0.4792 - val_accuracy: 0.7305 - 251ms/epoch - 7ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3980 - accuracy: 0.8128 - val_loss: 0.4790 - val_accuracy: 0.7305 - 240ms/epoch - 7ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3979 - accuracy: 0.8128 - val_loss: 0.4788 - val_accuracy: 0.7305 - 258ms/epoch - 7ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3980 - accuracy: 0.8128 - val_loss: 0.4786 - val_accuracy: 0.7305 - 251ms/epoch - 7ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8111 - val_loss: 0.4782 - val_accuracy: 0.7305 - 254ms/epoch - 7ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3974 - accuracy: 0.8128 - val_loss: 0.4781 - val_accuracy: 0.7376 - 249ms/epoch - 7ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3970 - accuracy: 0.8128 - val_loss: 0.4779 - val_accuracy: 0.7305 - 261ms/epoch - 7ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3971 - accuracy: 0.8128 - val_loss: 0.4778 - val_accuracy: 0.7305 - 246ms/epoch - 7ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3969 - accuracy: 0.8128 - val_loss: 0.4778 - val_accuracy: 0.7305 - 235ms/epoch - 7ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3969 - accuracy: 0.8111 - val_loss: 0.4772 - val_accuracy: 0.7305 - 253ms/epoch - 7ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3970 - accuracy: 0.8164 - val_loss: 0.4783 - val_accuracy: 0.7376 - 246ms/epoch - 7ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3967 - accuracy: 0.8182 - val_loss: 0.4777 - val_accuracy: 0.7376 - 292ms/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8146 - val_loss: 0.4773 - val_accuracy: 0.7305 - 277ms/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3962 - accuracy: 0.8164 - val_loss: 0.4773 - val_accuracy: 0.7305 - 254ms/epoch - 7ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8164 - val_loss: 0.4772 - val_accuracy: 0.7305 - 248ms/epoch - 7ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8128 - val_loss: 0.4771 - val_accuracy: 0.7376 - 249ms/epoch - 7ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3956 - accuracy: 0.8128 - val_loss: 0.4765 - val_accuracy: 0.7376 - 280ms/epoch - 8ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3957 - accuracy: 0.8146 - val_loss: 0.4764 - val_accuracy: 0.7376 - 286ms/epoch - 8ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3955 - accuracy: 0.8128 - val_loss: 0.4764 - val_accuracy: 0.7376 - 292ms/epoch - 8ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3955 - accuracy: 0.8146 - val_loss: 0.4765 - val_accuracy: 0.7376 - 275ms/epoch - 8ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8164 - val_loss: 0.4778 - val_accuracy: 0.7376 - 278ms/epoch - 8ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3954 - accuracy: 0.8164 - val_loss: 0.4775 - val_accuracy: 0.7376 - 262ms/epoch - 7ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3953 - accuracy: 0.8164 - val_loss: 0.4780 - val_accuracy: 0.7376 - 268ms/epoch - 7ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8128 - val_loss: 0.4773 - val_accuracy: 0.7376 - 270ms/epoch - 8ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3950 - accuracy: 0.8146 - val_loss: 0.4772 - val_accuracy: 0.7376 - 258ms/epoch - 7ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8146 - val_loss: 0.4771 - val_accuracy: 0.7376 - 278ms/epoch - 8ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3947 - accuracy: 0.8128 - val_loss: 0.4769 - val_accuracy: 0.7376 - 269ms/epoch - 7ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3947 - accuracy: 0.8182 - val_loss: 0.4767 - val_accuracy: 0.7305 - 275ms/epoch - 8ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3946 - accuracy: 0.8164 - val_loss: 0.4767 - val_accuracy: 0.7305 - 259ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3947 - accuracy: 0.8182 - val_loss: 0.4771 - val_accuracy: 0.7305 - 263ms/epoch - 7ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3949 - accuracy: 0.8182 - val_loss: 0.4767 - val_accuracy: 0.7305 - 263ms/epoch - 7ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8182 - val_loss: 0.4765 - val_accuracy: 0.7305 - 263ms/epoch - 7ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3942 - accuracy: 0.8164 - val_loss: 0.4766 - val_accuracy: 0.7234 - 274ms/epoch - 8ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3940 - accuracy: 0.8146 - val_loss: 0.4765 - val_accuracy: 0.7305 - 263ms/epoch - 7ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3942 - accuracy: 0.8146 - val_loss: 0.4776 - val_accuracy: 0.7376 - 263ms/epoch - 7ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3937 - accuracy: 0.8164 - val_loss: 0.4770 - val_accuracy: 0.7305 - 254ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "history_base = model_base.fit(x=X_train_base, y=y_train_base, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_per = model_per.fit(x=X_train_per, y=y_train_per, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_mdi = model_mdi.fit(x=X_train_mdi, y=y_train_mdi, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Testdata using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "---------Base-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------Permutation-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------MDI-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[137,   0],\n",
       "       [164,   0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_base = model_base.predict(X_test_base)\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "\n",
    "print(\"---------Base-Prediction----------\")\n",
    "evaluate_classification_result(y_test_base,pred_base,classes=nn_data_base[\"target_names\"])\n",
    "print(\"---------Permutation-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_per,pred_per,classes=nn_data_per[\"target_names\"])\n",
    "print(\"---------MDI-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_mdi,pred_mdi,classes=nn_data_mdi[\"target_names\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_base = model_base.predict(X_test_base)\n",
    "classes_base = [1 if i > 0.5  else 0 for i in pred_base]\n",
    "\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "classes_per = [1 if i > 0.5  else 0 for i in pred_per]\n",
    "\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "classes_mdi = [1 if i > 0.5  else 0 for i in pred_mdi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_per.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_per):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_per\n",
    "result_df[\"PRED\"] = classes_per\n",
    "\n",
    "result_df.to_csv(result_dir+\"ACHE/fe_rf_per_nn.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_mdi.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_mdi):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_mdi\n",
    "result_df[\"PRED\"] = classes_mdi\n",
    "\n",
    "result_df.to_csv(result_dir+\"ACHE/fe_rf_mdi_nn.csv\",encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activity_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
