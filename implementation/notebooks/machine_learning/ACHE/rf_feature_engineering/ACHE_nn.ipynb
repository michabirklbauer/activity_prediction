{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from pyMLaux import plot_history, evaluate_classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/bac/activity_prediction/implementation/'\n",
    "data_dir = base_dir + 'data/source/'\n",
    "result_dir = base_dir + 'data/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load & prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code needs to be adapted for each protein-ligand complex individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data_raw_mdi = pd.read_csv(data_dir+\"ACHE/ache_mdi.csv\")\n",
    "nn_data_raw_per = pd.read_csv(data_dir+\"ACHE/ache_per.csv\")\n",
    "nn_data_raw = pd.read_csv(data_dir+\"ACHE/ache.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {'inactive':0,'active':1}\n",
    "\n",
    "nn_data_per = {'data': np.array(nn_data_raw_per.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_per.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_per.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_mdi = {'data': np.array(nn_data_raw_mdi.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_mdi.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_mdi.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_base = {'data': np.array(nn_data_raw.iloc[:, 2:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw.columns[2:-1],\n",
    "             'target_names': ['inactive', 'active']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train- and test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(nn_data_base['data'], nn_data_base['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_mdi, X_test_mdi, y_train_mdi, y_test_mdi = train_test_split(nn_data_mdi['data'], nn_data_mdi['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_per, X_test_per, y_train_per, y_test_per = train_test_split(nn_data_per['data'], nn_data_per['target'],\n",
    "                                                    test_size=0.3, random_state=4232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and apply neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_base['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_base.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_per = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_per['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_per.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_mdi = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_mdi['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_mdi.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 3s - loss: 0.7807 - accuracy: 0.4207 - val_loss: 0.7560 - val_accuracy: 0.4255 - 3s/epoch - 80ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 1s - loss: 0.7254 - accuracy: 0.4706 - val_loss: 0.7238 - val_accuracy: 0.4823 - 903ms/epoch - 25ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 1s - loss: 0.6897 - accuracy: 0.5330 - val_loss: 0.6998 - val_accuracy: 0.5106 - 800ms/epoch - 22ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 1s - loss: 0.6607 - accuracy: 0.6096 - val_loss: 0.6796 - val_accuracy: 0.5745 - 744ms/epoch - 21ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 1s - loss: 0.6362 - accuracy: 0.6738 - val_loss: 0.6624 - val_accuracy: 0.6170 - 750ms/epoch - 21ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 1s - loss: 0.6163 - accuracy: 0.7041 - val_loss: 0.6486 - val_accuracy: 0.6525 - 855ms/epoch - 24ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 1s - loss: 0.5996 - accuracy: 0.7184 - val_loss: 0.6361 - val_accuracy: 0.6596 - 809ms/epoch - 22ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 1s - loss: 0.5830 - accuracy: 0.7469 - val_loss: 0.6218 - val_accuracy: 0.6667 - 771ms/epoch - 21ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 1s - loss: 0.5680 - accuracy: 0.7540 - val_loss: 0.6105 - val_accuracy: 0.6667 - 803ms/epoch - 22ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 1s - loss: 0.5558 - accuracy: 0.7665 - val_loss: 0.6011 - val_accuracy: 0.6879 - 707ms/epoch - 20ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 1s - loss: 0.5432 - accuracy: 0.7701 - val_loss: 0.5908 - val_accuracy: 0.7092 - 715ms/epoch - 20ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 1s - loss: 0.5327 - accuracy: 0.7772 - val_loss: 0.5825 - val_accuracy: 0.7092 - 815ms/epoch - 23ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 1s - loss: 0.5227 - accuracy: 0.7772 - val_loss: 0.5757 - val_accuracy: 0.7092 - 843ms/epoch - 23ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 1s - loss: 0.5142 - accuracy: 0.7772 - val_loss: 0.5684 - val_accuracy: 0.7163 - 752ms/epoch - 21ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 1s - loss: 0.5065 - accuracy: 0.7843 - val_loss: 0.5627 - val_accuracy: 0.7163 - 777ms/epoch - 22ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 1s - loss: 0.4989 - accuracy: 0.7897 - val_loss: 0.5573 - val_accuracy: 0.7234 - 822ms/epoch - 23ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 1s - loss: 0.4923 - accuracy: 0.7879 - val_loss: 0.5515 - val_accuracy: 0.7234 - 790ms/epoch - 22ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 1s - loss: 0.4856 - accuracy: 0.7914 - val_loss: 0.5465 - val_accuracy: 0.7163 - 759ms/epoch - 21ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 1s - loss: 0.4798 - accuracy: 0.7968 - val_loss: 0.5417 - val_accuracy: 0.7163 - 776ms/epoch - 22ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 1s - loss: 0.4746 - accuracy: 0.8004 - val_loss: 0.5374 - val_accuracy: 0.7163 - 722ms/epoch - 20ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 1s - loss: 0.4693 - accuracy: 0.7950 - val_loss: 0.5339 - val_accuracy: 0.7163 - 734ms/epoch - 20ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 1s - loss: 0.4654 - accuracy: 0.8021 - val_loss: 0.5292 - val_accuracy: 0.7163 - 762ms/epoch - 21ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 1s - loss: 0.4611 - accuracy: 0.8057 - val_loss: 0.5258 - val_accuracy: 0.7163 - 753ms/epoch - 21ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 1s - loss: 0.4569 - accuracy: 0.8057 - val_loss: 0.5227 - val_accuracy: 0.7163 - 753ms/epoch - 21ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 1s - loss: 0.4528 - accuracy: 0.8146 - val_loss: 0.5188 - val_accuracy: 0.7376 - 752ms/epoch - 21ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 1s - loss: 0.4491 - accuracy: 0.8128 - val_loss: 0.5163 - val_accuracy: 0.7447 - 759ms/epoch - 21ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 1s - loss: 0.4457 - accuracy: 0.8146 - val_loss: 0.5137 - val_accuracy: 0.7447 - 692ms/epoch - 19ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 1s - loss: 0.4427 - accuracy: 0.8164 - val_loss: 0.5110 - val_accuracy: 0.7376 - 806ms/epoch - 22ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 1s - loss: 0.4393 - accuracy: 0.8164 - val_loss: 0.5089 - val_accuracy: 0.7447 - 690ms/epoch - 19ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 1s - loss: 0.4370 - accuracy: 0.8217 - val_loss: 0.5066 - val_accuracy: 0.7376 - 785ms/epoch - 22ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 1s - loss: 0.4337 - accuracy: 0.8235 - val_loss: 0.5045 - val_accuracy: 0.7447 - 887ms/epoch - 25ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 1s - loss: 0.4314 - accuracy: 0.8235 - val_loss: 0.5028 - val_accuracy: 0.7447 - 853ms/epoch - 24ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 1s - loss: 0.4287 - accuracy: 0.8217 - val_loss: 0.5008 - val_accuracy: 0.7589 - 807ms/epoch - 22ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 1s - loss: 0.4262 - accuracy: 0.8253 - val_loss: 0.4986 - val_accuracy: 0.7518 - 644ms/epoch - 18ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 1s - loss: 0.4242 - accuracy: 0.8235 - val_loss: 0.4972 - val_accuracy: 0.7447 - 618ms/epoch - 17ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 1s - loss: 0.4216 - accuracy: 0.8289 - val_loss: 0.4955 - val_accuracy: 0.7518 - 584ms/epoch - 16ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4197 - accuracy: 0.8253 - val_loss: 0.4939 - val_accuracy: 0.7589 - 478ms/epoch - 13ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4178 - accuracy: 0.8235 - val_loss: 0.4931 - val_accuracy: 0.7518 - 385ms/epoch - 11ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4162 - accuracy: 0.8253 - val_loss: 0.4914 - val_accuracy: 0.7518 - 349ms/epoch - 10ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4138 - accuracy: 0.8307 - val_loss: 0.4897 - val_accuracy: 0.7589 - 324ms/epoch - 9ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4125 - accuracy: 0.8253 - val_loss: 0.4886 - val_accuracy: 0.7589 - 315ms/epoch - 9ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4103 - accuracy: 0.8307 - val_loss: 0.4869 - val_accuracy: 0.7518 - 309ms/epoch - 9ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4089 - accuracy: 0.8324 - val_loss: 0.4859 - val_accuracy: 0.7589 - 327ms/epoch - 9ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4069 - accuracy: 0.8324 - val_loss: 0.4844 - val_accuracy: 0.7589 - 345ms/epoch - 10ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4054 - accuracy: 0.8342 - val_loss: 0.4834 - val_accuracy: 0.7589 - 359ms/epoch - 10ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4045 - accuracy: 0.8307 - val_loss: 0.4816 - val_accuracy: 0.7589 - 340ms/epoch - 9ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4027 - accuracy: 0.8360 - val_loss: 0.4803 - val_accuracy: 0.7589 - 321ms/epoch - 9ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4012 - accuracy: 0.8360 - val_loss: 0.4794 - val_accuracy: 0.7589 - 304ms/epoch - 8ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4000 - accuracy: 0.8396 - val_loss: 0.4792 - val_accuracy: 0.7589 - 285ms/epoch - 8ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.3990 - accuracy: 0.8378 - val_loss: 0.4781 - val_accuracy: 0.7589 - 318ms/epoch - 9ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8342 - val_loss: 0.4772 - val_accuracy: 0.7589 - 311ms/epoch - 9ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8414 - val_loss: 0.4762 - val_accuracy: 0.7589 - 286ms/epoch - 8ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.3953 - accuracy: 0.8396 - val_loss: 0.4754 - val_accuracy: 0.7589 - 264ms/epoch - 7ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.3940 - accuracy: 0.8378 - val_loss: 0.4749 - val_accuracy: 0.7518 - 254ms/epoch - 7ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.3928 - accuracy: 0.8396 - val_loss: 0.4741 - val_accuracy: 0.7589 - 287ms/epoch - 8ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.3916 - accuracy: 0.8414 - val_loss: 0.4732 - val_accuracy: 0.7660 - 274ms/epoch - 8ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.3905 - accuracy: 0.8378 - val_loss: 0.4723 - val_accuracy: 0.7660 - 302ms/epoch - 8ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.3895 - accuracy: 0.8378 - val_loss: 0.4709 - val_accuracy: 0.7660 - 271ms/epoch - 8ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.3887 - accuracy: 0.8378 - val_loss: 0.4705 - val_accuracy: 0.7660 - 269ms/epoch - 7ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.3874 - accuracy: 0.8396 - val_loss: 0.4689 - val_accuracy: 0.7589 - 315ms/epoch - 9ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.3866 - accuracy: 0.8414 - val_loss: 0.4675 - val_accuracy: 0.7660 - 270ms/epoch - 7ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.3858 - accuracy: 0.8414 - val_loss: 0.4676 - val_accuracy: 0.7589 - 279ms/epoch - 8ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.3847 - accuracy: 0.8396 - val_loss: 0.4669 - val_accuracy: 0.7589 - 280ms/epoch - 8ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.3838 - accuracy: 0.8396 - val_loss: 0.4669 - val_accuracy: 0.7589 - 288ms/epoch - 8ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.3831 - accuracy: 0.8414 - val_loss: 0.4664 - val_accuracy: 0.7589 - 247ms/epoch - 7ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.3821 - accuracy: 0.8414 - val_loss: 0.4661 - val_accuracy: 0.7589 - 260ms/epoch - 7ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.3813 - accuracy: 0.8449 - val_loss: 0.4657 - val_accuracy: 0.7589 - 251ms/epoch - 7ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.3801 - accuracy: 0.8449 - val_loss: 0.4652 - val_accuracy: 0.7589 - 269ms/epoch - 7ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.3794 - accuracy: 0.8431 - val_loss: 0.4647 - val_accuracy: 0.7589 - 264ms/epoch - 7ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.3786 - accuracy: 0.8467 - val_loss: 0.4639 - val_accuracy: 0.7589 - 285ms/epoch - 8ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.3781 - accuracy: 0.8449 - val_loss: 0.4622 - val_accuracy: 0.7589 - 267ms/epoch - 7ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.3769 - accuracy: 0.8467 - val_loss: 0.4623 - val_accuracy: 0.7660 - 268ms/epoch - 7ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.3764 - accuracy: 0.8467 - val_loss: 0.4619 - val_accuracy: 0.7730 - 270ms/epoch - 7ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.3756 - accuracy: 0.8467 - val_loss: 0.4613 - val_accuracy: 0.7660 - 269ms/epoch - 7ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.3749 - accuracy: 0.8449 - val_loss: 0.4613 - val_accuracy: 0.7660 - 268ms/epoch - 7ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.3743 - accuracy: 0.8449 - val_loss: 0.4611 - val_accuracy: 0.7589 - 246ms/epoch - 7ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.3736 - accuracy: 0.8431 - val_loss: 0.4607 - val_accuracy: 0.7589 - 260ms/epoch - 7ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.3728 - accuracy: 0.8485 - val_loss: 0.4605 - val_accuracy: 0.7730 - 258ms/epoch - 7ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.3722 - accuracy: 0.8467 - val_loss: 0.4603 - val_accuracy: 0.7730 - 288ms/epoch - 8ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.3713 - accuracy: 0.8467 - val_loss: 0.4596 - val_accuracy: 0.7730 - 266ms/epoch - 7ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.3707 - accuracy: 0.8485 - val_loss: 0.4593 - val_accuracy: 0.7730 - 260ms/epoch - 7ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.3701 - accuracy: 0.8467 - val_loss: 0.4593 - val_accuracy: 0.7730 - 264ms/epoch - 7ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.3693 - accuracy: 0.8467 - val_loss: 0.4586 - val_accuracy: 0.7730 - 248ms/epoch - 7ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.3690 - accuracy: 0.8485 - val_loss: 0.4585 - val_accuracy: 0.7730 - 268ms/epoch - 7ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.3685 - accuracy: 0.8503 - val_loss: 0.4581 - val_accuracy: 0.7589 - 292ms/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.3677 - accuracy: 0.8520 - val_loss: 0.4580 - val_accuracy: 0.7589 - 238ms/epoch - 7ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.3672 - accuracy: 0.8520 - val_loss: 0.4581 - val_accuracy: 0.7660 - 237ms/epoch - 7ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.3667 - accuracy: 0.8538 - val_loss: 0.4577 - val_accuracy: 0.7660 - 261ms/epoch - 7ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.3660 - accuracy: 0.8503 - val_loss: 0.4567 - val_accuracy: 0.7660 - 256ms/epoch - 7ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.3656 - accuracy: 0.8485 - val_loss: 0.4562 - val_accuracy: 0.7660 - 260ms/epoch - 7ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.3652 - accuracy: 0.8538 - val_loss: 0.4556 - val_accuracy: 0.7660 - 251ms/epoch - 7ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.3641 - accuracy: 0.8485 - val_loss: 0.4561 - val_accuracy: 0.7660 - 251ms/epoch - 7ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.3640 - accuracy: 0.8485 - val_loss: 0.4560 - val_accuracy: 0.7730 - 248ms/epoch - 7ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.3636 - accuracy: 0.8485 - val_loss: 0.4556 - val_accuracy: 0.7660 - 243ms/epoch - 7ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.3627 - accuracy: 0.8503 - val_loss: 0.4555 - val_accuracy: 0.7660 - 261ms/epoch - 7ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.3622 - accuracy: 0.8538 - val_loss: 0.4554 - val_accuracy: 0.7660 - 254ms/epoch - 7ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.3618 - accuracy: 0.8538 - val_loss: 0.4548 - val_accuracy: 0.7660 - 237ms/epoch - 7ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.3613 - accuracy: 0.8538 - val_loss: 0.4549 - val_accuracy: 0.7660 - 247ms/epoch - 7ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.3605 - accuracy: 0.8520 - val_loss: 0.4551 - val_accuracy: 0.7660 - 252ms/epoch - 7ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.3600 - accuracy: 0.8467 - val_loss: 0.4556 - val_accuracy: 0.7660 - 272ms/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.3598 - accuracy: 0.8449 - val_loss: 0.4551 - val_accuracy: 0.7660 - 272ms/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.3591 - accuracy: 0.8485 - val_loss: 0.4548 - val_accuracy: 0.7660 - 264ms/epoch - 7ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.3588 - accuracy: 0.8485 - val_loss: 0.4556 - val_accuracy: 0.7660 - 266ms/epoch - 7ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.3580 - accuracy: 0.8538 - val_loss: 0.4543 - val_accuracy: 0.7660 - 250ms/epoch - 7ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3580 - accuracy: 0.8538 - val_loss: 0.4544 - val_accuracy: 0.7660 - 278ms/epoch - 8ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3571 - accuracy: 0.8503 - val_loss: 0.4547 - val_accuracy: 0.7660 - 250ms/epoch - 7ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3568 - accuracy: 0.8485 - val_loss: 0.4544 - val_accuracy: 0.7660 - 257ms/epoch - 7ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3564 - accuracy: 0.8520 - val_loss: 0.4542 - val_accuracy: 0.7660 - 238ms/epoch - 7ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3558 - accuracy: 0.8538 - val_loss: 0.4533 - val_accuracy: 0.7660 - 250ms/epoch - 7ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3557 - accuracy: 0.8538 - val_loss: 0.4531 - val_accuracy: 0.7660 - 299ms/epoch - 8ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3553 - accuracy: 0.8520 - val_loss: 0.4528 - val_accuracy: 0.7589 - 286ms/epoch - 8ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3549 - accuracy: 0.8503 - val_loss: 0.4528 - val_accuracy: 0.7660 - 288ms/epoch - 8ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3541 - accuracy: 0.8538 - val_loss: 0.4526 - val_accuracy: 0.7660 - 319ms/epoch - 9ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3536 - accuracy: 0.8538 - val_loss: 0.4531 - val_accuracy: 0.7589 - 317ms/epoch - 9ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3533 - accuracy: 0.8538 - val_loss: 0.4532 - val_accuracy: 0.7660 - 396ms/epoch - 11ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3530 - accuracy: 0.8503 - val_loss: 0.4525 - val_accuracy: 0.7589 - 374ms/epoch - 10ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3529 - accuracy: 0.8503 - val_loss: 0.4522 - val_accuracy: 0.7589 - 259ms/epoch - 7ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3523 - accuracy: 0.8538 - val_loss: 0.4525 - val_accuracy: 0.7660 - 261ms/epoch - 7ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3518 - accuracy: 0.8538 - val_loss: 0.4525 - val_accuracy: 0.7589 - 249ms/epoch - 7ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3514 - accuracy: 0.8520 - val_loss: 0.4529 - val_accuracy: 0.7589 - 268ms/epoch - 7ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3511 - accuracy: 0.8520 - val_loss: 0.4534 - val_accuracy: 0.7660 - 275ms/epoch - 8ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3511 - accuracy: 0.8485 - val_loss: 0.4542 - val_accuracy: 0.7730 - 251ms/epoch - 7ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3508 - accuracy: 0.8449 - val_loss: 0.4561 - val_accuracy: 0.7730 - 243ms/epoch - 7ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3506 - accuracy: 0.8449 - val_loss: 0.4553 - val_accuracy: 0.7730 - 295ms/epoch - 8ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3502 - accuracy: 0.8467 - val_loss: 0.4549 - val_accuracy: 0.7730 - 245ms/epoch - 7ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3492 - accuracy: 0.8520 - val_loss: 0.4536 - val_accuracy: 0.7518 - 229ms/epoch - 6ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3488 - accuracy: 0.8538 - val_loss: 0.4538 - val_accuracy: 0.7589 - 270ms/epoch - 7ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3485 - accuracy: 0.8556 - val_loss: 0.4536 - val_accuracy: 0.7518 - 249ms/epoch - 7ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3486 - accuracy: 0.8538 - val_loss: 0.4529 - val_accuracy: 0.7518 - 254ms/epoch - 7ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3479 - accuracy: 0.8556 - val_loss: 0.4523 - val_accuracy: 0.7518 - 251ms/epoch - 7ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3479 - accuracy: 0.8538 - val_loss: 0.4524 - val_accuracy: 0.7660 - 289ms/epoch - 8ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3473 - accuracy: 0.8538 - val_loss: 0.4516 - val_accuracy: 0.7518 - 258ms/epoch - 7ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3477 - accuracy: 0.8485 - val_loss: 0.4509 - val_accuracy: 0.7589 - 252ms/epoch - 7ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3469 - accuracy: 0.8520 - val_loss: 0.4515 - val_accuracy: 0.7518 - 265ms/epoch - 7ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3467 - accuracy: 0.8485 - val_loss: 0.4527 - val_accuracy: 0.7660 - 248ms/epoch - 7ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3464 - accuracy: 0.8520 - val_loss: 0.4526 - val_accuracy: 0.7660 - 256ms/epoch - 7ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3460 - accuracy: 0.8503 - val_loss: 0.4526 - val_accuracy: 0.7660 - 255ms/epoch - 7ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3458 - accuracy: 0.8503 - val_loss: 0.4524 - val_accuracy: 0.7660 - 252ms/epoch - 7ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3451 - accuracy: 0.8538 - val_loss: 0.4511 - val_accuracy: 0.7518 - 248ms/epoch - 7ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3448 - accuracy: 0.8520 - val_loss: 0.4518 - val_accuracy: 0.7660 - 247ms/epoch - 7ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3446 - accuracy: 0.8538 - val_loss: 0.4515 - val_accuracy: 0.7518 - 251ms/epoch - 7ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3441 - accuracy: 0.8520 - val_loss: 0.4510 - val_accuracy: 0.7518 - 242ms/epoch - 7ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3439 - accuracy: 0.8520 - val_loss: 0.4509 - val_accuracy: 0.7518 - 231ms/epoch - 6ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3440 - accuracy: 0.8503 - val_loss: 0.4516 - val_accuracy: 0.7660 - 237ms/epoch - 7ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3434 - accuracy: 0.8520 - val_loss: 0.4507 - val_accuracy: 0.7589 - 235ms/epoch - 7ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3430 - accuracy: 0.8520 - val_loss: 0.4516 - val_accuracy: 0.7589 - 250ms/epoch - 7ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3429 - accuracy: 0.8503 - val_loss: 0.4516 - val_accuracy: 0.7589 - 272ms/epoch - 8ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3426 - accuracy: 0.8538 - val_loss: 0.4519 - val_accuracy: 0.7589 - 287ms/epoch - 8ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3422 - accuracy: 0.8520 - val_loss: 0.4511 - val_accuracy: 0.7589 - 255ms/epoch - 7ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3418 - accuracy: 0.8503 - val_loss: 0.4512 - val_accuracy: 0.7589 - 250ms/epoch - 7ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 0.8070 - accuracy: 0.4385 - val_loss: 0.7857 - val_accuracy: 0.4043 - 671ms/epoch - 19ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.7747 - accuracy: 0.4563 - val_loss: 0.7597 - val_accuracy: 0.4397 - 269ms/epoch - 7ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.7463 - accuracy: 0.4920 - val_loss: 0.7376 - val_accuracy: 0.4610 - 257ms/epoch - 7ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.7206 - accuracy: 0.5241 - val_loss: 0.7184 - val_accuracy: 0.5035 - 305ms/epoch - 8ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.6970 - accuracy: 0.5508 - val_loss: 0.7003 - val_accuracy: 0.5390 - 291ms/epoch - 8ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.6766 - accuracy: 0.5793 - val_loss: 0.6847 - val_accuracy: 0.5603 - 279ms/epoch - 8ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.6574 - accuracy: 0.6007 - val_loss: 0.6695 - val_accuracy: 0.6099 - 258ms/epoch - 7ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.6398 - accuracy: 0.6310 - val_loss: 0.6560 - val_accuracy: 0.6383 - 256ms/epoch - 7ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.6235 - accuracy: 0.6524 - val_loss: 0.6440 - val_accuracy: 0.6596 - 250ms/epoch - 7ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.6087 - accuracy: 0.6667 - val_loss: 0.6331 - val_accuracy: 0.6667 - 257ms/epoch - 7ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5949 - accuracy: 0.6827 - val_loss: 0.6229 - val_accuracy: 0.6950 - 273ms/epoch - 8ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5820 - accuracy: 0.7112 - val_loss: 0.6133 - val_accuracy: 0.7021 - 257ms/epoch - 7ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5701 - accuracy: 0.7291 - val_loss: 0.6045 - val_accuracy: 0.7092 - 254ms/epoch - 7ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5596 - accuracy: 0.7433 - val_loss: 0.5965 - val_accuracy: 0.7021 - 230ms/epoch - 6ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5497 - accuracy: 0.7487 - val_loss: 0.5887 - val_accuracy: 0.7092 - 237ms/epoch - 7ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.5404 - accuracy: 0.7594 - val_loss: 0.5819 - val_accuracy: 0.6950 - 248ms/epoch - 7ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.5318 - accuracy: 0.7683 - val_loss: 0.5754 - val_accuracy: 0.7163 - 275ms/epoch - 8ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.5240 - accuracy: 0.7701 - val_loss: 0.5695 - val_accuracy: 0.7092 - 262ms/epoch - 7ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.5163 - accuracy: 0.7807 - val_loss: 0.5640 - val_accuracy: 0.7234 - 272ms/epoch - 8ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.5094 - accuracy: 0.7861 - val_loss: 0.5590 - val_accuracy: 0.7163 - 276ms/epoch - 8ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.5031 - accuracy: 0.7879 - val_loss: 0.5540 - val_accuracy: 0.7376 - 260ms/epoch - 7ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4973 - accuracy: 0.7914 - val_loss: 0.5495 - val_accuracy: 0.7376 - 258ms/epoch - 7ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4923 - accuracy: 0.7968 - val_loss: 0.5454 - val_accuracy: 0.7376 - 268ms/epoch - 7ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4867 - accuracy: 0.7986 - val_loss: 0.5413 - val_accuracy: 0.7376 - 272ms/epoch - 8ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4820 - accuracy: 0.8004 - val_loss: 0.5377 - val_accuracy: 0.7376 - 250ms/epoch - 7ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4775 - accuracy: 0.8093 - val_loss: 0.5342 - val_accuracy: 0.7518 - 256ms/epoch - 7ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4733 - accuracy: 0.8093 - val_loss: 0.5313 - val_accuracy: 0.7518 - 274ms/epoch - 8ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4696 - accuracy: 0.8075 - val_loss: 0.5284 - val_accuracy: 0.7447 - 260ms/epoch - 7ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4659 - accuracy: 0.8093 - val_loss: 0.5259 - val_accuracy: 0.7518 - 277ms/epoch - 8ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4621 - accuracy: 0.8128 - val_loss: 0.5227 - val_accuracy: 0.7447 - 246ms/epoch - 7ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4589 - accuracy: 0.8128 - val_loss: 0.5205 - val_accuracy: 0.7447 - 255ms/epoch - 7ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4560 - accuracy: 0.8146 - val_loss: 0.5178 - val_accuracy: 0.7447 - 303ms/epoch - 8ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4538 - accuracy: 0.8146 - val_loss: 0.5172 - val_accuracy: 0.7518 - 281ms/epoch - 8ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4516 - accuracy: 0.8128 - val_loss: 0.5147 - val_accuracy: 0.7518 - 269ms/epoch - 7ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4484 - accuracy: 0.8182 - val_loss: 0.5131 - val_accuracy: 0.7518 - 276ms/epoch - 8ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4459 - accuracy: 0.8182 - val_loss: 0.5107 - val_accuracy: 0.7589 - 273ms/epoch - 8ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4437 - accuracy: 0.8182 - val_loss: 0.5095 - val_accuracy: 0.7589 - 277ms/epoch - 8ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4425 - accuracy: 0.8164 - val_loss: 0.5078 - val_accuracy: 0.7518 - 278ms/epoch - 8ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4397 - accuracy: 0.8182 - val_loss: 0.5061 - val_accuracy: 0.7589 - 295ms/epoch - 8ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4378 - accuracy: 0.8164 - val_loss: 0.5047 - val_accuracy: 0.7589 - 274ms/epoch - 8ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4359 - accuracy: 0.8200 - val_loss: 0.5029 - val_accuracy: 0.7589 - 284ms/epoch - 8ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4342 - accuracy: 0.8182 - val_loss: 0.5015 - val_accuracy: 0.7518 - 295ms/epoch - 8ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4326 - accuracy: 0.8217 - val_loss: 0.5003 - val_accuracy: 0.7660 - 278ms/epoch - 8ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4313 - accuracy: 0.8217 - val_loss: 0.4990 - val_accuracy: 0.7518 - 289ms/epoch - 8ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4298 - accuracy: 0.8182 - val_loss: 0.4988 - val_accuracy: 0.7660 - 286ms/epoch - 8ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4280 - accuracy: 0.8271 - val_loss: 0.4970 - val_accuracy: 0.7801 - 271ms/epoch - 8ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4266 - accuracy: 0.8289 - val_loss: 0.4956 - val_accuracy: 0.7730 - 270ms/epoch - 8ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4256 - accuracy: 0.8324 - val_loss: 0.4946 - val_accuracy: 0.7518 - 285ms/epoch - 8ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4243 - accuracy: 0.8307 - val_loss: 0.4940 - val_accuracy: 0.7660 - 301ms/epoch - 8ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4229 - accuracy: 0.8307 - val_loss: 0.4929 - val_accuracy: 0.7730 - 293ms/epoch - 8ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4219 - accuracy: 0.8324 - val_loss: 0.4922 - val_accuracy: 0.7730 - 310ms/epoch - 9ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4208 - accuracy: 0.8324 - val_loss: 0.4910 - val_accuracy: 0.7730 - 297ms/epoch - 8ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4197 - accuracy: 0.8324 - val_loss: 0.4904 - val_accuracy: 0.7730 - 296ms/epoch - 8ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4187 - accuracy: 0.8324 - val_loss: 0.4896 - val_accuracy: 0.7730 - 312ms/epoch - 9ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4177 - accuracy: 0.8342 - val_loss: 0.4889 - val_accuracy: 0.7730 - 294ms/epoch - 8ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4169 - accuracy: 0.8324 - val_loss: 0.4871 - val_accuracy: 0.7660 - 320ms/epoch - 9ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4160 - accuracy: 0.8342 - val_loss: 0.4867 - val_accuracy: 0.7660 - 303ms/epoch - 8ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4152 - accuracy: 0.8342 - val_loss: 0.4857 - val_accuracy: 0.7660 - 288ms/epoch - 8ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4143 - accuracy: 0.8342 - val_loss: 0.4849 - val_accuracy: 0.7660 - 295ms/epoch - 8ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4137 - accuracy: 0.8342 - val_loss: 0.4847 - val_accuracy: 0.7660 - 285ms/epoch - 8ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4125 - accuracy: 0.8342 - val_loss: 0.4842 - val_accuracy: 0.7730 - 274ms/epoch - 8ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4119 - accuracy: 0.8307 - val_loss: 0.4837 - val_accuracy: 0.7730 - 290ms/epoch - 8ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4111 - accuracy: 0.8289 - val_loss: 0.4835 - val_accuracy: 0.7730 - 290ms/epoch - 8ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4107 - accuracy: 0.8289 - val_loss: 0.4831 - val_accuracy: 0.7660 - 292ms/epoch - 8ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4098 - accuracy: 0.8307 - val_loss: 0.4828 - val_accuracy: 0.7660 - 275ms/epoch - 8ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4093 - accuracy: 0.8307 - val_loss: 0.4821 - val_accuracy: 0.7660 - 289ms/epoch - 8ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4085 - accuracy: 0.8324 - val_loss: 0.4817 - val_accuracy: 0.7730 - 286ms/epoch - 8ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4082 - accuracy: 0.8324 - val_loss: 0.4815 - val_accuracy: 0.7730 - 285ms/epoch - 8ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4075 - accuracy: 0.8324 - val_loss: 0.4806 - val_accuracy: 0.7730 - 267ms/epoch - 7ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4070 - accuracy: 0.8324 - val_loss: 0.4800 - val_accuracy: 0.7730 - 331ms/epoch - 9ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4067 - accuracy: 0.8342 - val_loss: 0.4802 - val_accuracy: 0.7730 - 308ms/epoch - 9ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4058 - accuracy: 0.8342 - val_loss: 0.4800 - val_accuracy: 0.7660 - 285ms/epoch - 8ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4056 - accuracy: 0.8378 - val_loss: 0.4786 - val_accuracy: 0.7660 - 285ms/epoch - 8ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4051 - accuracy: 0.8378 - val_loss: 0.4785 - val_accuracy: 0.7660 - 286ms/epoch - 8ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4045 - accuracy: 0.8396 - val_loss: 0.4780 - val_accuracy: 0.7801 - 272ms/epoch - 8ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4042 - accuracy: 0.8342 - val_loss: 0.4777 - val_accuracy: 0.7801 - 267ms/epoch - 7ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4036 - accuracy: 0.8342 - val_loss: 0.4772 - val_accuracy: 0.7801 - 272ms/epoch - 8ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4032 - accuracy: 0.8360 - val_loss: 0.4770 - val_accuracy: 0.7872 - 289ms/epoch - 8ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4027 - accuracy: 0.8378 - val_loss: 0.4765 - val_accuracy: 0.7730 - 300ms/epoch - 8ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4022 - accuracy: 0.8396 - val_loss: 0.4769 - val_accuracy: 0.7872 - 253ms/epoch - 7ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4022 - accuracy: 0.8324 - val_loss: 0.4770 - val_accuracy: 0.7730 - 283ms/epoch - 8ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4016 - accuracy: 0.8342 - val_loss: 0.4767 - val_accuracy: 0.7730 - 269ms/epoch - 7ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4012 - accuracy: 0.8396 - val_loss: 0.4758 - val_accuracy: 0.7801 - 310ms/epoch - 9ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4008 - accuracy: 0.8414 - val_loss: 0.4759 - val_accuracy: 0.7801 - 332ms/epoch - 9ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4006 - accuracy: 0.8396 - val_loss: 0.4758 - val_accuracy: 0.7801 - 294ms/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4003 - accuracy: 0.8396 - val_loss: 0.4752 - val_accuracy: 0.7660 - 316ms/epoch - 9ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4001 - accuracy: 0.8378 - val_loss: 0.4750 - val_accuracy: 0.7801 - 274ms/epoch - 8ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.3998 - accuracy: 0.8396 - val_loss: 0.4741 - val_accuracy: 0.7730 - 333ms/epoch - 9ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.3995 - accuracy: 0.8414 - val_loss: 0.4743 - val_accuracy: 0.7801 - 281ms/epoch - 8ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.3991 - accuracy: 0.8396 - val_loss: 0.4741 - val_accuracy: 0.7801 - 266ms/epoch - 7ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.3989 - accuracy: 0.8431 - val_loss: 0.4744 - val_accuracy: 0.7801 - 286ms/epoch - 8ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.3985 - accuracy: 0.8431 - val_loss: 0.4743 - val_accuracy: 0.7801 - 290ms/epoch - 8ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.3982 - accuracy: 0.8414 - val_loss: 0.4744 - val_accuracy: 0.7801 - 317ms/epoch - 9ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.3979 - accuracy: 0.8414 - val_loss: 0.4742 - val_accuracy: 0.7730 - 286ms/epoch - 8ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.3977 - accuracy: 0.8414 - val_loss: 0.4742 - val_accuracy: 0.7801 - 321ms/epoch - 9ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8360 - val_loss: 0.4753 - val_accuracy: 0.7872 - 330ms/epoch - 9ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.3973 - accuracy: 0.8378 - val_loss: 0.4751 - val_accuracy: 0.7801 - 294ms/epoch - 8ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.3972 - accuracy: 0.8378 - val_loss: 0.4747 - val_accuracy: 0.7730 - 286ms/epoch - 8ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.3967 - accuracy: 0.8396 - val_loss: 0.4751 - val_accuracy: 0.7801 - 315ms/epoch - 9ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.3965 - accuracy: 0.8360 - val_loss: 0.4758 - val_accuracy: 0.7801 - 299ms/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8342 - val_loss: 0.4755 - val_accuracy: 0.7801 - 283ms/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8360 - val_loss: 0.4753 - val_accuracy: 0.7801 - 278ms/epoch - 8ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.3959 - accuracy: 0.8378 - val_loss: 0.4749 - val_accuracy: 0.7589 - 312ms/epoch - 9ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.3956 - accuracy: 0.8396 - val_loss: 0.4751 - val_accuracy: 0.7730 - 278ms/epoch - 8ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8342 - val_loss: 0.4761 - val_accuracy: 0.7943 - 311ms/epoch - 9ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3953 - accuracy: 0.8342 - val_loss: 0.4758 - val_accuracy: 0.7801 - 272ms/epoch - 8ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3951 - accuracy: 0.8378 - val_loss: 0.4747 - val_accuracy: 0.7589 - 265ms/epoch - 7ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8414 - val_loss: 0.4735 - val_accuracy: 0.7660 - 293ms/epoch - 8ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8414 - val_loss: 0.4736 - val_accuracy: 0.7660 - 292ms/epoch - 8ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3944 - accuracy: 0.8396 - val_loss: 0.4739 - val_accuracy: 0.7589 - 343ms/epoch - 10ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3942 - accuracy: 0.8378 - val_loss: 0.4737 - val_accuracy: 0.7660 - 308ms/epoch - 9ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3941 - accuracy: 0.8378 - val_loss: 0.4738 - val_accuracy: 0.7589 - 300ms/epoch - 8ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3937 - accuracy: 0.8396 - val_loss: 0.4738 - val_accuracy: 0.7589 - 319ms/epoch - 9ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3934 - accuracy: 0.8360 - val_loss: 0.4744 - val_accuracy: 0.7730 - 312ms/epoch - 9ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3933 - accuracy: 0.8360 - val_loss: 0.4746 - val_accuracy: 0.7730 - 340ms/epoch - 9ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3932 - accuracy: 0.8378 - val_loss: 0.4750 - val_accuracy: 0.7730 - 308ms/epoch - 9ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3930 - accuracy: 0.8342 - val_loss: 0.4746 - val_accuracy: 0.7660 - 360ms/epoch - 10ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3928 - accuracy: 0.8360 - val_loss: 0.4744 - val_accuracy: 0.7660 - 349ms/epoch - 10ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3928 - accuracy: 0.8378 - val_loss: 0.4745 - val_accuracy: 0.7589 - 340ms/epoch - 9ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3924 - accuracy: 0.8360 - val_loss: 0.4745 - val_accuracy: 0.7660 - 295ms/epoch - 8ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3924 - accuracy: 0.8360 - val_loss: 0.4747 - val_accuracy: 0.7660 - 309ms/epoch - 9ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3924 - accuracy: 0.8360 - val_loss: 0.4754 - val_accuracy: 0.7730 - 289ms/epoch - 8ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3919 - accuracy: 0.8360 - val_loss: 0.4754 - val_accuracy: 0.7730 - 270ms/epoch - 8ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3918 - accuracy: 0.8342 - val_loss: 0.4763 - val_accuracy: 0.7801 - 328ms/epoch - 9ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3917 - accuracy: 0.8342 - val_loss: 0.4756 - val_accuracy: 0.7730 - 311ms/epoch - 9ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3915 - accuracy: 0.8360 - val_loss: 0.4752 - val_accuracy: 0.7589 - 274ms/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3912 - accuracy: 0.8378 - val_loss: 0.4754 - val_accuracy: 0.7589 - 276ms/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3910 - accuracy: 0.8342 - val_loss: 0.4762 - val_accuracy: 0.7730 - 264ms/epoch - 7ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3910 - accuracy: 0.8342 - val_loss: 0.4758 - val_accuracy: 0.7730 - 274ms/epoch - 8ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3911 - accuracy: 0.8324 - val_loss: 0.4769 - val_accuracy: 0.7801 - 265ms/epoch - 7ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3911 - accuracy: 0.8324 - val_loss: 0.4762 - val_accuracy: 0.7730 - 280ms/epoch - 8ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3908 - accuracy: 0.8342 - val_loss: 0.4759 - val_accuracy: 0.7730 - 292ms/epoch - 8ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3906 - accuracy: 0.8360 - val_loss: 0.4757 - val_accuracy: 0.7660 - 292ms/epoch - 8ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3904 - accuracy: 0.8360 - val_loss: 0.4756 - val_accuracy: 0.7589 - 291ms/epoch - 8ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3903 - accuracy: 0.8342 - val_loss: 0.4757 - val_accuracy: 0.7589 - 260ms/epoch - 7ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3907 - accuracy: 0.8378 - val_loss: 0.4771 - val_accuracy: 0.7518 - 242ms/epoch - 7ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3899 - accuracy: 0.8360 - val_loss: 0.4775 - val_accuracy: 0.7589 - 251ms/epoch - 7ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3899 - accuracy: 0.8360 - val_loss: 0.4778 - val_accuracy: 0.7589 - 266ms/epoch - 7ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3898 - accuracy: 0.8360 - val_loss: 0.4777 - val_accuracy: 0.7589 - 244ms/epoch - 7ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8378 - val_loss: 0.4793 - val_accuracy: 0.7730 - 268ms/epoch - 7ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3898 - accuracy: 0.8360 - val_loss: 0.4800 - val_accuracy: 0.7801 - 255ms/epoch - 7ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3896 - accuracy: 0.8360 - val_loss: 0.4787 - val_accuracy: 0.7589 - 267ms/epoch - 7ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3894 - accuracy: 0.8360 - val_loss: 0.4781 - val_accuracy: 0.7589 - 254ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3892 - accuracy: 0.8360 - val_loss: 0.4780 - val_accuracy: 0.7589 - 251ms/epoch - 7ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3890 - accuracy: 0.8360 - val_loss: 0.4780 - val_accuracy: 0.7589 - 246ms/epoch - 7ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3889 - accuracy: 0.8342 - val_loss: 0.4780 - val_accuracy: 0.7518 - 249ms/epoch - 7ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3888 - accuracy: 0.8378 - val_loss: 0.4782 - val_accuracy: 0.7518 - 250ms/epoch - 7ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3888 - accuracy: 0.8378 - val_loss: 0.4780 - val_accuracy: 0.7518 - 261ms/epoch - 7ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3888 - accuracy: 0.8378 - val_loss: 0.4787 - val_accuracy: 0.7589 - 249ms/epoch - 7ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3886 - accuracy: 0.8378 - val_loss: 0.4791 - val_accuracy: 0.7589 - 244ms/epoch - 7ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 0.7195 - accuracy: 0.5508 - val_loss: 0.7006 - val_accuracy: 0.5745 - 680ms/epoch - 19ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.6721 - accuracy: 0.5758 - val_loss: 0.6706 - val_accuracy: 0.6099 - 249ms/epoch - 7ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.6451 - accuracy: 0.6096 - val_loss: 0.6533 - val_accuracy: 0.6454 - 247ms/epoch - 7ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.6262 - accuracy: 0.6328 - val_loss: 0.6414 - val_accuracy: 0.6596 - 262ms/epoch - 7ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.6128 - accuracy: 0.6542 - val_loss: 0.6321 - val_accuracy: 0.6667 - 289ms/epoch - 8ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.5997 - accuracy: 0.6631 - val_loss: 0.6226 - val_accuracy: 0.6667 - 244ms/epoch - 7ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.5878 - accuracy: 0.6791 - val_loss: 0.6136 - val_accuracy: 0.6738 - 258ms/epoch - 7ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.5768 - accuracy: 0.6898 - val_loss: 0.6062 - val_accuracy: 0.6879 - 265ms/epoch - 7ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.5665 - accuracy: 0.7023 - val_loss: 0.5986 - val_accuracy: 0.6950 - 255ms/epoch - 7ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.5570 - accuracy: 0.7059 - val_loss: 0.5917 - val_accuracy: 0.6879 - 276ms/epoch - 8ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5482 - accuracy: 0.7094 - val_loss: 0.5858 - val_accuracy: 0.6879 - 279ms/epoch - 8ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5409 - accuracy: 0.7201 - val_loss: 0.5798 - val_accuracy: 0.7021 - 287ms/epoch - 8ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5329 - accuracy: 0.7344 - val_loss: 0.5742 - val_accuracy: 0.6809 - 281ms/epoch - 8ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5263 - accuracy: 0.7433 - val_loss: 0.5693 - val_accuracy: 0.7021 - 279ms/epoch - 8ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5199 - accuracy: 0.7451 - val_loss: 0.5648 - val_accuracy: 0.7021 - 299ms/epoch - 8ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.5141 - accuracy: 0.7487 - val_loss: 0.5607 - val_accuracy: 0.7021 - 266ms/epoch - 7ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.5085 - accuracy: 0.7558 - val_loss: 0.5562 - val_accuracy: 0.7092 - 264ms/epoch - 7ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.5037 - accuracy: 0.7647 - val_loss: 0.5519 - val_accuracy: 0.7234 - 284ms/epoch - 8ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.4986 - accuracy: 0.7718 - val_loss: 0.5479 - val_accuracy: 0.7447 - 276ms/epoch - 8ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.4942 - accuracy: 0.7736 - val_loss: 0.5443 - val_accuracy: 0.7589 - 320ms/epoch - 9ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.4900 - accuracy: 0.7736 - val_loss: 0.5414 - val_accuracy: 0.7589 - 299ms/epoch - 8ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4861 - accuracy: 0.7754 - val_loss: 0.5380 - val_accuracy: 0.7589 - 262ms/epoch - 7ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4826 - accuracy: 0.7754 - val_loss: 0.5355 - val_accuracy: 0.7589 - 246ms/epoch - 7ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4795 - accuracy: 0.7754 - val_loss: 0.5332 - val_accuracy: 0.7589 - 297ms/epoch - 8ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4763 - accuracy: 0.7807 - val_loss: 0.5304 - val_accuracy: 0.7589 - 307ms/epoch - 9ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4739 - accuracy: 0.7897 - val_loss: 0.5281 - val_accuracy: 0.7589 - 274ms/epoch - 8ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4707 - accuracy: 0.7879 - val_loss: 0.5253 - val_accuracy: 0.7589 - 268ms/epoch - 7ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4679 - accuracy: 0.7825 - val_loss: 0.5227 - val_accuracy: 0.7589 - 266ms/epoch - 7ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4654 - accuracy: 0.7897 - val_loss: 0.5205 - val_accuracy: 0.7589 - 268ms/epoch - 7ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4633 - accuracy: 0.7897 - val_loss: 0.5184 - val_accuracy: 0.7660 - 250ms/epoch - 7ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4609 - accuracy: 0.7932 - val_loss: 0.5166 - val_accuracy: 0.7589 - 256ms/epoch - 7ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4584 - accuracy: 0.7950 - val_loss: 0.5140 - val_accuracy: 0.7589 - 275ms/epoch - 8ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4565 - accuracy: 0.7950 - val_loss: 0.5124 - val_accuracy: 0.7589 - 279ms/epoch - 8ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4540 - accuracy: 0.7950 - val_loss: 0.5104 - val_accuracy: 0.7589 - 257ms/epoch - 7ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4523 - accuracy: 0.8004 - val_loss: 0.5085 - val_accuracy: 0.7518 - 272ms/epoch - 8ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4500 - accuracy: 0.8021 - val_loss: 0.5067 - val_accuracy: 0.7518 - 268ms/epoch - 7ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4484 - accuracy: 0.8057 - val_loss: 0.5054 - val_accuracy: 0.7589 - 251ms/epoch - 7ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4467 - accuracy: 0.8057 - val_loss: 0.5033 - val_accuracy: 0.7589 - 257ms/epoch - 7ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4451 - accuracy: 0.8075 - val_loss: 0.5023 - val_accuracy: 0.7660 - 257ms/epoch - 7ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4434 - accuracy: 0.8039 - val_loss: 0.5006 - val_accuracy: 0.7589 - 262ms/epoch - 7ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4421 - accuracy: 0.8039 - val_loss: 0.4992 - val_accuracy: 0.7660 - 258ms/epoch - 7ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4405 - accuracy: 0.8075 - val_loss: 0.4979 - val_accuracy: 0.7660 - 256ms/epoch - 7ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4389 - accuracy: 0.8075 - val_loss: 0.4966 - val_accuracy: 0.7589 - 288ms/epoch - 8ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4376 - accuracy: 0.8075 - val_loss: 0.4955 - val_accuracy: 0.7589 - 276ms/epoch - 8ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4361 - accuracy: 0.8039 - val_loss: 0.4943 - val_accuracy: 0.7589 - 244ms/epoch - 7ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4348 - accuracy: 0.8039 - val_loss: 0.4935 - val_accuracy: 0.7589 - 258ms/epoch - 7ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4337 - accuracy: 0.8057 - val_loss: 0.4925 - val_accuracy: 0.7589 - 269ms/epoch - 7ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4325 - accuracy: 0.8021 - val_loss: 0.4912 - val_accuracy: 0.7589 - 240ms/epoch - 7ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4317 - accuracy: 0.8057 - val_loss: 0.4903 - val_accuracy: 0.7660 - 246ms/epoch - 7ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7589 - 260ms/epoch - 7ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4292 - accuracy: 0.8128 - val_loss: 0.4886 - val_accuracy: 0.7589 - 252ms/epoch - 7ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4285 - accuracy: 0.8057 - val_loss: 0.4874 - val_accuracy: 0.7589 - 243ms/epoch - 7ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4274 - accuracy: 0.8128 - val_loss: 0.4860 - val_accuracy: 0.7660 - 274ms/epoch - 8ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4264 - accuracy: 0.8146 - val_loss: 0.4853 - val_accuracy: 0.7660 - 250ms/epoch - 7ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4251 - accuracy: 0.8093 - val_loss: 0.4843 - val_accuracy: 0.7660 - 260ms/epoch - 7ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4243 - accuracy: 0.8146 - val_loss: 0.4836 - val_accuracy: 0.7660 - 256ms/epoch - 7ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4238 - accuracy: 0.8075 - val_loss: 0.4822 - val_accuracy: 0.7660 - 269ms/epoch - 7ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4226 - accuracy: 0.8111 - val_loss: 0.4818 - val_accuracy: 0.7660 - 277ms/epoch - 8ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4216 - accuracy: 0.8111 - val_loss: 0.4810 - val_accuracy: 0.7730 - 293ms/epoch - 8ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4206 - accuracy: 0.8111 - val_loss: 0.4805 - val_accuracy: 0.7730 - 263ms/epoch - 7ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4199 - accuracy: 0.8128 - val_loss: 0.4799 - val_accuracy: 0.7801 - 275ms/epoch - 8ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4198 - accuracy: 0.8111 - val_loss: 0.4792 - val_accuracy: 0.7730 - 243ms/epoch - 7ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4186 - accuracy: 0.8128 - val_loss: 0.4783 - val_accuracy: 0.7801 - 256ms/epoch - 7ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4178 - accuracy: 0.8128 - val_loss: 0.4781 - val_accuracy: 0.7801 - 247ms/epoch - 7ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4173 - accuracy: 0.8093 - val_loss: 0.4774 - val_accuracy: 0.7801 - 256ms/epoch - 7ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4166 - accuracy: 0.8128 - val_loss: 0.4769 - val_accuracy: 0.7801 - 260ms/epoch - 7ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4160 - accuracy: 0.8111 - val_loss: 0.4759 - val_accuracy: 0.7801 - 235ms/epoch - 7ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4151 - accuracy: 0.8111 - val_loss: 0.4752 - val_accuracy: 0.7801 - 248ms/epoch - 7ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4146 - accuracy: 0.8128 - val_loss: 0.4749 - val_accuracy: 0.7801 - 259ms/epoch - 7ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4141 - accuracy: 0.8111 - val_loss: 0.4744 - val_accuracy: 0.7801 - 273ms/epoch - 8ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4136 - accuracy: 0.8146 - val_loss: 0.4736 - val_accuracy: 0.7801 - 275ms/epoch - 8ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4131 - accuracy: 0.8093 - val_loss: 0.4734 - val_accuracy: 0.7730 - 252ms/epoch - 7ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4122 - accuracy: 0.8093 - val_loss: 0.4729 - val_accuracy: 0.7730 - 248ms/epoch - 7ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4118 - accuracy: 0.8075 - val_loss: 0.4727 - val_accuracy: 0.7730 - 290ms/epoch - 8ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4111 - accuracy: 0.8075 - val_loss: 0.4717 - val_accuracy: 0.7801 - 248ms/epoch - 7ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4107 - accuracy: 0.8111 - val_loss: 0.4717 - val_accuracy: 0.7730 - 258ms/epoch - 7ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4101 - accuracy: 0.8057 - val_loss: 0.4713 - val_accuracy: 0.7730 - 289ms/epoch - 8ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4097 - accuracy: 0.8057 - val_loss: 0.4710 - val_accuracy: 0.7730 - 298ms/epoch - 8ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4093 - accuracy: 0.8057 - val_loss: 0.4708 - val_accuracy: 0.7801 - 291ms/epoch - 8ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4088 - accuracy: 0.8057 - val_loss: 0.4706 - val_accuracy: 0.7801 - 266ms/epoch - 7ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4084 - accuracy: 0.8057 - val_loss: 0.4701 - val_accuracy: 0.7730 - 252ms/epoch - 7ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4086 - accuracy: 0.8164 - val_loss: 0.4696 - val_accuracy: 0.7730 - 272ms/epoch - 8ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4077 - accuracy: 0.8182 - val_loss: 0.4689 - val_accuracy: 0.7730 - 283ms/epoch - 8ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4072 - accuracy: 0.8128 - val_loss: 0.4689 - val_accuracy: 0.7660 - 299ms/epoch - 8ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4069 - accuracy: 0.8146 - val_loss: 0.4686 - val_accuracy: 0.7660 - 306ms/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4066 - accuracy: 0.8164 - val_loss: 0.4677 - val_accuracy: 0.7660 - 309ms/epoch - 9ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4061 - accuracy: 0.8182 - val_loss: 0.4679 - val_accuracy: 0.7801 - 293ms/epoch - 8ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4060 - accuracy: 0.8093 - val_loss: 0.4681 - val_accuracy: 0.7660 - 291ms/epoch - 8ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4052 - accuracy: 0.8128 - val_loss: 0.4678 - val_accuracy: 0.7660 - 310ms/epoch - 9ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4048 - accuracy: 0.8146 - val_loss: 0.4680 - val_accuracy: 0.7660 - 282ms/epoch - 8ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4047 - accuracy: 0.8093 - val_loss: 0.4676 - val_accuracy: 0.7660 - 258ms/epoch - 7ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4044 - accuracy: 0.8075 - val_loss: 0.4675 - val_accuracy: 0.7660 - 254ms/epoch - 7ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4041 - accuracy: 0.8057 - val_loss: 0.4676 - val_accuracy: 0.7660 - 264ms/epoch - 7ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.4038 - accuracy: 0.8057 - val_loss: 0.4676 - val_accuracy: 0.7660 - 271ms/epoch - 8ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4033 - accuracy: 0.8093 - val_loss: 0.4670 - val_accuracy: 0.7660 - 286ms/epoch - 8ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.4034 - accuracy: 0.8128 - val_loss: 0.4667 - val_accuracy: 0.7660 - 286ms/epoch - 8ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4029 - accuracy: 0.8146 - val_loss: 0.4663 - val_accuracy: 0.7730 - 311ms/epoch - 9ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.4024 - accuracy: 0.8128 - val_loss: 0.4663 - val_accuracy: 0.7660 - 277ms/epoch - 8ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.4022 - accuracy: 0.8128 - val_loss: 0.4664 - val_accuracy: 0.7660 - 284ms/epoch - 8ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.4018 - accuracy: 0.8146 - val_loss: 0.4663 - val_accuracy: 0.7660 - 284ms/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.4016 - accuracy: 0.8111 - val_loss: 0.4661 - val_accuracy: 0.7660 - 279ms/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.4017 - accuracy: 0.8128 - val_loss: 0.4654 - val_accuracy: 0.7730 - 281ms/epoch - 8ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.4013 - accuracy: 0.8111 - val_loss: 0.4653 - val_accuracy: 0.7730 - 282ms/epoch - 8ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.4017 - accuracy: 0.8146 - val_loss: 0.4643 - val_accuracy: 0.7730 - 257ms/epoch - 7ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.4009 - accuracy: 0.8128 - val_loss: 0.4645 - val_accuracy: 0.7730 - 253ms/epoch - 7ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.4009 - accuracy: 0.8128 - val_loss: 0.4650 - val_accuracy: 0.7660 - 251ms/epoch - 7ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.4006 - accuracy: 0.8093 - val_loss: 0.4649 - val_accuracy: 0.7730 - 239ms/epoch - 7ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.4000 - accuracy: 0.8128 - val_loss: 0.4649 - val_accuracy: 0.7730 - 248ms/epoch - 7ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3999 - accuracy: 0.8128 - val_loss: 0.4652 - val_accuracy: 0.7730 - 250ms/epoch - 7ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3996 - accuracy: 0.8146 - val_loss: 0.4652 - val_accuracy: 0.7730 - 250ms/epoch - 7ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3994 - accuracy: 0.8146 - val_loss: 0.4653 - val_accuracy: 0.7730 - 281ms/epoch - 8ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3995 - accuracy: 0.8128 - val_loss: 0.4659 - val_accuracy: 0.7730 - 281ms/epoch - 8ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3995 - accuracy: 0.8146 - val_loss: 0.4659 - val_accuracy: 0.7730 - 280ms/epoch - 8ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3990 - accuracy: 0.8128 - val_loss: 0.4659 - val_accuracy: 0.7518 - 284ms/epoch - 8ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3987 - accuracy: 0.8164 - val_loss: 0.4659 - val_accuracy: 0.7589 - 250ms/epoch - 7ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3985 - accuracy: 0.8128 - val_loss: 0.4660 - val_accuracy: 0.7518 - 284ms/epoch - 8ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3983 - accuracy: 0.8111 - val_loss: 0.4657 - val_accuracy: 0.7589 - 271ms/epoch - 8ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3981 - accuracy: 0.8111 - val_loss: 0.4658 - val_accuracy: 0.7589 - 272ms/epoch - 8ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3979 - accuracy: 0.8128 - val_loss: 0.4655 - val_accuracy: 0.7660 - 297ms/epoch - 8ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3981 - accuracy: 0.8146 - val_loss: 0.4655 - val_accuracy: 0.7801 - 273ms/epoch - 8ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3978 - accuracy: 0.8128 - val_loss: 0.4655 - val_accuracy: 0.7589 - 293ms/epoch - 8ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8146 - val_loss: 0.4657 - val_accuracy: 0.7589 - 278ms/epoch - 8ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8128 - val_loss: 0.4664 - val_accuracy: 0.7518 - 277ms/epoch - 8ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3973 - accuracy: 0.8146 - val_loss: 0.4661 - val_accuracy: 0.7518 - 318ms/epoch - 9ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3972 - accuracy: 0.8128 - val_loss: 0.4659 - val_accuracy: 0.7518 - 279ms/epoch - 8ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3971 - accuracy: 0.8128 - val_loss: 0.4660 - val_accuracy: 0.7518 - 299ms/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3968 - accuracy: 0.8146 - val_loss: 0.4658 - val_accuracy: 0.7518 - 298ms/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3970 - accuracy: 0.8164 - val_loss: 0.4660 - val_accuracy: 0.7589 - 286ms/epoch - 8ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8146 - val_loss: 0.4656 - val_accuracy: 0.7660 - 291ms/epoch - 8ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8146 - val_loss: 0.4650 - val_accuracy: 0.7589 - 277ms/epoch - 8ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8164 - val_loss: 0.4649 - val_accuracy: 0.7589 - 279ms/epoch - 8ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8182 - val_loss: 0.4651 - val_accuracy: 0.7730 - 285ms/epoch - 8ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3962 - accuracy: 0.8182 - val_loss: 0.4651 - val_accuracy: 0.7801 - 277ms/epoch - 8ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8182 - val_loss: 0.4654 - val_accuracy: 0.7447 - 271ms/epoch - 8ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3957 - accuracy: 0.8111 - val_loss: 0.4654 - val_accuracy: 0.7589 - 246ms/epoch - 7ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3954 - accuracy: 0.8164 - val_loss: 0.4656 - val_accuracy: 0.7589 - 240ms/epoch - 7ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3956 - accuracy: 0.8200 - val_loss: 0.4653 - val_accuracy: 0.7447 - 247ms/epoch - 7ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3953 - accuracy: 0.8217 - val_loss: 0.4654 - val_accuracy: 0.7730 - 252ms/epoch - 7ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3951 - accuracy: 0.8182 - val_loss: 0.4658 - val_accuracy: 0.7730 - 242ms/epoch - 7ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3950 - accuracy: 0.8182 - val_loss: 0.4658 - val_accuracy: 0.7730 - 256ms/epoch - 7ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3945 - accuracy: 0.8164 - val_loss: 0.4660 - val_accuracy: 0.7801 - 277ms/epoch - 8ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8128 - val_loss: 0.4655 - val_accuracy: 0.7730 - 259ms/epoch - 7ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3946 - accuracy: 0.8146 - val_loss: 0.4655 - val_accuracy: 0.7730 - 262ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3946 - accuracy: 0.8200 - val_loss: 0.4652 - val_accuracy: 0.7660 - 261ms/epoch - 7ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3946 - accuracy: 0.8182 - val_loss: 0.4652 - val_accuracy: 0.7589 - 263ms/epoch - 7ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3944 - accuracy: 0.8182 - val_loss: 0.4657 - val_accuracy: 0.7447 - 253ms/epoch - 7ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3945 - accuracy: 0.8182 - val_loss: 0.4655 - val_accuracy: 0.7518 - 254ms/epoch - 7ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3941 - accuracy: 0.8200 - val_loss: 0.4657 - val_accuracy: 0.7589 - 289ms/epoch - 8ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3940 - accuracy: 0.8164 - val_loss: 0.4660 - val_accuracy: 0.7660 - 275ms/epoch - 8ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3939 - accuracy: 0.8164 - val_loss: 0.4662 - val_accuracy: 0.7660 - 263ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "history_base = model_base.fit(x=X_train_base, y=y_train_base, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_per = model_per.fit(x=X_train_per, y=y_train_per, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_mdi = model_mdi.fit(x=X_train_mdi, y=y_train_mdi, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Testdata using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "---------Base-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------Permutation-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------MDI-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[137,   0],\n",
       "       [164,   0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_base = model_base.predict(X_test_base)\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "\n",
    "print(\"---------Base-Prediction----------\")\n",
    "evaluate_classification_result(y_test_base,pred_base,classes=nn_data_base[\"target_names\"])\n",
    "print(\"---------Permutation-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_per,pred_per,classes=nn_data_per[\"target_names\"])\n",
    "print(\"---------MDI-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_mdi,pred_mdi,classes=nn_data_mdi[\"target_names\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_base = model_base.predict(X_test_base)\n",
    "classes_base = [1 if i > 0.5  else 0 for i in pred_base]\n",
    "\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "classes_per = [1 if i > 0.5  else 0 for i in pred_per]\n",
    "\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "classes_mdi = [1 if i > 0.5  else 0 for i in pred_mdi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_per.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_per):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_per\n",
    "result_df[\"PRED\"] = classes_per\n",
    "\n",
    "result_df.to_csv(result_dir+\"ACHE/fe_rf_per_nn.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_mdi.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_mdi):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_mdi\n",
    "result_df[\"PRED\"] = classes_mdi\n",
    "\n",
    "result_df.to_csv(result_dir+\"ACHE/fe_mdi_per_nn.csv\",encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activity_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
