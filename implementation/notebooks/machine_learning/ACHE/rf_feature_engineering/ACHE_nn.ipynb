{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from pyMLaux import plot_history, evaluate_classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dynamic path\n",
    "base_dir = Path(os.getcwd()) / \"implementation\"\n",
    "data_dir = base_dir / \"data/source/\"\n",
    "result_dir = base_dir / \"data/results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load & prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code needs to be adapted for each protein-ligand complex individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data_raw_mdi = pd.read_csv(data_dir/\"ACHE/ache_mdi.csv\")\n",
    "nn_data_raw_per = pd.read_csv(data_dir/\"ACHE/ache_per.csv\")\n",
    "nn_data_raw = pd.read_csv(data_dir/\"ACHE/ache.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {'inactive':0,'active':1}\n",
    "\n",
    "nn_data_per = {'data': np.array(nn_data_raw_per.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_per.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_per.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_mdi = {'data': np.array(nn_data_raw_mdi.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_mdi.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_mdi.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_base = {'data': np.array(nn_data_raw.iloc[:, 2:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw.columns[2:-1],\n",
    "             'target_names': ['inactive', 'active']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train- and test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(nn_data_base['data'], nn_data_base['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_mdi, X_test_mdi, y_train_mdi, y_test_mdi = train_test_split(nn_data_mdi['data'], nn_data_mdi['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_per, X_test_per, y_train_per, y_test_per = train_test_split(nn_data_per['data'], nn_data_per['target'],\n",
    "                                                    test_size=0.3, random_state=4232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and apply neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 18:59:22.794202: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:23.360474: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:23.360719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:23.382468: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:23.382686: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:23.382759: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:24.659309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:24.659487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:24.659507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-29 18:59:24.659617: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 18:59:24.659676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 841 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model_base = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_base['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_base.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_per = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_per['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_per.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_mdi = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_mdi['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_mdi.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 18:59:32.118736: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-29 18:59:35.036670: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fe7d07afca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-29 18:59:35.036738: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-04-29 18:59:35.197656: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-29 18:59:35.454626: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714409975.954500   17391 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 10s - loss: 0.7267 - accuracy: 0.5098 - val_loss: 0.7212 - val_accuracy: 0.5177 - 10s/epoch - 275ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 1s - loss: 0.6805 - accuracy: 0.5811 - val_loss: 0.6889 - val_accuracy: 0.5532 - 1s/epoch - 34ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 1s - loss: 0.6488 - accuracy: 0.6221 - val_loss: 0.6670 - val_accuracy: 0.5745 - 1s/epoch - 35ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 1s - loss: 0.6240 - accuracy: 0.6720 - val_loss: 0.6498 - val_accuracy: 0.5816 - 1s/epoch - 36ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 1s - loss: 0.6039 - accuracy: 0.6952 - val_loss: 0.6351 - val_accuracy: 0.6241 - 1s/epoch - 35ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 1s - loss: 0.5852 - accuracy: 0.7148 - val_loss: 0.6213 - val_accuracy: 0.6667 - 1s/epoch - 39ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 1s - loss: 0.5685 - accuracy: 0.7540 - val_loss: 0.6100 - val_accuracy: 0.7021 - 1s/epoch - 33ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 1s - loss: 0.5543 - accuracy: 0.7629 - val_loss: 0.5996 - val_accuracy: 0.7234 - 1s/epoch - 34ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 1s - loss: 0.5413 - accuracy: 0.7665 - val_loss: 0.5901 - val_accuracy: 0.7234 - 1s/epoch - 37ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 1s - loss: 0.5298 - accuracy: 0.7754 - val_loss: 0.5820 - val_accuracy: 0.7376 - 1s/epoch - 38ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 1s - loss: 0.5195 - accuracy: 0.7790 - val_loss: 0.5743 - val_accuracy: 0.7376 - 1s/epoch - 31ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 1s - loss: 0.5102 - accuracy: 0.7843 - val_loss: 0.5676 - val_accuracy: 0.7376 - 1s/epoch - 33ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 1s - loss: 0.5019 - accuracy: 0.7879 - val_loss: 0.5618 - val_accuracy: 0.7305 - 1s/epoch - 38ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 1s - loss: 0.4945 - accuracy: 0.7897 - val_loss: 0.5565 - val_accuracy: 0.7305 - 1s/epoch - 33ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 1s - loss: 0.4873 - accuracy: 0.7986 - val_loss: 0.5518 - val_accuracy: 0.7447 - 1s/epoch - 32ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 1s - loss: 0.4809 - accuracy: 0.7897 - val_loss: 0.5472 - val_accuracy: 0.7447 - 1s/epoch - 37ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 1s - loss: 0.4754 - accuracy: 0.7986 - val_loss: 0.5427 - val_accuracy: 0.7447 - 1s/epoch - 35ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 1s - loss: 0.4699 - accuracy: 0.7986 - val_loss: 0.5386 - val_accuracy: 0.7518 - 1s/epoch - 39ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 1s - loss: 0.4647 - accuracy: 0.7968 - val_loss: 0.5349 - val_accuracy: 0.7518 - 1s/epoch - 36ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 1s - loss: 0.4600 - accuracy: 0.8057 - val_loss: 0.5315 - val_accuracy: 0.7518 - 1s/epoch - 33ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 1s - loss: 0.4556 - accuracy: 0.8039 - val_loss: 0.5286 - val_accuracy: 0.7518 - 1s/epoch - 34ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 1s - loss: 0.4518 - accuracy: 0.8093 - val_loss: 0.5253 - val_accuracy: 0.7660 - 1s/epoch - 32ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 1s - loss: 0.4475 - accuracy: 0.8075 - val_loss: 0.5221 - val_accuracy: 0.7660 - 1s/epoch - 35ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 1s - loss: 0.4442 - accuracy: 0.8057 - val_loss: 0.5194 - val_accuracy: 0.7518 - 1s/epoch - 28ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 1s - loss: 0.4407 - accuracy: 0.8093 - val_loss: 0.5167 - val_accuracy: 0.7660 - 1s/epoch - 32ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 1s - loss: 0.4378 - accuracy: 0.8111 - val_loss: 0.5140 - val_accuracy: 0.7589 - 1s/epoch - 29ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 1s - loss: 0.4348 - accuracy: 0.8146 - val_loss: 0.5122 - val_accuracy: 0.7660 - 963ms/epoch - 27ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 1s - loss: 0.4324 - accuracy: 0.8093 - val_loss: 0.5096 - val_accuracy: 0.7589 - 995ms/epoch - 28ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 1s - loss: 0.4292 - accuracy: 0.8146 - val_loss: 0.5073 - val_accuracy: 0.7589 - 888ms/epoch - 25ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 1s - loss: 0.4267 - accuracy: 0.8164 - val_loss: 0.5054 - val_accuracy: 0.7589 - 1s/epoch - 32ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 1s - loss: 0.4242 - accuracy: 0.8182 - val_loss: 0.5033 - val_accuracy: 0.7660 - 1s/epoch - 32ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 1s - loss: 0.4218 - accuracy: 0.8182 - val_loss: 0.5014 - val_accuracy: 0.7589 - 1s/epoch - 32ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 1s - loss: 0.4202 - accuracy: 0.8164 - val_loss: 0.5003 - val_accuracy: 0.7589 - 1s/epoch - 32ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 1s - loss: 0.4176 - accuracy: 0.8217 - val_loss: 0.4989 - val_accuracy: 0.7801 - 1s/epoch - 32ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 1s - loss: 0.4154 - accuracy: 0.8253 - val_loss: 0.4969 - val_accuracy: 0.7660 - 1s/epoch - 29ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 1s - loss: 0.4136 - accuracy: 0.8253 - val_loss: 0.4951 - val_accuracy: 0.7660 - 1s/epoch - 34ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 1s - loss: 0.4117 - accuracy: 0.8253 - val_loss: 0.4939 - val_accuracy: 0.7660 - 892ms/epoch - 25ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 1s - loss: 0.4103 - accuracy: 0.8253 - val_loss: 0.4923 - val_accuracy: 0.7730 - 1s/epoch - 31ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 1s - loss: 0.4082 - accuracy: 0.8289 - val_loss: 0.4910 - val_accuracy: 0.7730 - 1s/epoch - 29ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 1s - loss: 0.4065 - accuracy: 0.8271 - val_loss: 0.4898 - val_accuracy: 0.7730 - 1s/epoch - 33ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 1s - loss: 0.4050 - accuracy: 0.8271 - val_loss: 0.4885 - val_accuracy: 0.7730 - 1s/epoch - 37ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 1s - loss: 0.4038 - accuracy: 0.8271 - val_loss: 0.4877 - val_accuracy: 0.7801 - 1s/epoch - 39ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 2s - loss: 0.4020 - accuracy: 0.8253 - val_loss: 0.4875 - val_accuracy: 0.7872 - 2s/epoch - 43ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 1s - loss: 0.4003 - accuracy: 0.8271 - val_loss: 0.4858 - val_accuracy: 0.7872 - 1s/epoch - 37ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 1s - loss: 0.3994 - accuracy: 0.8289 - val_loss: 0.4838 - val_accuracy: 0.7730 - 1s/epoch - 33ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 1s - loss: 0.3974 - accuracy: 0.8235 - val_loss: 0.4824 - val_accuracy: 0.7872 - 1s/epoch - 30ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 1s - loss: 0.3969 - accuracy: 0.8271 - val_loss: 0.4808 - val_accuracy: 0.7730 - 1s/epoch - 28ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 2s - loss: 0.3953 - accuracy: 0.8271 - val_loss: 0.4796 - val_accuracy: 0.7801 - 2s/epoch - 47ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 1s - loss: 0.3942 - accuracy: 0.8289 - val_loss: 0.4790 - val_accuracy: 0.7801 - 1s/epoch - 38ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 1s - loss: 0.3930 - accuracy: 0.8271 - val_loss: 0.4777 - val_accuracy: 0.7801 - 1s/epoch - 36ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 1s - loss: 0.3918 - accuracy: 0.8235 - val_loss: 0.4764 - val_accuracy: 0.7872 - 1s/epoch - 34ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 1s - loss: 0.3908 - accuracy: 0.8324 - val_loss: 0.4755 - val_accuracy: 0.7801 - 1s/epoch - 31ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 1s - loss: 0.3897 - accuracy: 0.8289 - val_loss: 0.4752 - val_accuracy: 0.7872 - 858ms/epoch - 24ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 1s - loss: 0.3884 - accuracy: 0.8271 - val_loss: 0.4742 - val_accuracy: 0.7872 - 1s/epoch - 39ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 1s - loss: 0.3872 - accuracy: 0.8307 - val_loss: 0.4736 - val_accuracy: 0.7872 - 1s/epoch - 35ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 2s - loss: 0.3862 - accuracy: 0.8342 - val_loss: 0.4731 - val_accuracy: 0.7872 - 2s/epoch - 54ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 2s - loss: 0.3855 - accuracy: 0.8342 - val_loss: 0.4720 - val_accuracy: 0.7872 - 2s/epoch - 47ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 1s - loss: 0.3843 - accuracy: 0.8342 - val_loss: 0.4717 - val_accuracy: 0.7872 - 1s/epoch - 38ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 1s - loss: 0.3840 - accuracy: 0.8324 - val_loss: 0.4719 - val_accuracy: 0.7730 - 1s/epoch - 40ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 1s - loss: 0.3822 - accuracy: 0.8342 - val_loss: 0.4698 - val_accuracy: 0.7872 - 1s/epoch - 35ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 2s - loss: 0.3818 - accuracy: 0.8360 - val_loss: 0.4698 - val_accuracy: 0.7872 - 2s/epoch - 42ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 2s - loss: 0.3806 - accuracy: 0.8378 - val_loss: 0.4684 - val_accuracy: 0.7872 - 2s/epoch - 49ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 1s - loss: 0.3799 - accuracy: 0.8342 - val_loss: 0.4685 - val_accuracy: 0.7872 - 1s/epoch - 39ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 1s - loss: 0.3796 - accuracy: 0.8324 - val_loss: 0.4688 - val_accuracy: 0.7730 - 1s/epoch - 31ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 1s - loss: 0.3787 - accuracy: 0.8307 - val_loss: 0.4674 - val_accuracy: 0.7801 - 1s/epoch - 32ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 2s - loss: 0.3776 - accuracy: 0.8324 - val_loss: 0.4666 - val_accuracy: 0.7872 - 2s/epoch - 42ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 1s - loss: 0.3767 - accuracy: 0.8324 - val_loss: 0.4662 - val_accuracy: 0.7872 - 1s/epoch - 40ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 1s - loss: 0.3761 - accuracy: 0.8307 - val_loss: 0.4661 - val_accuracy: 0.7801 - 1s/epoch - 28ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 1s - loss: 0.3749 - accuracy: 0.8396 - val_loss: 0.4642 - val_accuracy: 0.7801 - 1s/epoch - 35ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 2s - loss: 0.3743 - accuracy: 0.8414 - val_loss: 0.4640 - val_accuracy: 0.7872 - 2s/epoch - 49ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 2s - loss: 0.3737 - accuracy: 0.8396 - val_loss: 0.4634 - val_accuracy: 0.7730 - 2s/epoch - 49ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 2s - loss: 0.3730 - accuracy: 0.8378 - val_loss: 0.4626 - val_accuracy: 0.7801 - 2s/epoch - 45ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 1s - loss: 0.3721 - accuracy: 0.8431 - val_loss: 0.4619 - val_accuracy: 0.7801 - 1s/epoch - 39ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 2s - loss: 0.3714 - accuracy: 0.8431 - val_loss: 0.4606 - val_accuracy: 0.7801 - 2s/epoch - 49ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 1s - loss: 0.3708 - accuracy: 0.8396 - val_loss: 0.4605 - val_accuracy: 0.7801 - 1s/epoch - 42ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 1s - loss: 0.3701 - accuracy: 0.8396 - val_loss: 0.4600 - val_accuracy: 0.7801 - 1s/epoch - 31ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 1s - loss: 0.3697 - accuracy: 0.8396 - val_loss: 0.4599 - val_accuracy: 0.7801 - 1s/epoch - 33ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 1s - loss: 0.3689 - accuracy: 0.8414 - val_loss: 0.4593 - val_accuracy: 0.7801 - 1s/epoch - 37ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 1s - loss: 0.3681 - accuracy: 0.8431 - val_loss: 0.4593 - val_accuracy: 0.7801 - 1s/epoch - 36ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 1s - loss: 0.3674 - accuracy: 0.8414 - val_loss: 0.4588 - val_accuracy: 0.7801 - 1s/epoch - 35ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 1s - loss: 0.3673 - accuracy: 0.8396 - val_loss: 0.4584 - val_accuracy: 0.7801 - 1s/epoch - 33ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 1s - loss: 0.3664 - accuracy: 0.8414 - val_loss: 0.4576 - val_accuracy: 0.7801 - 1s/epoch - 29ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 1s - loss: 0.3659 - accuracy: 0.8396 - val_loss: 0.4576 - val_accuracy: 0.7730 - 1s/epoch - 31ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 1s - loss: 0.3652 - accuracy: 0.8431 - val_loss: 0.4573 - val_accuracy: 0.7730 - 1s/epoch - 28ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 1s - loss: 0.3646 - accuracy: 0.8449 - val_loss: 0.4569 - val_accuracy: 0.7730 - 1s/epoch - 30ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 1s - loss: 0.3641 - accuracy: 0.8431 - val_loss: 0.4572 - val_accuracy: 0.7730 - 1s/epoch - 34ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 1s - loss: 0.3637 - accuracy: 0.8467 - val_loss: 0.4575 - val_accuracy: 0.7730 - 1s/epoch - 34ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 1s - loss: 0.3631 - accuracy: 0.8449 - val_loss: 0.4571 - val_accuracy: 0.7730 - 1s/epoch - 38ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 2s - loss: 0.3629 - accuracy: 0.8449 - val_loss: 0.4583 - val_accuracy: 0.7730 - 2s/epoch - 46ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 2s - loss: 0.3620 - accuracy: 0.8467 - val_loss: 0.4563 - val_accuracy: 0.7730 - 2s/epoch - 58ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 1s - loss: 0.3614 - accuracy: 0.8467 - val_loss: 0.4559 - val_accuracy: 0.7801 - 1s/epoch - 38ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 1s - loss: 0.3608 - accuracy: 0.8449 - val_loss: 0.4556 - val_accuracy: 0.7801 - 1s/epoch - 31ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 1s - loss: 0.3602 - accuracy: 0.8449 - val_loss: 0.4551 - val_accuracy: 0.7730 - 1s/epoch - 38ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 1s - loss: 0.3599 - accuracy: 0.8431 - val_loss: 0.4548 - val_accuracy: 0.7730 - 1s/epoch - 39ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 2s - loss: 0.3593 - accuracy: 0.8431 - val_loss: 0.4545 - val_accuracy: 0.7730 - 2s/epoch - 43ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 2s - loss: 0.3589 - accuracy: 0.8467 - val_loss: 0.4547 - val_accuracy: 0.7801 - 2s/epoch - 42ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 1s - loss: 0.3584 - accuracy: 0.8467 - val_loss: 0.4539 - val_accuracy: 0.7730 - 1s/epoch - 40ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 1s - loss: 0.3579 - accuracy: 0.8485 - val_loss: 0.4543 - val_accuracy: 0.7801 - 1s/epoch - 32ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 1s - loss: 0.3573 - accuracy: 0.8467 - val_loss: 0.4534 - val_accuracy: 0.7730 - 1s/epoch - 33ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 1s - loss: 0.3568 - accuracy: 0.8467 - val_loss: 0.4531 - val_accuracy: 0.7730 - 1s/epoch - 32ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 1s - loss: 0.3563 - accuracy: 0.8467 - val_loss: 0.4533 - val_accuracy: 0.7730 - 1s/epoch - 37ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 1s - loss: 0.3560 - accuracy: 0.8485 - val_loss: 0.4532 - val_accuracy: 0.7730 - 786ms/epoch - 22ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 1s - loss: 0.3555 - accuracy: 0.8467 - val_loss: 0.4526 - val_accuracy: 0.7730 - 768ms/epoch - 21ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 1s - loss: 0.3552 - accuracy: 0.8485 - val_loss: 0.4527 - val_accuracy: 0.7730 - 700ms/epoch - 19ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 1s - loss: 0.3545 - accuracy: 0.8485 - val_loss: 0.4526 - val_accuracy: 0.7801 - 709ms/epoch - 20ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 1s - loss: 0.3543 - accuracy: 0.8503 - val_loss: 0.4526 - val_accuracy: 0.7801 - 766ms/epoch - 21ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 1s - loss: 0.3539 - accuracy: 0.8503 - val_loss: 0.4526 - val_accuracy: 0.7730 - 881ms/epoch - 24ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 1s - loss: 0.3533 - accuracy: 0.8503 - val_loss: 0.4524 - val_accuracy: 0.7801 - 815ms/epoch - 23ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 1s - loss: 0.3532 - accuracy: 0.8538 - val_loss: 0.4520 - val_accuracy: 0.7801 - 717ms/epoch - 20ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 1s - loss: 0.3527 - accuracy: 0.8503 - val_loss: 0.4525 - val_accuracy: 0.7730 - 861ms/epoch - 24ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 1s - loss: 0.3519 - accuracy: 0.8520 - val_loss: 0.4530 - val_accuracy: 0.7730 - 574ms/epoch - 16ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 1s - loss: 0.3517 - accuracy: 0.8503 - val_loss: 0.4523 - val_accuracy: 0.7730 - 669ms/epoch - 19ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 1s - loss: 0.3512 - accuracy: 0.8538 - val_loss: 0.4515 - val_accuracy: 0.7801 - 753ms/epoch - 21ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 1s - loss: 0.3509 - accuracy: 0.8556 - val_loss: 0.4516 - val_accuracy: 0.7801 - 723ms/epoch - 20ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 1s - loss: 0.3505 - accuracy: 0.8538 - val_loss: 0.4514 - val_accuracy: 0.7801 - 652ms/epoch - 18ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 1s - loss: 0.3500 - accuracy: 0.8556 - val_loss: 0.4511 - val_accuracy: 0.7730 - 661ms/epoch - 18ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 1s - loss: 0.3498 - accuracy: 0.8556 - val_loss: 0.4505 - val_accuracy: 0.7730 - 903ms/epoch - 25ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 1s - loss: 0.3494 - accuracy: 0.8574 - val_loss: 0.4507 - val_accuracy: 0.7730 - 734ms/epoch - 20ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 1s - loss: 0.3489 - accuracy: 0.8556 - val_loss: 0.4501 - val_accuracy: 0.7801 - 843ms/epoch - 23ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 1s - loss: 0.3486 - accuracy: 0.8556 - val_loss: 0.4498 - val_accuracy: 0.7801 - 1s/epoch - 28ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 1s - loss: 0.3483 - accuracy: 0.8556 - val_loss: 0.4498 - val_accuracy: 0.7801 - 822ms/epoch - 23ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 1s - loss: 0.3481 - accuracy: 0.8556 - val_loss: 0.4507 - val_accuracy: 0.7660 - 789ms/epoch - 22ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 1s - loss: 0.3475 - accuracy: 0.8556 - val_loss: 0.4498 - val_accuracy: 0.7730 - 615ms/epoch - 17ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 1s - loss: 0.3475 - accuracy: 0.8574 - val_loss: 0.4501 - val_accuracy: 0.7801 - 674ms/epoch - 19ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 1s - loss: 0.3470 - accuracy: 0.8538 - val_loss: 0.4502 - val_accuracy: 0.7730 - 749ms/epoch - 21ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 1s - loss: 0.3468 - accuracy: 0.8520 - val_loss: 0.4512 - val_accuracy: 0.7730 - 692ms/epoch - 19ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 1s - loss: 0.3461 - accuracy: 0.8538 - val_loss: 0.4502 - val_accuracy: 0.7730 - 746ms/epoch - 21ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 1s - loss: 0.3462 - accuracy: 0.8556 - val_loss: 0.4497 - val_accuracy: 0.7801 - 811ms/epoch - 23ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 1s - loss: 0.3455 - accuracy: 0.8538 - val_loss: 0.4498 - val_accuracy: 0.7801 - 699ms/epoch - 19ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 1s - loss: 0.3453 - accuracy: 0.8538 - val_loss: 0.4503 - val_accuracy: 0.7730 - 590ms/epoch - 16ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 1s - loss: 0.3448 - accuracy: 0.8520 - val_loss: 0.4506 - val_accuracy: 0.7730 - 656ms/epoch - 18ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 1s - loss: 0.3443 - accuracy: 0.8538 - val_loss: 0.4491 - val_accuracy: 0.7801 - 695ms/epoch - 19ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 1s - loss: 0.3440 - accuracy: 0.8556 - val_loss: 0.4487 - val_accuracy: 0.7730 - 716ms/epoch - 20ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 1s - loss: 0.3444 - accuracy: 0.8538 - val_loss: 0.4499 - val_accuracy: 0.7801 - 854ms/epoch - 24ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 1s - loss: 0.3437 - accuracy: 0.8538 - val_loss: 0.4498 - val_accuracy: 0.7801 - 621ms/epoch - 17ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 1s - loss: 0.3436 - accuracy: 0.8538 - val_loss: 0.4495 - val_accuracy: 0.7801 - 608ms/epoch - 17ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 1s - loss: 0.3431 - accuracy: 0.8538 - val_loss: 0.4503 - val_accuracy: 0.7730 - 656ms/epoch - 18ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 1s - loss: 0.3426 - accuracy: 0.8538 - val_loss: 0.4492 - val_accuracy: 0.7801 - 719ms/epoch - 20ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 1s - loss: 0.3424 - accuracy: 0.8520 - val_loss: 0.4493 - val_accuracy: 0.7801 - 697ms/epoch - 19ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 1s - loss: 0.3424 - accuracy: 0.8556 - val_loss: 0.4476 - val_accuracy: 0.7872 - 609ms/epoch - 17ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 1s - loss: 0.3429 - accuracy: 0.8538 - val_loss: 0.4471 - val_accuracy: 0.7872 - 689ms/epoch - 19ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 1s - loss: 0.3418 - accuracy: 0.8556 - val_loss: 0.4476 - val_accuracy: 0.7943 - 719ms/epoch - 20ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 1s - loss: 0.3412 - accuracy: 0.8556 - val_loss: 0.4485 - val_accuracy: 0.7872 - 787ms/epoch - 22ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 1s - loss: 0.3410 - accuracy: 0.8556 - val_loss: 0.4489 - val_accuracy: 0.7801 - 964ms/epoch - 27ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 1s - loss: 0.3408 - accuracy: 0.8574 - val_loss: 0.4483 - val_accuracy: 0.7872 - 706ms/epoch - 20ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 1s - loss: 0.3405 - accuracy: 0.8574 - val_loss: 0.4487 - val_accuracy: 0.7801 - 738ms/epoch - 21ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 1s - loss: 0.3399 - accuracy: 0.8592 - val_loss: 0.4483 - val_accuracy: 0.7801 - 885ms/epoch - 25ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 1s - loss: 0.3398 - accuracy: 0.8592 - val_loss: 0.4488 - val_accuracy: 0.7801 - 967ms/epoch - 27ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 1s - loss: 0.3395 - accuracy: 0.8556 - val_loss: 0.4484 - val_accuracy: 0.7801 - 757ms/epoch - 21ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 1s - loss: 0.3392 - accuracy: 0.8592 - val_loss: 0.4487 - val_accuracy: 0.7801 - 701ms/epoch - 19ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 3s - loss: 0.7029 - accuracy: 0.5223 - val_loss: 0.6409 - val_accuracy: 0.6170 - 3s/epoch - 94ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 1s - loss: 0.6760 - accuracy: 0.5704 - val_loss: 0.6254 - val_accuracy: 0.6596 - 541ms/epoch - 15ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 1s - loss: 0.6546 - accuracy: 0.6043 - val_loss: 0.6129 - val_accuracy: 0.6383 - 650ms/epoch - 18ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 1s - loss: 0.6363 - accuracy: 0.6275 - val_loss: 0.6015 - val_accuracy: 0.6879 - 555ms/epoch - 15ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 1s - loss: 0.6202 - accuracy: 0.6506 - val_loss: 0.5911 - val_accuracy: 0.7021 - 577ms/epoch - 16ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 1s - loss: 0.6053 - accuracy: 0.6649 - val_loss: 0.5813 - val_accuracy: 0.7021 - 559ms/epoch - 16ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 1s - loss: 0.5912 - accuracy: 0.6952 - val_loss: 0.5737 - val_accuracy: 0.7092 - 525ms/epoch - 15ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 1s - loss: 0.5796 - accuracy: 0.7130 - val_loss: 0.5652 - val_accuracy: 0.7305 - 568ms/epoch - 16ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 1s - loss: 0.5689 - accuracy: 0.7219 - val_loss: 0.5589 - val_accuracy: 0.7305 - 651ms/epoch - 18ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 1s - loss: 0.5585 - accuracy: 0.7344 - val_loss: 0.5525 - val_accuracy: 0.7376 - 553ms/epoch - 15ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 1s - loss: 0.5490 - accuracy: 0.7415 - val_loss: 0.5464 - val_accuracy: 0.7518 - 610ms/epoch - 17ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 1s - loss: 0.5402 - accuracy: 0.7487 - val_loss: 0.5410 - val_accuracy: 0.7447 - 613ms/epoch - 17ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 1s - loss: 0.5325 - accuracy: 0.7576 - val_loss: 0.5360 - val_accuracy: 0.7376 - 612ms/epoch - 17ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 1s - loss: 0.5247 - accuracy: 0.7594 - val_loss: 0.5311 - val_accuracy: 0.7518 - 531ms/epoch - 15ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 1s - loss: 0.5183 - accuracy: 0.7611 - val_loss: 0.5272 - val_accuracy: 0.7518 - 745ms/epoch - 21ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 1s - loss: 0.5122 - accuracy: 0.7594 - val_loss: 0.5236 - val_accuracy: 0.7518 - 575ms/epoch - 16ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 1s - loss: 0.5060 - accuracy: 0.7754 - val_loss: 0.5203 - val_accuracy: 0.7660 - 589ms/epoch - 16ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 1s - loss: 0.5010 - accuracy: 0.7807 - val_loss: 0.5171 - val_accuracy: 0.7660 - 568ms/epoch - 16ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 1s - loss: 0.4963 - accuracy: 0.7861 - val_loss: 0.5144 - val_accuracy: 0.7660 - 542ms/epoch - 15ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 1s - loss: 0.4913 - accuracy: 0.7790 - val_loss: 0.5114 - val_accuracy: 0.7801 - 644ms/epoch - 18ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 1s - loss: 0.4872 - accuracy: 0.7879 - val_loss: 0.5087 - val_accuracy: 0.7872 - 565ms/epoch - 16ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 1s - loss: 0.4830 - accuracy: 0.7897 - val_loss: 0.5063 - val_accuracy: 0.7943 - 611ms/epoch - 17ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 1s - loss: 0.4793 - accuracy: 0.7843 - val_loss: 0.5039 - val_accuracy: 0.7943 - 686ms/epoch - 19ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 1s - loss: 0.4755 - accuracy: 0.7897 - val_loss: 0.5015 - val_accuracy: 0.7943 - 654ms/epoch - 18ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 1s - loss: 0.4725 - accuracy: 0.7861 - val_loss: 0.4992 - val_accuracy: 0.7872 - 583ms/epoch - 16ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 1s - loss: 0.4687 - accuracy: 0.7861 - val_loss: 0.4973 - val_accuracy: 0.7872 - 670ms/epoch - 19ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 1s - loss: 0.4657 - accuracy: 0.7897 - val_loss: 0.4954 - val_accuracy: 0.7872 - 816ms/epoch - 23ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 1s - loss: 0.4628 - accuracy: 0.7879 - val_loss: 0.4935 - val_accuracy: 0.7872 - 711ms/epoch - 20ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 1s - loss: 0.4600 - accuracy: 0.8075 - val_loss: 0.4922 - val_accuracy: 0.7872 - 644ms/epoch - 18ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 1s - loss: 0.4579 - accuracy: 0.8093 - val_loss: 0.4912 - val_accuracy: 0.7872 - 548ms/epoch - 15ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 1s - loss: 0.4556 - accuracy: 0.8128 - val_loss: 0.4897 - val_accuracy: 0.7872 - 547ms/epoch - 15ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4533 - accuracy: 0.8146 - val_loss: 0.4882 - val_accuracy: 0.7872 - 489ms/epoch - 14ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4513 - accuracy: 0.8111 - val_loss: 0.4870 - val_accuracy: 0.7872 - 377ms/epoch - 10ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4489 - accuracy: 0.8128 - val_loss: 0.4854 - val_accuracy: 0.7872 - 338ms/epoch - 9ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4470 - accuracy: 0.8093 - val_loss: 0.4844 - val_accuracy: 0.7872 - 352ms/epoch - 10ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4451 - accuracy: 0.8111 - val_loss: 0.4837 - val_accuracy: 0.7943 - 251ms/epoch - 7ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4434 - accuracy: 0.8111 - val_loss: 0.4828 - val_accuracy: 0.7943 - 293ms/epoch - 8ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4416 - accuracy: 0.8111 - val_loss: 0.4816 - val_accuracy: 0.7943 - 239ms/epoch - 7ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4399 - accuracy: 0.8164 - val_loss: 0.4811 - val_accuracy: 0.7943 - 248ms/epoch - 7ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4386 - accuracy: 0.8128 - val_loss: 0.4800 - val_accuracy: 0.7943 - 243ms/epoch - 7ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4368 - accuracy: 0.8164 - val_loss: 0.4794 - val_accuracy: 0.7943 - 249ms/epoch - 7ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4354 - accuracy: 0.8146 - val_loss: 0.4786 - val_accuracy: 0.7872 - 217ms/epoch - 6ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4342 - accuracy: 0.8093 - val_loss: 0.4782 - val_accuracy: 0.7872 - 237ms/epoch - 7ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4326 - accuracy: 0.8128 - val_loss: 0.4779 - val_accuracy: 0.7872 - 274ms/epoch - 8ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4313 - accuracy: 0.8128 - val_loss: 0.4770 - val_accuracy: 0.7872 - 278ms/epoch - 8ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 1s - loss: 0.4298 - accuracy: 0.8128 - val_loss: 0.4765 - val_accuracy: 0.7872 - 546ms/epoch - 15ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 1s - loss: 0.4287 - accuracy: 0.8111 - val_loss: 0.4760 - val_accuracy: 0.7801 - 577ms/epoch - 16ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 1s - loss: 0.4278 - accuracy: 0.8093 - val_loss: 0.4754 - val_accuracy: 0.7872 - 595ms/epoch - 17ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 1s - loss: 0.4266 - accuracy: 0.8111 - val_loss: 0.4749 - val_accuracy: 0.7872 - 808ms/epoch - 22ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 1s - loss: 0.4253 - accuracy: 0.8093 - val_loss: 0.4743 - val_accuracy: 0.7872 - 732ms/epoch - 20ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 1s - loss: 0.4243 - accuracy: 0.8128 - val_loss: 0.4740 - val_accuracy: 0.7872 - 886ms/epoch - 25ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 1s - loss: 0.4233 - accuracy: 0.8146 - val_loss: 0.4738 - val_accuracy: 0.7872 - 728ms/epoch - 20ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 1s - loss: 0.4224 - accuracy: 0.8111 - val_loss: 0.4726 - val_accuracy: 0.7872 - 620ms/epoch - 17ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 1s - loss: 0.4218 - accuracy: 0.8111 - val_loss: 0.4721 - val_accuracy: 0.7872 - 652ms/epoch - 18ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 1s - loss: 0.4209 - accuracy: 0.8111 - val_loss: 0.4719 - val_accuracy: 0.7872 - 566ms/epoch - 16ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 1s - loss: 0.4204 - accuracy: 0.8146 - val_loss: 0.4711 - val_accuracy: 0.7872 - 600ms/epoch - 17ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 1s - loss: 0.4193 - accuracy: 0.8128 - val_loss: 0.4709 - val_accuracy: 0.7872 - 559ms/epoch - 16ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 1s - loss: 0.4183 - accuracy: 0.8146 - val_loss: 0.4708 - val_accuracy: 0.7872 - 583ms/epoch - 16ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 1s - loss: 0.4174 - accuracy: 0.8146 - val_loss: 0.4707 - val_accuracy: 0.7801 - 560ms/epoch - 16ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 1s - loss: 0.4166 - accuracy: 0.8164 - val_loss: 0.4705 - val_accuracy: 0.7801 - 614ms/epoch - 17ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 1s - loss: 0.4159 - accuracy: 0.8200 - val_loss: 0.4701 - val_accuracy: 0.7801 - 597ms/epoch - 17ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 1s - loss: 0.4149 - accuracy: 0.8182 - val_loss: 0.4701 - val_accuracy: 0.7801 - 544ms/epoch - 15ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 1s - loss: 0.4142 - accuracy: 0.8182 - val_loss: 0.4700 - val_accuracy: 0.7801 - 618ms/epoch - 17ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 1s - loss: 0.4136 - accuracy: 0.8217 - val_loss: 0.4699 - val_accuracy: 0.7801 - 581ms/epoch - 16ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 1s - loss: 0.4129 - accuracy: 0.8200 - val_loss: 0.4695 - val_accuracy: 0.7801 - 588ms/epoch - 16ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 1s - loss: 0.4124 - accuracy: 0.8217 - val_loss: 0.4699 - val_accuracy: 0.7730 - 572ms/epoch - 16ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 1s - loss: 0.4117 - accuracy: 0.8217 - val_loss: 0.4697 - val_accuracy: 0.7730 - 619ms/epoch - 17ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 1s - loss: 0.4108 - accuracy: 0.8253 - val_loss: 0.4695 - val_accuracy: 0.7730 - 529ms/epoch - 15ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 1s - loss: 0.4104 - accuracy: 0.8253 - val_loss: 0.4695 - val_accuracy: 0.7730 - 547ms/epoch - 15ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 1s - loss: 0.4098 - accuracy: 0.8253 - val_loss: 0.4693 - val_accuracy: 0.7730 - 592ms/epoch - 16ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 1s - loss: 0.4092 - accuracy: 0.8217 - val_loss: 0.4695 - val_accuracy: 0.7801 - 640ms/epoch - 18ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 1s - loss: 0.4087 - accuracy: 0.8235 - val_loss: 0.4706 - val_accuracy: 0.7801 - 627ms/epoch - 17ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 1s - loss: 0.4082 - accuracy: 0.8200 - val_loss: 0.4703 - val_accuracy: 0.7801 - 596ms/epoch - 17ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 1s - loss: 0.4078 - accuracy: 0.8253 - val_loss: 0.4705 - val_accuracy: 0.7801 - 618ms/epoch - 17ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 1s - loss: 0.4072 - accuracy: 0.8235 - val_loss: 0.4707 - val_accuracy: 0.7801 - 632ms/epoch - 18ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 1s - loss: 0.4071 - accuracy: 0.8271 - val_loss: 0.4714 - val_accuracy: 0.7801 - 586ms/epoch - 16ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 1s - loss: 0.4061 - accuracy: 0.8289 - val_loss: 0.4712 - val_accuracy: 0.7801 - 541ms/epoch - 15ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 1s - loss: 0.4057 - accuracy: 0.8271 - val_loss: 0.4708 - val_accuracy: 0.7730 - 556ms/epoch - 15ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 1s - loss: 0.4055 - accuracy: 0.8289 - val_loss: 0.4706 - val_accuracy: 0.7801 - 620ms/epoch - 17ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 1s - loss: 0.4049 - accuracy: 0.8289 - val_loss: 0.4708 - val_accuracy: 0.7801 - 581ms/epoch - 16ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 1s - loss: 0.4043 - accuracy: 0.8342 - val_loss: 0.4718 - val_accuracy: 0.7730 - 594ms/epoch - 16ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 1s - loss: 0.4044 - accuracy: 0.8324 - val_loss: 0.4721 - val_accuracy: 0.7730 - 555ms/epoch - 15ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 1s - loss: 0.4037 - accuracy: 0.8342 - val_loss: 0.4718 - val_accuracy: 0.7730 - 562ms/epoch - 16ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 1s - loss: 0.4033 - accuracy: 0.8360 - val_loss: 0.4716 - val_accuracy: 0.7730 - 603ms/epoch - 17ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 1s - loss: 0.4029 - accuracy: 0.8342 - val_loss: 0.4715 - val_accuracy: 0.7730 - 543ms/epoch - 15ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 1s - loss: 0.4024 - accuracy: 0.8360 - val_loss: 0.4718 - val_accuracy: 0.7730 - 541ms/epoch - 15ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 1s - loss: 0.4021 - accuracy: 0.8342 - val_loss: 0.4720 - val_accuracy: 0.7730 - 601ms/epoch - 17ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 1s - loss: 0.4020 - accuracy: 0.8342 - val_loss: 0.4720 - val_accuracy: 0.7730 - 617ms/epoch - 17ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 1s - loss: 0.4014 - accuracy: 0.8324 - val_loss: 0.4720 - val_accuracy: 0.7730 - 547ms/epoch - 15ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 1s - loss: 0.4013 - accuracy: 0.8342 - val_loss: 0.4722 - val_accuracy: 0.7730 - 544ms/epoch - 15ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 1s - loss: 0.4008 - accuracy: 0.8360 - val_loss: 0.4731 - val_accuracy: 0.7660 - 650ms/epoch - 18ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 1s - loss: 0.4004 - accuracy: 0.8360 - val_loss: 0.4730 - val_accuracy: 0.7660 - 579ms/epoch - 16ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 1s - loss: 0.4001 - accuracy: 0.8360 - val_loss: 0.4727 - val_accuracy: 0.7660 - 625ms/epoch - 17ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 1s - loss: 0.3997 - accuracy: 0.8342 - val_loss: 0.4727 - val_accuracy: 0.7660 - 728ms/epoch - 20ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 1s - loss: 0.3995 - accuracy: 0.8360 - val_loss: 0.4730 - val_accuracy: 0.7660 - 806ms/epoch - 22ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 1s - loss: 0.3991 - accuracy: 0.8342 - val_loss: 0.4728 - val_accuracy: 0.7660 - 779ms/epoch - 22ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 1s - loss: 0.3989 - accuracy: 0.8360 - val_loss: 0.4729 - val_accuracy: 0.7660 - 792ms/epoch - 22ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 1s - loss: 0.3987 - accuracy: 0.8342 - val_loss: 0.4736 - val_accuracy: 0.7730 - 745ms/epoch - 21ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 1s - loss: 0.3982 - accuracy: 0.8360 - val_loss: 0.4734 - val_accuracy: 0.7660 - 706ms/epoch - 20ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 1s - loss: 0.3980 - accuracy: 0.8342 - val_loss: 0.4731 - val_accuracy: 0.7660 - 698ms/epoch - 19ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 1s - loss: 0.3976 - accuracy: 0.8342 - val_loss: 0.4731 - val_accuracy: 0.7589 - 715ms/epoch - 20ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 1s - loss: 0.3977 - accuracy: 0.8360 - val_loss: 0.4727 - val_accuracy: 0.7589 - 699ms/epoch - 19ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 1s - loss: 0.3971 - accuracy: 0.8324 - val_loss: 0.4730 - val_accuracy: 0.7660 - 747ms/epoch - 21ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 1s - loss: 0.3971 - accuracy: 0.8360 - val_loss: 0.4732 - val_accuracy: 0.7589 - 772ms/epoch - 21ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 1s - loss: 0.3970 - accuracy: 0.8324 - val_loss: 0.4728 - val_accuracy: 0.7660 - 676ms/epoch - 19ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 1s - loss: 0.3967 - accuracy: 0.8324 - val_loss: 0.4728 - val_accuracy: 0.7589 - 761ms/epoch - 21ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 1s - loss: 0.3965 - accuracy: 0.8324 - val_loss: 0.4732 - val_accuracy: 0.7589 - 758ms/epoch - 21ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 1s - loss: 0.3961 - accuracy: 0.8342 - val_loss: 0.4733 - val_accuracy: 0.7589 - 700ms/epoch - 19ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 1s - loss: 0.3958 - accuracy: 0.8324 - val_loss: 0.4731 - val_accuracy: 0.7589 - 722ms/epoch - 20ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 1s - loss: 0.3955 - accuracy: 0.8360 - val_loss: 0.4734 - val_accuracy: 0.7589 - 811ms/epoch - 23ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 1s - loss: 0.3953 - accuracy: 0.8378 - val_loss: 0.4729 - val_accuracy: 0.7589 - 664ms/epoch - 18ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 1s - loss: 0.3955 - accuracy: 0.8360 - val_loss: 0.4741 - val_accuracy: 0.7589 - 679ms/epoch - 19ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 1s - loss: 0.3948 - accuracy: 0.8342 - val_loss: 0.4740 - val_accuracy: 0.7589 - 673ms/epoch - 19ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 1s - loss: 0.3946 - accuracy: 0.8378 - val_loss: 0.4743 - val_accuracy: 0.7589 - 662ms/epoch - 18ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 1s - loss: 0.3947 - accuracy: 0.8378 - val_loss: 0.4743 - val_accuracy: 0.7589 - 571ms/epoch - 16ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 1s - loss: 0.3945 - accuracy: 0.8360 - val_loss: 0.4749 - val_accuracy: 0.7589 - 568ms/epoch - 16ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 1s - loss: 0.3942 - accuracy: 0.8360 - val_loss: 0.4750 - val_accuracy: 0.7589 - 505ms/epoch - 14ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3941 - accuracy: 0.8360 - val_loss: 0.4764 - val_accuracy: 0.7730 - 460ms/epoch - 13ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3944 - accuracy: 0.8396 - val_loss: 0.4768 - val_accuracy: 0.7730 - 398ms/epoch - 11ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3940 - accuracy: 0.8360 - val_loss: 0.4756 - val_accuracy: 0.7589 - 401ms/epoch - 11ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3936 - accuracy: 0.8360 - val_loss: 0.4752 - val_accuracy: 0.7589 - 347ms/epoch - 10ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3933 - accuracy: 0.8378 - val_loss: 0.4745 - val_accuracy: 0.7589 - 352ms/epoch - 10ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3931 - accuracy: 0.8378 - val_loss: 0.4742 - val_accuracy: 0.7589 - 337ms/epoch - 9ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3930 - accuracy: 0.8378 - val_loss: 0.4748 - val_accuracy: 0.7589 - 380ms/epoch - 11ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3929 - accuracy: 0.8342 - val_loss: 0.4742 - val_accuracy: 0.7518 - 361ms/epoch - 10ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3926 - accuracy: 0.8360 - val_loss: 0.4746 - val_accuracy: 0.7589 - 332ms/epoch - 9ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3925 - accuracy: 0.8396 - val_loss: 0.4748 - val_accuracy: 0.7589 - 351ms/epoch - 10ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3923 - accuracy: 0.8342 - val_loss: 0.4746 - val_accuracy: 0.7447 - 359ms/epoch - 10ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3921 - accuracy: 0.8396 - val_loss: 0.4746 - val_accuracy: 0.7447 - 330ms/epoch - 9ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3920 - accuracy: 0.8360 - val_loss: 0.4740 - val_accuracy: 0.7376 - 359ms/epoch - 10ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3919 - accuracy: 0.8324 - val_loss: 0.4741 - val_accuracy: 0.7376 - 345ms/epoch - 10ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3916 - accuracy: 0.8360 - val_loss: 0.4744 - val_accuracy: 0.7376 - 323ms/epoch - 9ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3914 - accuracy: 0.8396 - val_loss: 0.4747 - val_accuracy: 0.7447 - 310ms/epoch - 9ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3913 - accuracy: 0.8414 - val_loss: 0.4749 - val_accuracy: 0.7447 - 303ms/epoch - 8ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3915 - accuracy: 0.8431 - val_loss: 0.4750 - val_accuracy: 0.7376 - 295ms/epoch - 8ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3913 - accuracy: 0.8414 - val_loss: 0.4754 - val_accuracy: 0.7518 - 273ms/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3912 - accuracy: 0.8414 - val_loss: 0.4756 - val_accuracy: 0.7518 - 291ms/epoch - 8ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3909 - accuracy: 0.8414 - val_loss: 0.4755 - val_accuracy: 0.7447 - 281ms/epoch - 8ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3908 - accuracy: 0.8414 - val_loss: 0.4756 - val_accuracy: 0.7518 - 271ms/epoch - 8ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3906 - accuracy: 0.8414 - val_loss: 0.4755 - val_accuracy: 0.7447 - 271ms/epoch - 8ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3905 - accuracy: 0.8414 - val_loss: 0.4756 - val_accuracy: 0.7447 - 258ms/epoch - 7ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3902 - accuracy: 0.8414 - val_loss: 0.4755 - val_accuracy: 0.7518 - 317ms/epoch - 9ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3903 - accuracy: 0.8414 - val_loss: 0.4758 - val_accuracy: 0.7518 - 266ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3901 - accuracy: 0.8396 - val_loss: 0.4763 - val_accuracy: 0.7589 - 273ms/epoch - 8ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3901 - accuracy: 0.8396 - val_loss: 0.4757 - val_accuracy: 0.7589 - 291ms/epoch - 8ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3898 - accuracy: 0.8396 - val_loss: 0.4758 - val_accuracy: 0.7589 - 292ms/epoch - 8ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8396 - val_loss: 0.4761 - val_accuracy: 0.7660 - 316ms/epoch - 9ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3896 - accuracy: 0.8396 - val_loss: 0.4768 - val_accuracy: 0.7589 - 321ms/epoch - 9ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3896 - accuracy: 0.8396 - val_loss: 0.4763 - val_accuracy: 0.7589 - 333ms/epoch - 9ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3893 - accuracy: 0.8396 - val_loss: 0.4762 - val_accuracy: 0.7660 - 321ms/epoch - 9ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 0.7422 - accuracy: 0.5152 - val_loss: 0.6849 - val_accuracy: 0.6028 - 794ms/epoch - 22ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.7118 - accuracy: 0.5561 - val_loss: 0.6667 - val_accuracy: 0.6028 - 291ms/epoch - 8ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.6888 - accuracy: 0.5633 - val_loss: 0.6518 - val_accuracy: 0.6170 - 305ms/epoch - 8ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.6669 - accuracy: 0.5954 - val_loss: 0.6383 - val_accuracy: 0.6312 - 295ms/epoch - 8ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.6488 - accuracy: 0.6132 - val_loss: 0.6262 - val_accuracy: 0.6383 - 328ms/epoch - 9ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.6322 - accuracy: 0.6275 - val_loss: 0.6151 - val_accuracy: 0.6383 - 277ms/epoch - 8ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.6171 - accuracy: 0.6399 - val_loss: 0.6048 - val_accuracy: 0.6596 - 348ms/epoch - 10ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.6041 - accuracy: 0.6649 - val_loss: 0.5958 - val_accuracy: 0.6738 - 276ms/epoch - 8ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.5921 - accuracy: 0.6809 - val_loss: 0.5879 - val_accuracy: 0.6738 - 263ms/epoch - 7ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.5811 - accuracy: 0.6988 - val_loss: 0.5807 - val_accuracy: 0.7021 - 276ms/epoch - 8ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5708 - accuracy: 0.7112 - val_loss: 0.5743 - val_accuracy: 0.7092 - 265ms/epoch - 7ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5615 - accuracy: 0.7201 - val_loss: 0.5678 - val_accuracy: 0.7163 - 341ms/epoch - 9ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5526 - accuracy: 0.7291 - val_loss: 0.5617 - val_accuracy: 0.7305 - 296ms/epoch - 8ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5446 - accuracy: 0.7326 - val_loss: 0.5562 - val_accuracy: 0.7376 - 301ms/epoch - 8ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5373 - accuracy: 0.7398 - val_loss: 0.5523 - val_accuracy: 0.7234 - 331ms/epoch - 9ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.5304 - accuracy: 0.7504 - val_loss: 0.5478 - val_accuracy: 0.7305 - 311ms/epoch - 9ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.5242 - accuracy: 0.7558 - val_loss: 0.5436 - val_accuracy: 0.7305 - 287ms/epoch - 8ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.5191 - accuracy: 0.7594 - val_loss: 0.5399 - val_accuracy: 0.7305 - 287ms/epoch - 8ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.5133 - accuracy: 0.7611 - val_loss: 0.5366 - val_accuracy: 0.7305 - 341ms/epoch - 9ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.5080 - accuracy: 0.7665 - val_loss: 0.5332 - val_accuracy: 0.7305 - 293ms/epoch - 8ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.5034 - accuracy: 0.7701 - val_loss: 0.5300 - val_accuracy: 0.7305 - 317ms/epoch - 9ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4991 - accuracy: 0.7754 - val_loss: 0.5271 - val_accuracy: 0.7518 - 359ms/epoch - 10ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4948 - accuracy: 0.7736 - val_loss: 0.5244 - val_accuracy: 0.7518 - 337ms/epoch - 9ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4905 - accuracy: 0.7807 - val_loss: 0.5215 - val_accuracy: 0.7660 - 334ms/epoch - 9ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4869 - accuracy: 0.7843 - val_loss: 0.5192 - val_accuracy: 0.7660 - 365ms/epoch - 10ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4834 - accuracy: 0.7879 - val_loss: 0.5170 - val_accuracy: 0.7660 - 295ms/epoch - 8ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4801 - accuracy: 0.7843 - val_loss: 0.5142 - val_accuracy: 0.7660 - 280ms/epoch - 8ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4775 - accuracy: 0.7825 - val_loss: 0.5120 - val_accuracy: 0.7730 - 330ms/epoch - 9ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4742 - accuracy: 0.7843 - val_loss: 0.5102 - val_accuracy: 0.7660 - 273ms/epoch - 8ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4711 - accuracy: 0.7897 - val_loss: 0.5080 - val_accuracy: 0.7660 - 280ms/epoch - 8ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4685 - accuracy: 0.7879 - val_loss: 0.5063 - val_accuracy: 0.7660 - 273ms/epoch - 8ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4660 - accuracy: 0.7932 - val_loss: 0.5051 - val_accuracy: 0.7660 - 320ms/epoch - 9ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4636 - accuracy: 0.7879 - val_loss: 0.5032 - val_accuracy: 0.7660 - 302ms/epoch - 8ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4613 - accuracy: 0.7950 - val_loss: 0.5017 - val_accuracy: 0.7660 - 276ms/epoch - 8ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4589 - accuracy: 0.7914 - val_loss: 0.5003 - val_accuracy: 0.7730 - 302ms/epoch - 8ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4568 - accuracy: 0.7968 - val_loss: 0.4988 - val_accuracy: 0.7730 - 277ms/epoch - 8ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4548 - accuracy: 0.7968 - val_loss: 0.4983 - val_accuracy: 0.7801 - 275ms/epoch - 8ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4527 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7801 - 280ms/epoch - 8ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4507 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7730 - 291ms/epoch - 8ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4489 - accuracy: 0.8004 - val_loss: 0.4948 - val_accuracy: 0.7801 - 321ms/epoch - 9ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4472 - accuracy: 0.7986 - val_loss: 0.4941 - val_accuracy: 0.7660 - 278ms/epoch - 8ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4455 - accuracy: 0.7932 - val_loss: 0.4930 - val_accuracy: 0.7660 - 291ms/epoch - 8ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4444 - accuracy: 0.7950 - val_loss: 0.4921 - val_accuracy: 0.7589 - 304ms/epoch - 8ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4424 - accuracy: 0.7968 - val_loss: 0.4908 - val_accuracy: 0.7730 - 287ms/epoch - 8ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.4902 - val_accuracy: 0.7660 - 287ms/epoch - 8ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4393 - accuracy: 0.8004 - val_loss: 0.4888 - val_accuracy: 0.7660 - 300ms/epoch - 8ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4377 - accuracy: 0.8004 - val_loss: 0.4882 - val_accuracy: 0.7660 - 337ms/epoch - 9ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4373 - accuracy: 0.8004 - val_loss: 0.4880 - val_accuracy: 0.7872 - 294ms/epoch - 8ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4352 - accuracy: 0.8057 - val_loss: 0.4873 - val_accuracy: 0.7801 - 282ms/epoch - 8ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4341 - accuracy: 0.8039 - val_loss: 0.4869 - val_accuracy: 0.7872 - 307ms/epoch - 9ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4327 - accuracy: 0.8021 - val_loss: 0.4856 - val_accuracy: 0.7801 - 280ms/epoch - 8ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4318 - accuracy: 0.8004 - val_loss: 0.4842 - val_accuracy: 0.7660 - 293ms/epoch - 8ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4305 - accuracy: 0.8021 - val_loss: 0.4834 - val_accuracy: 0.7660 - 281ms/epoch - 8ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4293 - accuracy: 0.8021 - val_loss: 0.4830 - val_accuracy: 0.7660 - 337ms/epoch - 9ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4279 - accuracy: 0.8057 - val_loss: 0.4825 - val_accuracy: 0.7801 - 278ms/epoch - 8ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4273 - accuracy: 0.8039 - val_loss: 0.4818 - val_accuracy: 0.7660 - 276ms/epoch - 8ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4263 - accuracy: 0.8075 - val_loss: 0.4817 - val_accuracy: 0.7660 - 282ms/epoch - 8ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4252 - accuracy: 0.8057 - val_loss: 0.4813 - val_accuracy: 0.7730 - 261ms/epoch - 7ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4243 - accuracy: 0.8057 - val_loss: 0.4809 - val_accuracy: 0.7660 - 269ms/epoch - 7ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4234 - accuracy: 0.8039 - val_loss: 0.4802 - val_accuracy: 0.7660 - 276ms/epoch - 8ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4225 - accuracy: 0.8039 - val_loss: 0.4798 - val_accuracy: 0.7660 - 333ms/epoch - 9ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4220 - accuracy: 0.8039 - val_loss: 0.4793 - val_accuracy: 0.7660 - 355ms/epoch - 10ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4210 - accuracy: 0.8039 - val_loss: 0.4789 - val_accuracy: 0.7589 - 336ms/epoch - 9ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4202 - accuracy: 0.8057 - val_loss: 0.4782 - val_accuracy: 0.7589 - 295ms/epoch - 8ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4192 - accuracy: 0.8093 - val_loss: 0.4779 - val_accuracy: 0.7589 - 373ms/epoch - 10ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4185 - accuracy: 0.8075 - val_loss: 0.4775 - val_accuracy: 0.7589 - 346ms/epoch - 10ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4180 - accuracy: 0.8075 - val_loss: 0.4773 - val_accuracy: 0.7589 - 312ms/epoch - 9ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4171 - accuracy: 0.8093 - val_loss: 0.4769 - val_accuracy: 0.7589 - 355ms/epoch - 10ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4168 - accuracy: 0.8128 - val_loss: 0.4763 - val_accuracy: 0.7589 - 288ms/epoch - 8ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4158 - accuracy: 0.8111 - val_loss: 0.4765 - val_accuracy: 0.7660 - 278ms/epoch - 8ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4150 - accuracy: 0.8128 - val_loss: 0.4763 - val_accuracy: 0.7660 - 289ms/epoch - 8ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4147 - accuracy: 0.8111 - val_loss: 0.4761 - val_accuracy: 0.7660 - 262ms/epoch - 7ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4139 - accuracy: 0.8182 - val_loss: 0.4766 - val_accuracy: 0.7730 - 271ms/epoch - 8ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4136 - accuracy: 0.8200 - val_loss: 0.4761 - val_accuracy: 0.7660 - 262ms/epoch - 7ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4129 - accuracy: 0.8200 - val_loss: 0.4751 - val_accuracy: 0.7660 - 308ms/epoch - 9ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4123 - accuracy: 0.8128 - val_loss: 0.4744 - val_accuracy: 0.7589 - 266ms/epoch - 7ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4117 - accuracy: 0.8128 - val_loss: 0.4744 - val_accuracy: 0.7589 - 290ms/epoch - 8ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4115 - accuracy: 0.8182 - val_loss: 0.4740 - val_accuracy: 0.7518 - 275ms/epoch - 8ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4113 - accuracy: 0.8200 - val_loss: 0.4736 - val_accuracy: 0.7447 - 324ms/epoch - 9ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4104 - accuracy: 0.8164 - val_loss: 0.4739 - val_accuracy: 0.7589 - 285ms/epoch - 8ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4099 - accuracy: 0.8182 - val_loss: 0.4744 - val_accuracy: 0.7589 - 268ms/epoch - 7ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4094 - accuracy: 0.8182 - val_loss: 0.4744 - val_accuracy: 0.7589 - 290ms/epoch - 8ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4094 - accuracy: 0.8182 - val_loss: 0.4734 - val_accuracy: 0.7447 - 312ms/epoch - 9ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4089 - accuracy: 0.8164 - val_loss: 0.4734 - val_accuracy: 0.7589 - 273ms/epoch - 8ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4082 - accuracy: 0.8146 - val_loss: 0.4734 - val_accuracy: 0.7518 - 287ms/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4077 - accuracy: 0.8164 - val_loss: 0.4734 - val_accuracy: 0.7518 - 299ms/epoch - 8ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4071 - accuracy: 0.8200 - val_loss: 0.4741 - val_accuracy: 0.7518 - 298ms/epoch - 8ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4072 - accuracy: 0.8146 - val_loss: 0.4741 - val_accuracy: 0.7518 - 268ms/epoch - 7ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4066 - accuracy: 0.8182 - val_loss: 0.4733 - val_accuracy: 0.7518 - 265ms/epoch - 7ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4062 - accuracy: 0.8182 - val_loss: 0.4732 - val_accuracy: 0.7518 - 310ms/epoch - 9ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4060 - accuracy: 0.8182 - val_loss: 0.4732 - val_accuracy: 0.7518 - 269ms/epoch - 7ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4058 - accuracy: 0.8200 - val_loss: 0.4732 - val_accuracy: 0.7518 - 304ms/epoch - 8ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4058 - accuracy: 0.8164 - val_loss: 0.4739 - val_accuracy: 0.7589 - 303ms/epoch - 8ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.4054 - accuracy: 0.8111 - val_loss: 0.4728 - val_accuracy: 0.7518 - 309ms/epoch - 9ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4045 - accuracy: 0.8164 - val_loss: 0.4721 - val_accuracy: 0.7447 - 267ms/epoch - 7ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.4046 - accuracy: 0.8146 - val_loss: 0.4726 - val_accuracy: 0.7589 - 322ms/epoch - 9ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4042 - accuracy: 0.8182 - val_loss: 0.4725 - val_accuracy: 0.7518 - 334ms/epoch - 9ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.4039 - accuracy: 0.8146 - val_loss: 0.4723 - val_accuracy: 0.7589 - 304ms/epoch - 8ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.4038 - accuracy: 0.8182 - val_loss: 0.4722 - val_accuracy: 0.7518 - 274ms/epoch - 8ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.4032 - accuracy: 0.8164 - val_loss: 0.4721 - val_accuracy: 0.7518 - 279ms/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.4032 - accuracy: 0.8182 - val_loss: 0.4722 - val_accuracy: 0.7589 - 295ms/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.4027 - accuracy: 0.8146 - val_loss: 0.4720 - val_accuracy: 0.7589 - 286ms/epoch - 8ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.4024 - accuracy: 0.8128 - val_loss: 0.4716 - val_accuracy: 0.7518 - 280ms/epoch - 8ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.4024 - accuracy: 0.8164 - val_loss: 0.4713 - val_accuracy: 0.7518 - 328ms/epoch - 9ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.4020 - accuracy: 0.8146 - val_loss: 0.4717 - val_accuracy: 0.7518 - 271ms/epoch - 8ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.4021 - accuracy: 0.8182 - val_loss: 0.4720 - val_accuracy: 0.7589 - 277ms/epoch - 8ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.4014 - accuracy: 0.8164 - val_loss: 0.4705 - val_accuracy: 0.7518 - 269ms/epoch - 7ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.4012 - accuracy: 0.8164 - val_loss: 0.4704 - val_accuracy: 0.7518 - 267ms/epoch - 7ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.4009 - accuracy: 0.8146 - val_loss: 0.4700 - val_accuracy: 0.7518 - 320ms/epoch - 9ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.4008 - accuracy: 0.8182 - val_loss: 0.4704 - val_accuracy: 0.7518 - 282ms/epoch - 8ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.4007 - accuracy: 0.8146 - val_loss: 0.4707 - val_accuracy: 0.7660 - 275ms/epoch - 8ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.4004 - accuracy: 0.8182 - val_loss: 0.4701 - val_accuracy: 0.7589 - 309ms/epoch - 9ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3999 - accuracy: 0.8200 - val_loss: 0.4703 - val_accuracy: 0.7589 - 274ms/epoch - 8ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3997 - accuracy: 0.8182 - val_loss: 0.4699 - val_accuracy: 0.7518 - 254ms/epoch - 7ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3996 - accuracy: 0.8182 - val_loss: 0.4700 - val_accuracy: 0.7518 - 276ms/epoch - 8ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3994 - accuracy: 0.8164 - val_loss: 0.4704 - val_accuracy: 0.7589 - 282ms/epoch - 8ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3990 - accuracy: 0.8200 - val_loss: 0.4706 - val_accuracy: 0.7589 - 303ms/epoch - 8ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3988 - accuracy: 0.8146 - val_loss: 0.4707 - val_accuracy: 0.7589 - 269ms/epoch - 7ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3989 - accuracy: 0.8128 - val_loss: 0.4708 - val_accuracy: 0.7589 - 316ms/epoch - 9ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3990 - accuracy: 0.8128 - val_loss: 0.4719 - val_accuracy: 0.7730 - 279ms/epoch - 8ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3992 - accuracy: 0.8146 - val_loss: 0.4720 - val_accuracy: 0.7801 - 274ms/epoch - 8ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3986 - accuracy: 0.8146 - val_loss: 0.4714 - val_accuracy: 0.7660 - 276ms/epoch - 8ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3985 - accuracy: 0.8111 - val_loss: 0.4710 - val_accuracy: 0.7660 - 270ms/epoch - 7ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3983 - accuracy: 0.8111 - val_loss: 0.4704 - val_accuracy: 0.7660 - 287ms/epoch - 8ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3980 - accuracy: 0.8128 - val_loss: 0.4704 - val_accuracy: 0.7660 - 270ms/epoch - 7ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3980 - accuracy: 0.8217 - val_loss: 0.4704 - val_accuracy: 0.7589 - 277ms/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3989 - accuracy: 0.8164 - val_loss: 0.4691 - val_accuracy: 0.7589 - 306ms/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3977 - accuracy: 0.8164 - val_loss: 0.4696 - val_accuracy: 0.7660 - 264ms/epoch - 7ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3979 - accuracy: 0.8111 - val_loss: 0.4713 - val_accuracy: 0.7660 - 287ms/epoch - 8ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3974 - accuracy: 0.8164 - val_loss: 0.4714 - val_accuracy: 0.7660 - 264ms/epoch - 7ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3972 - accuracy: 0.8146 - val_loss: 0.4713 - val_accuracy: 0.7660 - 270ms/epoch - 7ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3969 - accuracy: 0.8164 - val_loss: 0.4716 - val_accuracy: 0.7660 - 327ms/epoch - 9ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3967 - accuracy: 0.8146 - val_loss: 0.4718 - val_accuracy: 0.7660 - 273ms/epoch - 8ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3967 - accuracy: 0.8182 - val_loss: 0.4718 - val_accuracy: 0.7660 - 307ms/epoch - 9ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8200 - val_loss: 0.4716 - val_accuracy: 0.7660 - 292ms/epoch - 8ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8217 - val_loss: 0.4722 - val_accuracy: 0.7660 - 270ms/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3963 - accuracy: 0.8200 - val_loss: 0.4719 - val_accuracy: 0.7660 - 282ms/epoch - 8ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3960 - accuracy: 0.8182 - val_loss: 0.4723 - val_accuracy: 0.7660 - 268ms/epoch - 7ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8200 - val_loss: 0.4722 - val_accuracy: 0.7660 - 281ms/epoch - 8ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8164 - val_loss: 0.4733 - val_accuracy: 0.7660 - 308ms/epoch - 9ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8164 - val_loss: 0.4731 - val_accuracy: 0.7660 - 288ms/epoch - 8ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3956 - accuracy: 0.8128 - val_loss: 0.4735 - val_accuracy: 0.7660 - 323ms/epoch - 9ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3956 - accuracy: 0.8111 - val_loss: 0.4735 - val_accuracy: 0.7660 - 267ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3951 - accuracy: 0.8164 - val_loss: 0.4732 - val_accuracy: 0.7660 - 282ms/epoch - 8ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3950 - accuracy: 0.8182 - val_loss: 0.4736 - val_accuracy: 0.7660 - 270ms/epoch - 7ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3949 - accuracy: 0.8146 - val_loss: 0.4734 - val_accuracy: 0.7660 - 280ms/epoch - 8ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8164 - val_loss: 0.4735 - val_accuracy: 0.7660 - 302ms/epoch - 8ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3949 - accuracy: 0.8217 - val_loss: 0.4736 - val_accuracy: 0.7518 - 282ms/epoch - 8ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3947 - accuracy: 0.8235 - val_loss: 0.4737 - val_accuracy: 0.7589 - 313ms/epoch - 9ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3943 - accuracy: 0.8164 - val_loss: 0.4741 - val_accuracy: 0.7589 - 266ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "history_base = model_base.fit(x=X_train_base, y=y_train_base, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_per = model_per.fit(x=X_train_per, y=y_train_per, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_mdi = model_mdi.fit(x=X_train_mdi, y=y_train_mdi, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Testdata using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "---------Base-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------Permutation-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------MDI-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/root/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[137,   0],\n",
       "       [164,   0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_base = model_base.predict(X_test_base)\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "\n",
    "print(\"---------Base-Prediction----------\")\n",
    "evaluate_classification_result(y_test_base,pred_base,classes=nn_data_base[\"target_names\"])\n",
    "print(\"---------Permutation-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_per,pred_per,classes=nn_data_per[\"target_names\"])\n",
    "print(\"---------MDI-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_mdi,pred_mdi,classes=nn_data_mdi[\"target_names\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_base = model_base.predict(X_test_base)\n",
    "classes_base = [1 if i > 0.5  else 0 for i in pred_base]\n",
    "\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "classes_per = [1 if i > 0.5  else 0 for i in pred_per]\n",
    "\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "classes_mdi = [1 if i > 0.5  else 0 for i in pred_mdi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_per.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_per):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_per\n",
    "result_df[\"PRED\"] = classes_per\n",
    "\n",
    "result_df.to_csv(result_dir/\"ACHE/fe_rf_per_nn.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_mdi.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_mdi):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_mdi\n",
    "result_df[\"PRED\"] = classes_mdi\n",
    "\n",
    "result_df.to_csv(result_dir / \"ACHE/fe_rf_mdi_nn.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activity_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
