{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 10:54:16.592869: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-20 10:54:16.592949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-20 10:54:16.594662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-20 10:54:16.606115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 10:54:18.817667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from pyMLaux import plot_history, evaluate_classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dynamic path\n",
    "base_dir = Path(os.getcwd()).parents[3]\n",
    "data_dir = base_dir / \"data/source/\"\n",
    "result_dir = base_dir / \"data/results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load & prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code needs to be adapted for each protein-ligand complex individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data_raw_mdi = pd.read_csv(data_dir/\"ACHE/ache_mdi.csv\")\n",
    "nn_data_raw_per = pd.read_csv(data_dir/\"ACHE/ache_per.csv\")\n",
    "nn_data_raw = pd.read_csv(data_dir/\"ACHE/ache.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {'inactive':0,'active':1}\n",
    "\n",
    "nn_data_per = {'data': np.array(nn_data_raw_per.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_per.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_per.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_mdi = {'data': np.array(nn_data_raw_mdi.iloc[:, 1:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw_mdi.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw_mdi.columns[1:-1],\n",
    "             'target_names': ['inactive', 'active']}\n",
    "\n",
    "nn_data_base = {'data': np.array(nn_data_raw.iloc[:, 2:-1]),\n",
    "             'target': np.array([lookup[y] for y in nn_data_raw.iloc[0:,-1]]),\n",
    "             'feature_names': nn_data_raw.columns[2:-1],\n",
    "             'target_names': ['inactive', 'active']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train- and test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(nn_data_base['data'], nn_data_base['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_mdi, X_test_mdi, y_train_mdi, y_test_mdi = train_test_split(nn_data_mdi['data'], nn_data_mdi['target'],\n",
    "                                                    test_size=0.3, random_state=4232)\n",
    "\n",
    "X_train_per, X_test_per, y_train_per, y_test_per = train_test_split(nn_data_per['data'], nn_data_per['target'],\n",
    "                                                    test_size=0.3, random_state=4232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and apply neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 10:54:21.371480: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.450422: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.451225: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.454685: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.454889: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.455636: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.753930: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.754161: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.754188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-20 10:54:21.754822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 10:54:21.756017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9716 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model_base = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_base['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_base.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_per = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_per['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_per.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_mdi = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(nn_data_mdi['data'].shape[1], )),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_mdi.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 10:54:24.946839: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-20 10:54:25.797570: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fd5b4556c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-20 10:54:25.797642: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-04-20 10:54:25.810635: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-20 10:54:25.841412: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713603266.094589   16746 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 3s - loss: 0.6751 - accuracy: 0.5758 - val_loss: 0.6760 - val_accuracy: 0.5177 - 3s/epoch - 95ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.6470 - accuracy: 0.6488 - val_loss: 0.6583 - val_accuracy: 0.5816 - 410ms/epoch - 11ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.6235 - accuracy: 0.6916 - val_loss: 0.6416 - val_accuracy: 0.6099 - 408ms/epoch - 11ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.6035 - accuracy: 0.7112 - val_loss: 0.6263 - val_accuracy: 0.6525 - 382ms/epoch - 11ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.5853 - accuracy: 0.7219 - val_loss: 0.6132 - val_accuracy: 0.6950 - 401ms/epoch - 11ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.5689 - accuracy: 0.7415 - val_loss: 0.6003 - val_accuracy: 0.6950 - 395ms/epoch - 11ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.5542 - accuracy: 0.7415 - val_loss: 0.5900 - val_accuracy: 0.6950 - 385ms/epoch - 11ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.5410 - accuracy: 0.7522 - val_loss: 0.5805 - val_accuracy: 0.7092 - 387ms/epoch - 11ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.5293 - accuracy: 0.7576 - val_loss: 0.5717 - val_accuracy: 0.7092 - 383ms/epoch - 11ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.5193 - accuracy: 0.7825 - val_loss: 0.5638 - val_accuracy: 0.7163 - 380ms/epoch - 11ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5104 - accuracy: 0.7914 - val_loss: 0.5569 - val_accuracy: 0.7305 - 383ms/epoch - 11ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5017 - accuracy: 0.7914 - val_loss: 0.5504 - val_accuracy: 0.7376 - 391ms/epoch - 11ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.4938 - accuracy: 0.7932 - val_loss: 0.5447 - val_accuracy: 0.7376 - 385ms/epoch - 11ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.4870 - accuracy: 0.7986 - val_loss: 0.5394 - val_accuracy: 0.7447 - 383ms/epoch - 11ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.4808 - accuracy: 0.8021 - val_loss: 0.5355 - val_accuracy: 0.7376 - 394ms/epoch - 11ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.4746 - accuracy: 0.8004 - val_loss: 0.5312 - val_accuracy: 0.7518 - 382ms/epoch - 11ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.4693 - accuracy: 0.8004 - val_loss: 0.5274 - val_accuracy: 0.7518 - 390ms/epoch - 11ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.4646 - accuracy: 0.8111 - val_loss: 0.5238 - val_accuracy: 0.7518 - 385ms/epoch - 11ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.4596 - accuracy: 0.8128 - val_loss: 0.5203 - val_accuracy: 0.7589 - 377ms/epoch - 10ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.4555 - accuracy: 0.8057 - val_loss: 0.5169 - val_accuracy: 0.7589 - 374ms/epoch - 10ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.4511 - accuracy: 0.8146 - val_loss: 0.5134 - val_accuracy: 0.7589 - 367ms/epoch - 10ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4480 - accuracy: 0.8128 - val_loss: 0.5114 - val_accuracy: 0.7518 - 369ms/epoch - 10ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4443 - accuracy: 0.8164 - val_loss: 0.5089 - val_accuracy: 0.7518 - 380ms/epoch - 11ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4414 - accuracy: 0.8164 - val_loss: 0.5063 - val_accuracy: 0.7518 - 368ms/epoch - 10ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4379 - accuracy: 0.8235 - val_loss: 0.5037 - val_accuracy: 0.7518 - 398ms/epoch - 11ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4349 - accuracy: 0.8200 - val_loss: 0.5017 - val_accuracy: 0.7518 - 381ms/epoch - 11ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4324 - accuracy: 0.8253 - val_loss: 0.4997 - val_accuracy: 0.7518 - 383ms/epoch - 11ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4295 - accuracy: 0.8217 - val_loss: 0.4983 - val_accuracy: 0.7589 - 380ms/epoch - 11ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4272 - accuracy: 0.8164 - val_loss: 0.4965 - val_accuracy: 0.7589 - 377ms/epoch - 10ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4255 - accuracy: 0.8235 - val_loss: 0.4942 - val_accuracy: 0.7518 - 378ms/epoch - 10ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4226 - accuracy: 0.8217 - val_loss: 0.4928 - val_accuracy: 0.7518 - 363ms/epoch - 10ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4211 - accuracy: 0.8235 - val_loss: 0.4913 - val_accuracy: 0.7518 - 385ms/epoch - 11ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4184 - accuracy: 0.8235 - val_loss: 0.4898 - val_accuracy: 0.7589 - 381ms/epoch - 11ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4165 - accuracy: 0.8253 - val_loss: 0.4880 - val_accuracy: 0.7518 - 372ms/epoch - 10ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4142 - accuracy: 0.8271 - val_loss: 0.4867 - val_accuracy: 0.7518 - 380ms/epoch - 11ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4124 - accuracy: 0.8271 - val_loss: 0.4857 - val_accuracy: 0.7518 - 370ms/epoch - 10ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4107 - accuracy: 0.8289 - val_loss: 0.4841 - val_accuracy: 0.7518 - 399ms/epoch - 11ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4092 - accuracy: 0.8253 - val_loss: 0.4831 - val_accuracy: 0.7518 - 369ms/epoch - 10ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4071 - accuracy: 0.8307 - val_loss: 0.4820 - val_accuracy: 0.7518 - 389ms/epoch - 11ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4057 - accuracy: 0.8271 - val_loss: 0.4802 - val_accuracy: 0.7518 - 369ms/epoch - 10ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4044 - accuracy: 0.8271 - val_loss: 0.4793 - val_accuracy: 0.7518 - 365ms/epoch - 10ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4025 - accuracy: 0.8289 - val_loss: 0.4781 - val_accuracy: 0.7518 - 366ms/epoch - 10ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4011 - accuracy: 0.8289 - val_loss: 0.4767 - val_accuracy: 0.7518 - 339ms/epoch - 9ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.3998 - accuracy: 0.8271 - val_loss: 0.4766 - val_accuracy: 0.7589 - 332ms/epoch - 9ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.3989 - accuracy: 0.8271 - val_loss: 0.4756 - val_accuracy: 0.7518 - 338ms/epoch - 9ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.3970 - accuracy: 0.8307 - val_loss: 0.4747 - val_accuracy: 0.7660 - 336ms/epoch - 9ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.3961 - accuracy: 0.8289 - val_loss: 0.4740 - val_accuracy: 0.7660 - 368ms/epoch - 10ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.3950 - accuracy: 0.8324 - val_loss: 0.4735 - val_accuracy: 0.7589 - 353ms/epoch - 10ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.3936 - accuracy: 0.8307 - val_loss: 0.4723 - val_accuracy: 0.7660 - 331ms/epoch - 9ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.3924 - accuracy: 0.8307 - val_loss: 0.4714 - val_accuracy: 0.7660 - 345ms/epoch - 10ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.3915 - accuracy: 0.8289 - val_loss: 0.4709 - val_accuracy: 0.7660 - 341ms/epoch - 9ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.3902 - accuracy: 0.8271 - val_loss: 0.4700 - val_accuracy: 0.7660 - 356ms/epoch - 10ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.3892 - accuracy: 0.8289 - val_loss: 0.4692 - val_accuracy: 0.7589 - 379ms/epoch - 11ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.3881 - accuracy: 0.8289 - val_loss: 0.4684 - val_accuracy: 0.7660 - 371ms/epoch - 10ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.3870 - accuracy: 0.8289 - val_loss: 0.4676 - val_accuracy: 0.7589 - 361ms/epoch - 10ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.3862 - accuracy: 0.8289 - val_loss: 0.4675 - val_accuracy: 0.7589 - 363ms/epoch - 10ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.3853 - accuracy: 0.8289 - val_loss: 0.4669 - val_accuracy: 0.7660 - 372ms/epoch - 10ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.3844 - accuracy: 0.8307 - val_loss: 0.4662 - val_accuracy: 0.7660 - 362ms/epoch - 10ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.3832 - accuracy: 0.8324 - val_loss: 0.4658 - val_accuracy: 0.7730 - 375ms/epoch - 10ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.3824 - accuracy: 0.8307 - val_loss: 0.4659 - val_accuracy: 0.7589 - 394ms/epoch - 11ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.3819 - accuracy: 0.8396 - val_loss: 0.4658 - val_accuracy: 0.7589 - 392ms/epoch - 11ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.3813 - accuracy: 0.8324 - val_loss: 0.4649 - val_accuracy: 0.7730 - 405ms/epoch - 11ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.3795 - accuracy: 0.8360 - val_loss: 0.4648 - val_accuracy: 0.7589 - 380ms/epoch - 11ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.3789 - accuracy: 0.8360 - val_loss: 0.4637 - val_accuracy: 0.7660 - 389ms/epoch - 11ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.3780 - accuracy: 0.8307 - val_loss: 0.4627 - val_accuracy: 0.7730 - 390ms/epoch - 11ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.3772 - accuracy: 0.8324 - val_loss: 0.4623 - val_accuracy: 0.7730 - 387ms/epoch - 11ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.3764 - accuracy: 0.8342 - val_loss: 0.4619 - val_accuracy: 0.7730 - 413ms/epoch - 11ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.3756 - accuracy: 0.8342 - val_loss: 0.4616 - val_accuracy: 0.7801 - 411ms/epoch - 11ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.3751 - accuracy: 0.8378 - val_loss: 0.4621 - val_accuracy: 0.7660 - 423ms/epoch - 12ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.3739 - accuracy: 0.8342 - val_loss: 0.4609 - val_accuracy: 0.7730 - 419ms/epoch - 12ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.3736 - accuracy: 0.8414 - val_loss: 0.4602 - val_accuracy: 0.7801 - 435ms/epoch - 12ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.3731 - accuracy: 0.8396 - val_loss: 0.4599 - val_accuracy: 0.7801 - 434ms/epoch - 12ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.3720 - accuracy: 0.8396 - val_loss: 0.4600 - val_accuracy: 0.7730 - 433ms/epoch - 12ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.3712 - accuracy: 0.8396 - val_loss: 0.4592 - val_accuracy: 0.7730 - 434ms/epoch - 12ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.3707 - accuracy: 0.8431 - val_loss: 0.4581 - val_accuracy: 0.7872 - 439ms/epoch - 12ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.3702 - accuracy: 0.8396 - val_loss: 0.4580 - val_accuracy: 0.7801 - 417ms/epoch - 12ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.3699 - accuracy: 0.8449 - val_loss: 0.4574 - val_accuracy: 0.7801 - 405ms/epoch - 11ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.3689 - accuracy: 0.8396 - val_loss: 0.4574 - val_accuracy: 0.7801 - 439ms/epoch - 12ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.3679 - accuracy: 0.8378 - val_loss: 0.4583 - val_accuracy: 0.7660 - 424ms/epoch - 12ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.3678 - accuracy: 0.8360 - val_loss: 0.4587 - val_accuracy: 0.7660 - 422ms/epoch - 12ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.3671 - accuracy: 0.8396 - val_loss: 0.4581 - val_accuracy: 0.7660 - 426ms/epoch - 12ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.3663 - accuracy: 0.8378 - val_loss: 0.4572 - val_accuracy: 0.7730 - 434ms/epoch - 12ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.3659 - accuracy: 0.8396 - val_loss: 0.4566 - val_accuracy: 0.7801 - 412ms/epoch - 11ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.3654 - accuracy: 0.8431 - val_loss: 0.4557 - val_accuracy: 0.7730 - 436ms/epoch - 12ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.3647 - accuracy: 0.8431 - val_loss: 0.4557 - val_accuracy: 0.7801 - 435ms/epoch - 12ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.3642 - accuracy: 0.8414 - val_loss: 0.4559 - val_accuracy: 0.7730 - 413ms/epoch - 11ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.3635 - accuracy: 0.8414 - val_loss: 0.4548 - val_accuracy: 0.7801 - 416ms/epoch - 12ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.3629 - accuracy: 0.8414 - val_loss: 0.4552 - val_accuracy: 0.7801 - 425ms/epoch - 12ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.3627 - accuracy: 0.8414 - val_loss: 0.4546 - val_accuracy: 0.7730 - 412ms/epoch - 11ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.3624 - accuracy: 0.8431 - val_loss: 0.4551 - val_accuracy: 0.7730 - 414ms/epoch - 12ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.3620 - accuracy: 0.8431 - val_loss: 0.4537 - val_accuracy: 0.7801 - 438ms/epoch - 12ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.3611 - accuracy: 0.8467 - val_loss: 0.4548 - val_accuracy: 0.7730 - 426ms/epoch - 12ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.3605 - accuracy: 0.8414 - val_loss: 0.4550 - val_accuracy: 0.7660 - 426ms/epoch - 12ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.3602 - accuracy: 0.8449 - val_loss: 0.4546 - val_accuracy: 0.7730 - 468ms/epoch - 13ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.3600 - accuracy: 0.8449 - val_loss: 0.4534 - val_accuracy: 0.7730 - 412ms/epoch - 11ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.3592 - accuracy: 0.8449 - val_loss: 0.4534 - val_accuracy: 0.7730 - 412ms/epoch - 11ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.3587 - accuracy: 0.8467 - val_loss: 0.4537 - val_accuracy: 0.7660 - 441ms/epoch - 12ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.3582 - accuracy: 0.8467 - val_loss: 0.4535 - val_accuracy: 0.7660 - 444ms/epoch - 12ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.3577 - accuracy: 0.8485 - val_loss: 0.4525 - val_accuracy: 0.7730 - 422ms/epoch - 12ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.3577 - accuracy: 0.8449 - val_loss: 0.4521 - val_accuracy: 0.7730 - 411ms/epoch - 11ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.3570 - accuracy: 0.8467 - val_loss: 0.4516 - val_accuracy: 0.7730 - 416ms/epoch - 12ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.3564 - accuracy: 0.8485 - val_loss: 0.4525 - val_accuracy: 0.7660 - 428ms/epoch - 12ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.3560 - accuracy: 0.8414 - val_loss: 0.4525 - val_accuracy: 0.7660 - 420ms/epoch - 12ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.3560 - accuracy: 0.8378 - val_loss: 0.4529 - val_accuracy: 0.7589 - 400ms/epoch - 11ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3556 - accuracy: 0.8414 - val_loss: 0.4524 - val_accuracy: 0.7660 - 406ms/epoch - 11ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3552 - accuracy: 0.8414 - val_loss: 0.4513 - val_accuracy: 0.7660 - 415ms/epoch - 12ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3544 - accuracy: 0.8431 - val_loss: 0.4509 - val_accuracy: 0.7660 - 435ms/epoch - 12ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3540 - accuracy: 0.8467 - val_loss: 0.4506 - val_accuracy: 0.7730 - 434ms/epoch - 12ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3537 - accuracy: 0.8467 - val_loss: 0.4503 - val_accuracy: 0.7730 - 426ms/epoch - 12ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3530 - accuracy: 0.8449 - val_loss: 0.4495 - val_accuracy: 0.7730 - 420ms/epoch - 12ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3527 - accuracy: 0.8485 - val_loss: 0.4491 - val_accuracy: 0.7730 - 414ms/epoch - 11ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3523 - accuracy: 0.8467 - val_loss: 0.4490 - val_accuracy: 0.7730 - 425ms/epoch - 12ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3518 - accuracy: 0.8485 - val_loss: 0.4486 - val_accuracy: 0.7730 - 451ms/epoch - 13ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3515 - accuracy: 0.8449 - val_loss: 0.4492 - val_accuracy: 0.7730 - 426ms/epoch - 12ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3514 - accuracy: 0.8467 - val_loss: 0.4481 - val_accuracy: 0.7730 - 432ms/epoch - 12ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3508 - accuracy: 0.8431 - val_loss: 0.4478 - val_accuracy: 0.7801 - 436ms/epoch - 12ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3515 - accuracy: 0.8449 - val_loss: 0.4480 - val_accuracy: 0.7730 - 468ms/epoch - 13ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3505 - accuracy: 0.8449 - val_loss: 0.4466 - val_accuracy: 0.7801 - 416ms/epoch - 12ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3497 - accuracy: 0.8467 - val_loss: 0.4470 - val_accuracy: 0.7801 - 407ms/epoch - 11ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3498 - accuracy: 0.8449 - val_loss: 0.4472 - val_accuracy: 0.7730 - 425ms/epoch - 12ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3489 - accuracy: 0.8449 - val_loss: 0.4464 - val_accuracy: 0.7801 - 435ms/epoch - 12ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3487 - accuracy: 0.8467 - val_loss: 0.4459 - val_accuracy: 0.7801 - 437ms/epoch - 12ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3484 - accuracy: 0.8467 - val_loss: 0.4460 - val_accuracy: 0.7801 - 435ms/epoch - 12ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3479 - accuracy: 0.8467 - val_loss: 0.4459 - val_accuracy: 0.7801 - 459ms/epoch - 13ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3476 - accuracy: 0.8467 - val_loss: 0.4452 - val_accuracy: 0.7801 - 443ms/epoch - 12ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3475 - accuracy: 0.8467 - val_loss: 0.4458 - val_accuracy: 0.7801 - 426ms/epoch - 12ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3471 - accuracy: 0.8467 - val_loss: 0.4462 - val_accuracy: 0.7730 - 422ms/epoch - 12ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3472 - accuracy: 0.8467 - val_loss: 0.4459 - val_accuracy: 0.7801 - 413ms/epoch - 11ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3466 - accuracy: 0.8467 - val_loss: 0.4455 - val_accuracy: 0.7801 - 412ms/epoch - 11ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3460 - accuracy: 0.8467 - val_loss: 0.4458 - val_accuracy: 0.7801 - 425ms/epoch - 12ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3457 - accuracy: 0.8485 - val_loss: 0.4455 - val_accuracy: 0.7801 - 415ms/epoch - 12ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3454 - accuracy: 0.8485 - val_loss: 0.4453 - val_accuracy: 0.7801 - 438ms/epoch - 12ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3452 - accuracy: 0.8467 - val_loss: 0.4452 - val_accuracy: 0.7801 - 403ms/epoch - 11ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3449 - accuracy: 0.8503 - val_loss: 0.4450 - val_accuracy: 0.7801 - 413ms/epoch - 11ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3442 - accuracy: 0.8520 - val_loss: 0.4450 - val_accuracy: 0.7801 - 431ms/epoch - 12ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3442 - accuracy: 0.8485 - val_loss: 0.4453 - val_accuracy: 0.7801 - 417ms/epoch - 12ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3440 - accuracy: 0.8485 - val_loss: 0.4447 - val_accuracy: 0.7801 - 415ms/epoch - 12ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3439 - accuracy: 0.8467 - val_loss: 0.4453 - val_accuracy: 0.7801 - 428ms/epoch - 12ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3434 - accuracy: 0.8503 - val_loss: 0.4450 - val_accuracy: 0.7801 - 456ms/epoch - 13ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3430 - accuracy: 0.8503 - val_loss: 0.4447 - val_accuracy: 0.7801 - 408ms/epoch - 11ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3428 - accuracy: 0.8503 - val_loss: 0.4451 - val_accuracy: 0.7801 - 422ms/epoch - 12ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3425 - accuracy: 0.8503 - val_loss: 0.4447 - val_accuracy: 0.7801 - 426ms/epoch - 12ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3423 - accuracy: 0.8467 - val_loss: 0.4455 - val_accuracy: 0.7801 - 418ms/epoch - 12ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3418 - accuracy: 0.8485 - val_loss: 0.4457 - val_accuracy: 0.7801 - 427ms/epoch - 12ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3418 - accuracy: 0.8467 - val_loss: 0.4466 - val_accuracy: 0.7730 - 420ms/epoch - 12ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3414 - accuracy: 0.8467 - val_loss: 0.4466 - val_accuracy: 0.7730 - 419ms/epoch - 12ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3412 - accuracy: 0.8467 - val_loss: 0.4462 - val_accuracy: 0.7801 - 422ms/epoch - 12ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3406 - accuracy: 0.8467 - val_loss: 0.4445 - val_accuracy: 0.7801 - 427ms/epoch - 12ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3403 - accuracy: 0.8503 - val_loss: 0.4451 - val_accuracy: 0.7801 - 436ms/epoch - 12ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3402 - accuracy: 0.8503 - val_loss: 0.4458 - val_accuracy: 0.7730 - 421ms/epoch - 12ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 0.7221 - accuracy: 0.5686 - val_loss: 0.7594 - val_accuracy: 0.5248 - 1s/epoch - 40ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.6834 - accuracy: 0.6096 - val_loss: 0.7318 - val_accuracy: 0.5532 - 418ms/epoch - 12ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.6589 - accuracy: 0.6292 - val_loss: 0.7131 - val_accuracy: 0.5674 - 447ms/epoch - 12ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.6407 - accuracy: 0.6453 - val_loss: 0.6978 - val_accuracy: 0.5674 - 415ms/epoch - 12ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.6247 - accuracy: 0.6720 - val_loss: 0.6844 - val_accuracy: 0.6028 - 421ms/epoch - 12ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.6113 - accuracy: 0.6827 - val_loss: 0.6723 - val_accuracy: 0.6099 - 428ms/epoch - 12ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.5989 - accuracy: 0.6970 - val_loss: 0.6613 - val_accuracy: 0.6170 - 428ms/epoch - 12ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.5882 - accuracy: 0.6970 - val_loss: 0.6507 - val_accuracy: 0.6383 - 417ms/epoch - 12ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.5778 - accuracy: 0.7059 - val_loss: 0.6420 - val_accuracy: 0.6525 - 417ms/epoch - 12ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.5685 - accuracy: 0.7059 - val_loss: 0.6327 - val_accuracy: 0.6525 - 422ms/epoch - 12ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5595 - accuracy: 0.7255 - val_loss: 0.6247 - val_accuracy: 0.6667 - 443ms/epoch - 12ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5519 - accuracy: 0.7326 - val_loss: 0.6167 - val_accuracy: 0.6738 - 421ms/epoch - 12ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5441 - accuracy: 0.7469 - val_loss: 0.6091 - val_accuracy: 0.6738 - 424ms/epoch - 12ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5367 - accuracy: 0.7594 - val_loss: 0.6010 - val_accuracy: 0.6738 - 414ms/epoch - 11ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5299 - accuracy: 0.7647 - val_loss: 0.5947 - val_accuracy: 0.6879 - 431ms/epoch - 12ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.5238 - accuracy: 0.7718 - val_loss: 0.5889 - val_accuracy: 0.6809 - 426ms/epoch - 12ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.5180 - accuracy: 0.7736 - val_loss: 0.5827 - val_accuracy: 0.6738 - 425ms/epoch - 12ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.5123 - accuracy: 0.7807 - val_loss: 0.5772 - val_accuracy: 0.6738 - 401ms/epoch - 11ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.5075 - accuracy: 0.7790 - val_loss: 0.5720 - val_accuracy: 0.6809 - 413ms/epoch - 11ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.5027 - accuracy: 0.7772 - val_loss: 0.5679 - val_accuracy: 0.6950 - 425ms/epoch - 12ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.4986 - accuracy: 0.7825 - val_loss: 0.5632 - val_accuracy: 0.7021 - 432ms/epoch - 12ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4938 - accuracy: 0.7825 - val_loss: 0.5591 - val_accuracy: 0.7021 - 423ms/epoch - 12ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4896 - accuracy: 0.7861 - val_loss: 0.5549 - val_accuracy: 0.7021 - 413ms/epoch - 11ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4857 - accuracy: 0.7843 - val_loss: 0.5509 - val_accuracy: 0.7163 - 425ms/epoch - 12ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4819 - accuracy: 0.7932 - val_loss: 0.5471 - val_accuracy: 0.7163 - 432ms/epoch - 12ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4784 - accuracy: 0.7950 - val_loss: 0.5436 - val_accuracy: 0.7305 - 414ms/epoch - 12ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4753 - accuracy: 0.7968 - val_loss: 0.5405 - val_accuracy: 0.7305 - 424ms/epoch - 12ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4723 - accuracy: 0.7986 - val_loss: 0.5365 - val_accuracy: 0.7376 - 417ms/epoch - 12ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4695 - accuracy: 0.7986 - val_loss: 0.5335 - val_accuracy: 0.7518 - 423ms/epoch - 12ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4666 - accuracy: 0.8039 - val_loss: 0.5302 - val_accuracy: 0.7447 - 421ms/epoch - 12ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4639 - accuracy: 0.8021 - val_loss: 0.5276 - val_accuracy: 0.7447 - 418ms/epoch - 12ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4613 - accuracy: 0.8021 - val_loss: 0.5249 - val_accuracy: 0.7447 - 405ms/epoch - 11ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4589 - accuracy: 0.8039 - val_loss: 0.5229 - val_accuracy: 0.7518 - 411ms/epoch - 11ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4568 - accuracy: 0.8004 - val_loss: 0.5204 - val_accuracy: 0.7447 - 425ms/epoch - 12ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4545 - accuracy: 0.8004 - val_loss: 0.5180 - val_accuracy: 0.7518 - 404ms/epoch - 11ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4522 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7518 - 435ms/epoch - 12ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4504 - accuracy: 0.8004 - val_loss: 0.5139 - val_accuracy: 0.7447 - 436ms/epoch - 12ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4484 - accuracy: 0.7986 - val_loss: 0.5123 - val_accuracy: 0.7518 - 412ms/epoch - 11ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4459 - accuracy: 0.8039 - val_loss: 0.5091 - val_accuracy: 0.7447 - 405ms/epoch - 11ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4443 - accuracy: 0.8075 - val_loss: 0.5071 - val_accuracy: 0.7518 - 428ms/epoch - 12ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4423 - accuracy: 0.8093 - val_loss: 0.5057 - val_accuracy: 0.7518 - 426ms/epoch - 12ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4406 - accuracy: 0.8057 - val_loss: 0.5045 - val_accuracy: 0.7589 - 422ms/epoch - 12ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4393 - accuracy: 0.8093 - val_loss: 0.5029 - val_accuracy: 0.7518 - 421ms/epoch - 12ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4374 - accuracy: 0.8075 - val_loss: 0.5015 - val_accuracy: 0.7589 - 427ms/epoch - 12ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4360 - accuracy: 0.8093 - val_loss: 0.5002 - val_accuracy: 0.7518 - 423ms/epoch - 12ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4347 - accuracy: 0.8075 - val_loss: 0.4991 - val_accuracy: 0.7518 - 428ms/epoch - 12ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4333 - accuracy: 0.8075 - val_loss: 0.4979 - val_accuracy: 0.7589 - 429ms/epoch - 12ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4319 - accuracy: 0.8075 - val_loss: 0.4965 - val_accuracy: 0.7589 - 432ms/epoch - 12ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4306 - accuracy: 0.8039 - val_loss: 0.4949 - val_accuracy: 0.7589 - 447ms/epoch - 12ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4296 - accuracy: 0.8075 - val_loss: 0.4940 - val_accuracy: 0.7589 - 416ms/epoch - 12ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4284 - accuracy: 0.8093 - val_loss: 0.4928 - val_accuracy: 0.7589 - 447ms/epoch - 12ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4269 - accuracy: 0.8075 - val_loss: 0.4924 - val_accuracy: 0.7660 - 434ms/epoch - 12ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4262 - accuracy: 0.8093 - val_loss: 0.4918 - val_accuracy: 0.7660 - 439ms/epoch - 12ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4251 - accuracy: 0.8075 - val_loss: 0.4908 - val_accuracy: 0.7660 - 433ms/epoch - 12ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4239 - accuracy: 0.8146 - val_loss: 0.4891 - val_accuracy: 0.7730 - 435ms/epoch - 12ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4229 - accuracy: 0.8128 - val_loss: 0.4884 - val_accuracy: 0.7730 - 418ms/epoch - 12ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4219 - accuracy: 0.8146 - val_loss: 0.4880 - val_accuracy: 0.7660 - 431ms/epoch - 12ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4208 - accuracy: 0.8146 - val_loss: 0.4870 - val_accuracy: 0.7730 - 437ms/epoch - 12ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4206 - accuracy: 0.8128 - val_loss: 0.4863 - val_accuracy: 0.7660 - 421ms/epoch - 12ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4190 - accuracy: 0.8128 - val_loss: 0.4854 - val_accuracy: 0.7660 - 413ms/epoch - 11ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4182 - accuracy: 0.8128 - val_loss: 0.4845 - val_accuracy: 0.7660 - 436ms/epoch - 12ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4175 - accuracy: 0.8111 - val_loss: 0.4842 - val_accuracy: 0.7660 - 426ms/epoch - 12ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4167 - accuracy: 0.8146 - val_loss: 0.4834 - val_accuracy: 0.7660 - 423ms/epoch - 12ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4159 - accuracy: 0.8111 - val_loss: 0.4831 - val_accuracy: 0.7660 - 427ms/epoch - 12ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4153 - accuracy: 0.8128 - val_loss: 0.4825 - val_accuracy: 0.7660 - 408ms/epoch - 11ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4147 - accuracy: 0.8128 - val_loss: 0.4820 - val_accuracy: 0.7660 - 436ms/epoch - 12ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4140 - accuracy: 0.8111 - val_loss: 0.4814 - val_accuracy: 0.7660 - 428ms/epoch - 12ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4131 - accuracy: 0.8111 - val_loss: 0.4807 - val_accuracy: 0.7660 - 421ms/epoch - 12ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4124 - accuracy: 0.8093 - val_loss: 0.4801 - val_accuracy: 0.7660 - 426ms/epoch - 12ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4118 - accuracy: 0.8111 - val_loss: 0.4797 - val_accuracy: 0.7660 - 415ms/epoch - 12ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4113 - accuracy: 0.8111 - val_loss: 0.4796 - val_accuracy: 0.7660 - 426ms/epoch - 12ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4109 - accuracy: 0.8111 - val_loss: 0.4792 - val_accuracy: 0.7660 - 433ms/epoch - 12ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4104 - accuracy: 0.8164 - val_loss: 0.4785 - val_accuracy: 0.7730 - 412ms/epoch - 11ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4095 - accuracy: 0.8146 - val_loss: 0.4784 - val_accuracy: 0.7660 - 421ms/epoch - 12ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4088 - accuracy: 0.8182 - val_loss: 0.4772 - val_accuracy: 0.7730 - 417ms/epoch - 12ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4086 - accuracy: 0.8200 - val_loss: 0.4772 - val_accuracy: 0.7730 - 426ms/epoch - 12ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4078 - accuracy: 0.8217 - val_loss: 0.4768 - val_accuracy: 0.7730 - 414ms/epoch - 12ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4073 - accuracy: 0.8200 - val_loss: 0.4766 - val_accuracy: 0.7660 - 432ms/epoch - 12ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4069 - accuracy: 0.8200 - val_loss: 0.4762 - val_accuracy: 0.7660 - 434ms/epoch - 12ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4063 - accuracy: 0.8200 - val_loss: 0.4757 - val_accuracy: 0.7730 - 418ms/epoch - 12ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4063 - accuracy: 0.8253 - val_loss: 0.4751 - val_accuracy: 0.7730 - 411ms/epoch - 11ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4054 - accuracy: 0.8235 - val_loss: 0.4750 - val_accuracy: 0.7801 - 415ms/epoch - 12ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4048 - accuracy: 0.8217 - val_loss: 0.4748 - val_accuracy: 0.7801 - 441ms/epoch - 12ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4047 - accuracy: 0.8217 - val_loss: 0.4752 - val_accuracy: 0.7801 - 423ms/epoch - 12ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4039 - accuracy: 0.8217 - val_loss: 0.4750 - val_accuracy: 0.7801 - 441ms/epoch - 12ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4037 - accuracy: 0.8253 - val_loss: 0.4750 - val_accuracy: 0.7801 - 412ms/epoch - 11ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4033 - accuracy: 0.8253 - val_loss: 0.4747 - val_accuracy: 0.7801 - 414ms/epoch - 11ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4028 - accuracy: 0.8271 - val_loss: 0.4743 - val_accuracy: 0.7801 - 423ms/epoch - 12ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4024 - accuracy: 0.8253 - val_loss: 0.4741 - val_accuracy: 0.7872 - 435ms/epoch - 12ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4020 - accuracy: 0.8253 - val_loss: 0.4745 - val_accuracy: 0.7730 - 423ms/epoch - 12ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4018 - accuracy: 0.8235 - val_loss: 0.4747 - val_accuracy: 0.7730 - 432ms/epoch - 12ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4014 - accuracy: 0.8235 - val_loss: 0.4743 - val_accuracy: 0.7730 - 426ms/epoch - 12ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4009 - accuracy: 0.8217 - val_loss: 0.4738 - val_accuracy: 0.7730 - 425ms/epoch - 12ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.4009 - accuracy: 0.8307 - val_loss: 0.4739 - val_accuracy: 0.7730 - 416ms/epoch - 12ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4006 - accuracy: 0.8289 - val_loss: 0.4740 - val_accuracy: 0.7660 - 412ms/epoch - 11ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.4001 - accuracy: 0.8235 - val_loss: 0.4741 - val_accuracy: 0.7730 - 409ms/epoch - 11ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4001 - accuracy: 0.8324 - val_loss: 0.4737 - val_accuracy: 0.7730 - 427ms/epoch - 12ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.3997 - accuracy: 0.8360 - val_loss: 0.4734 - val_accuracy: 0.7730 - 430ms/epoch - 12ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.3993 - accuracy: 0.8342 - val_loss: 0.4736 - val_accuracy: 0.7730 - 403ms/epoch - 11ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.3991 - accuracy: 0.8289 - val_loss: 0.4741 - val_accuracy: 0.7730 - 426ms/epoch - 12ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.3986 - accuracy: 0.8307 - val_loss: 0.4743 - val_accuracy: 0.7730 - 439ms/epoch - 12ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.3984 - accuracy: 0.8289 - val_loss: 0.4738 - val_accuracy: 0.7730 - 450ms/epoch - 13ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.3982 - accuracy: 0.8324 - val_loss: 0.4738 - val_accuracy: 0.7730 - 431ms/epoch - 12ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.3977 - accuracy: 0.8324 - val_loss: 0.4738 - val_accuracy: 0.7730 - 404ms/epoch - 11ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8342 - val_loss: 0.4738 - val_accuracy: 0.7660 - 470ms/epoch - 13ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3973 - accuracy: 0.8342 - val_loss: 0.4742 - val_accuracy: 0.7589 - 448ms/epoch - 12ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3969 - accuracy: 0.8324 - val_loss: 0.4742 - val_accuracy: 0.7589 - 412ms/epoch - 11ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3967 - accuracy: 0.8342 - val_loss: 0.4739 - val_accuracy: 0.7589 - 412ms/epoch - 11ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8360 - val_loss: 0.4741 - val_accuracy: 0.7518 - 424ms/epoch - 12ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3965 - accuracy: 0.8342 - val_loss: 0.4742 - val_accuracy: 0.7518 - 424ms/epoch - 12ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3959 - accuracy: 0.8378 - val_loss: 0.4739 - val_accuracy: 0.7589 - 427ms/epoch - 12ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8360 - val_loss: 0.4737 - val_accuracy: 0.7660 - 428ms/epoch - 12ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3957 - accuracy: 0.8378 - val_loss: 0.4742 - val_accuracy: 0.7589 - 426ms/epoch - 12ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8378 - val_loss: 0.4739 - val_accuracy: 0.7589 - 436ms/epoch - 12ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3951 - accuracy: 0.8360 - val_loss: 0.4742 - val_accuracy: 0.7589 - 425ms/epoch - 12ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3953 - accuracy: 0.8378 - val_loss: 0.4743 - val_accuracy: 0.7589 - 405ms/epoch - 11ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8378 - val_loss: 0.4742 - val_accuracy: 0.7589 - 409ms/epoch - 11ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3947 - accuracy: 0.8378 - val_loss: 0.4747 - val_accuracy: 0.7589 - 430ms/epoch - 12ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3943 - accuracy: 0.8378 - val_loss: 0.4741 - val_accuracy: 0.7589 - 435ms/epoch - 12ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3943 - accuracy: 0.8396 - val_loss: 0.4738 - val_accuracy: 0.7589 - 435ms/epoch - 12ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3941 - accuracy: 0.8378 - val_loss: 0.4736 - val_accuracy: 0.7589 - 443ms/epoch - 12ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3939 - accuracy: 0.8378 - val_loss: 0.4738 - val_accuracy: 0.7589 - 410ms/epoch - 11ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3937 - accuracy: 0.8396 - val_loss: 0.4752 - val_accuracy: 0.7589 - 432ms/epoch - 12ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 0s - loss: 0.3936 - accuracy: 0.8396 - val_loss: 0.4751 - val_accuracy: 0.7589 - 430ms/epoch - 12ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3932 - accuracy: 0.8414 - val_loss: 0.4754 - val_accuracy: 0.7589 - 429ms/epoch - 12ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3934 - accuracy: 0.8378 - val_loss: 0.4750 - val_accuracy: 0.7518 - 418ms/epoch - 12ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3929 - accuracy: 0.8378 - val_loss: 0.4751 - val_accuracy: 0.7589 - 437ms/epoch - 12ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 1s - loss: 0.3926 - accuracy: 0.8396 - val_loss: 0.4755 - val_accuracy: 0.7801 - 512ms/epoch - 14ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3926 - accuracy: 0.8378 - val_loss: 0.4750 - val_accuracy: 0.7589 - 459ms/epoch - 13ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3925 - accuracy: 0.8396 - val_loss: 0.4755 - val_accuracy: 0.7589 - 460ms/epoch - 13ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3923 - accuracy: 0.8396 - val_loss: 0.4753 - val_accuracy: 0.7589 - 445ms/epoch - 12ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3921 - accuracy: 0.8396 - val_loss: 0.4757 - val_accuracy: 0.7589 - 428ms/epoch - 12ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3921 - accuracy: 0.8396 - val_loss: 0.4762 - val_accuracy: 0.7660 - 419ms/epoch - 12ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3925 - accuracy: 0.8342 - val_loss: 0.4778 - val_accuracy: 0.7730 - 438ms/epoch - 12ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3919 - accuracy: 0.8378 - val_loss: 0.4769 - val_accuracy: 0.7730 - 436ms/epoch - 12ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3916 - accuracy: 0.8378 - val_loss: 0.4769 - val_accuracy: 0.7801 - 431ms/epoch - 12ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3915 - accuracy: 0.8360 - val_loss: 0.4770 - val_accuracy: 0.7730 - 429ms/epoch - 12ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3913 - accuracy: 0.8378 - val_loss: 0.4764 - val_accuracy: 0.7660 - 428ms/epoch - 12ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3910 - accuracy: 0.8378 - val_loss: 0.4766 - val_accuracy: 0.7589 - 436ms/epoch - 12ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3910 - accuracy: 0.8414 - val_loss: 0.4762 - val_accuracy: 0.7589 - 430ms/epoch - 12ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3908 - accuracy: 0.8414 - val_loss: 0.4761 - val_accuracy: 0.7589 - 419ms/epoch - 12ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3907 - accuracy: 0.8414 - val_loss: 0.4763 - val_accuracy: 0.7589 - 411ms/epoch - 11ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3903 - accuracy: 0.8396 - val_loss: 0.4768 - val_accuracy: 0.7660 - 441ms/epoch - 12ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3903 - accuracy: 0.8414 - val_loss: 0.4769 - val_accuracy: 0.7660 - 464ms/epoch - 13ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3902 - accuracy: 0.8414 - val_loss: 0.4768 - val_accuracy: 0.7660 - 437ms/epoch - 12ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3904 - accuracy: 0.8414 - val_loss: 0.4769 - val_accuracy: 0.7589 - 426ms/epoch - 12ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3901 - accuracy: 0.8414 - val_loss: 0.4771 - val_accuracy: 0.7660 - 452ms/epoch - 13ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3899 - accuracy: 0.8414 - val_loss: 0.4768 - val_accuracy: 0.7660 - 411ms/epoch - 11ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8414 - val_loss: 0.4769 - val_accuracy: 0.7660 - 438ms/epoch - 12ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8378 - val_loss: 0.4775 - val_accuracy: 0.7660 - 454ms/epoch - 13ms/step\n",
      "Epoch 1/150\n",
      "36/36 - 1s - loss: 0.6689 - accuracy: 0.5989 - val_loss: 0.7354 - val_accuracy: 0.5461 - 1s/epoch - 37ms/step\n",
      "Epoch 2/150\n",
      "36/36 - 0s - loss: 0.6415 - accuracy: 0.6168 - val_loss: 0.7155 - val_accuracy: 0.5887 - 450ms/epoch - 13ms/step\n",
      "Epoch 3/150\n",
      "36/36 - 0s - loss: 0.6218 - accuracy: 0.6399 - val_loss: 0.6989 - val_accuracy: 0.6028 - 435ms/epoch - 12ms/step\n",
      "Epoch 4/150\n",
      "36/36 - 0s - loss: 0.6050 - accuracy: 0.6595 - val_loss: 0.6846 - val_accuracy: 0.6241 - 458ms/epoch - 13ms/step\n",
      "Epoch 5/150\n",
      "36/36 - 0s - loss: 0.5902 - accuracy: 0.6809 - val_loss: 0.6720 - val_accuracy: 0.6170 - 444ms/epoch - 12ms/step\n",
      "Epoch 6/150\n",
      "36/36 - 0s - loss: 0.5784 - accuracy: 0.6916 - val_loss: 0.6606 - val_accuracy: 0.6028 - 420ms/epoch - 12ms/step\n",
      "Epoch 7/150\n",
      "36/36 - 0s - loss: 0.5670 - accuracy: 0.6988 - val_loss: 0.6523 - val_accuracy: 0.6099 - 445ms/epoch - 12ms/step\n",
      "Epoch 8/150\n",
      "36/36 - 0s - loss: 0.5569 - accuracy: 0.7184 - val_loss: 0.6432 - val_accuracy: 0.6241 - 418ms/epoch - 12ms/step\n",
      "Epoch 9/150\n",
      "36/36 - 0s - loss: 0.5476 - accuracy: 0.7344 - val_loss: 0.6350 - val_accuracy: 0.6383 - 416ms/epoch - 12ms/step\n",
      "Epoch 10/150\n",
      "36/36 - 0s - loss: 0.5388 - accuracy: 0.7415 - val_loss: 0.6278 - val_accuracy: 0.6454 - 416ms/epoch - 12ms/step\n",
      "Epoch 11/150\n",
      "36/36 - 0s - loss: 0.5314 - accuracy: 0.7487 - val_loss: 0.6208 - val_accuracy: 0.6525 - 441ms/epoch - 12ms/step\n",
      "Epoch 12/150\n",
      "36/36 - 0s - loss: 0.5243 - accuracy: 0.7558 - val_loss: 0.6137 - val_accuracy: 0.6525 - 422ms/epoch - 12ms/step\n",
      "Epoch 13/150\n",
      "36/36 - 0s - loss: 0.5172 - accuracy: 0.7754 - val_loss: 0.6072 - val_accuracy: 0.6667 - 422ms/epoch - 12ms/step\n",
      "Epoch 14/150\n",
      "36/36 - 0s - loss: 0.5109 - accuracy: 0.7772 - val_loss: 0.6004 - val_accuracy: 0.6809 - 418ms/epoch - 12ms/step\n",
      "Epoch 15/150\n",
      "36/36 - 0s - loss: 0.5058 - accuracy: 0.7790 - val_loss: 0.5961 - val_accuracy: 0.6879 - 434ms/epoch - 12ms/step\n",
      "Epoch 16/150\n",
      "36/36 - 0s - loss: 0.5009 - accuracy: 0.7861 - val_loss: 0.5914 - val_accuracy: 0.7021 - 430ms/epoch - 12ms/step\n",
      "Epoch 17/150\n",
      "36/36 - 0s - loss: 0.4967 - accuracy: 0.7861 - val_loss: 0.5870 - val_accuracy: 0.6950 - 418ms/epoch - 12ms/step\n",
      "Epoch 18/150\n",
      "36/36 - 0s - loss: 0.4922 - accuracy: 0.7861 - val_loss: 0.5821 - val_accuracy: 0.6950 - 420ms/epoch - 12ms/step\n",
      "Epoch 19/150\n",
      "36/36 - 0s - loss: 0.4881 - accuracy: 0.7932 - val_loss: 0.5787 - val_accuracy: 0.6950 - 433ms/epoch - 12ms/step\n",
      "Epoch 20/150\n",
      "36/36 - 0s - loss: 0.4839 - accuracy: 0.7932 - val_loss: 0.5745 - val_accuracy: 0.7021 - 431ms/epoch - 12ms/step\n",
      "Epoch 21/150\n",
      "36/36 - 0s - loss: 0.4806 - accuracy: 0.7986 - val_loss: 0.5710 - val_accuracy: 0.7021 - 418ms/epoch - 12ms/step\n",
      "Epoch 22/150\n",
      "36/36 - 0s - loss: 0.4771 - accuracy: 0.7950 - val_loss: 0.5677 - val_accuracy: 0.7021 - 403ms/epoch - 11ms/step\n",
      "Epoch 23/150\n",
      "36/36 - 0s - loss: 0.4739 - accuracy: 0.8021 - val_loss: 0.5646 - val_accuracy: 0.7021 - 411ms/epoch - 11ms/step\n",
      "Epoch 24/150\n",
      "36/36 - 0s - loss: 0.4713 - accuracy: 0.8004 - val_loss: 0.5618 - val_accuracy: 0.7163 - 444ms/epoch - 12ms/step\n",
      "Epoch 25/150\n",
      "36/36 - 0s - loss: 0.4686 - accuracy: 0.8039 - val_loss: 0.5602 - val_accuracy: 0.7092 - 436ms/epoch - 12ms/step\n",
      "Epoch 26/150\n",
      "36/36 - 0s - loss: 0.4661 - accuracy: 0.8075 - val_loss: 0.5580 - val_accuracy: 0.7092 - 426ms/epoch - 12ms/step\n",
      "Epoch 27/150\n",
      "36/36 - 0s - loss: 0.4637 - accuracy: 0.8039 - val_loss: 0.5558 - val_accuracy: 0.7092 - 421ms/epoch - 12ms/step\n",
      "Epoch 28/150\n",
      "36/36 - 0s - loss: 0.4614 - accuracy: 0.8057 - val_loss: 0.5525 - val_accuracy: 0.7163 - 425ms/epoch - 12ms/step\n",
      "Epoch 29/150\n",
      "36/36 - 0s - loss: 0.4590 - accuracy: 0.8057 - val_loss: 0.5500 - val_accuracy: 0.7163 - 435ms/epoch - 12ms/step\n",
      "Epoch 30/150\n",
      "36/36 - 0s - loss: 0.4571 - accuracy: 0.8146 - val_loss: 0.5480 - val_accuracy: 0.7163 - 427ms/epoch - 12ms/step\n",
      "Epoch 31/150\n",
      "36/36 - 0s - loss: 0.4545 - accuracy: 0.8146 - val_loss: 0.5453 - val_accuracy: 0.7163 - 432ms/epoch - 12ms/step\n",
      "Epoch 32/150\n",
      "36/36 - 0s - loss: 0.4524 - accuracy: 0.8146 - val_loss: 0.5435 - val_accuracy: 0.7163 - 438ms/epoch - 12ms/step\n",
      "Epoch 33/150\n",
      "36/36 - 0s - loss: 0.4507 - accuracy: 0.8128 - val_loss: 0.5414 - val_accuracy: 0.7163 - 441ms/epoch - 12ms/step\n",
      "Epoch 34/150\n",
      "36/36 - 0s - loss: 0.4485 - accuracy: 0.8146 - val_loss: 0.5390 - val_accuracy: 0.7234 - 425ms/epoch - 12ms/step\n",
      "Epoch 35/150\n",
      "36/36 - 0s - loss: 0.4468 - accuracy: 0.8146 - val_loss: 0.5369 - val_accuracy: 0.7305 - 419ms/epoch - 12ms/step\n",
      "Epoch 36/150\n",
      "36/36 - 0s - loss: 0.4454 - accuracy: 0.8146 - val_loss: 0.5348 - val_accuracy: 0.7305 - 420ms/epoch - 12ms/step\n",
      "Epoch 37/150\n",
      "36/36 - 0s - loss: 0.4438 - accuracy: 0.8146 - val_loss: 0.5329 - val_accuracy: 0.7305 - 416ms/epoch - 12ms/step\n",
      "Epoch 38/150\n",
      "36/36 - 0s - loss: 0.4420 - accuracy: 0.8128 - val_loss: 0.5312 - val_accuracy: 0.7234 - 433ms/epoch - 12ms/step\n",
      "Epoch 39/150\n",
      "36/36 - 0s - loss: 0.4406 - accuracy: 0.8128 - val_loss: 0.5295 - val_accuracy: 0.7305 - 437ms/epoch - 12ms/step\n",
      "Epoch 40/150\n",
      "36/36 - 0s - loss: 0.4392 - accuracy: 0.8128 - val_loss: 0.5278 - val_accuracy: 0.7305 - 420ms/epoch - 12ms/step\n",
      "Epoch 41/150\n",
      "36/36 - 0s - loss: 0.4378 - accuracy: 0.8093 - val_loss: 0.5261 - val_accuracy: 0.7305 - 409ms/epoch - 11ms/step\n",
      "Epoch 42/150\n",
      "36/36 - 0s - loss: 0.4365 - accuracy: 0.8111 - val_loss: 0.5246 - val_accuracy: 0.7305 - 439ms/epoch - 12ms/step\n",
      "Epoch 43/150\n",
      "36/36 - 0s - loss: 0.4350 - accuracy: 0.8182 - val_loss: 0.5232 - val_accuracy: 0.7305 - 420ms/epoch - 12ms/step\n",
      "Epoch 44/150\n",
      "36/36 - 0s - loss: 0.4338 - accuracy: 0.8128 - val_loss: 0.5216 - val_accuracy: 0.7376 - 427ms/epoch - 12ms/step\n",
      "Epoch 45/150\n",
      "36/36 - 0s - loss: 0.4326 - accuracy: 0.8146 - val_loss: 0.5205 - val_accuracy: 0.7376 - 414ms/epoch - 11ms/step\n",
      "Epoch 46/150\n",
      "36/36 - 0s - loss: 0.4314 - accuracy: 0.8128 - val_loss: 0.5195 - val_accuracy: 0.7305 - 428ms/epoch - 12ms/step\n",
      "Epoch 47/150\n",
      "36/36 - 0s - loss: 0.4306 - accuracy: 0.8164 - val_loss: 0.5183 - val_accuracy: 0.7305 - 430ms/epoch - 12ms/step\n",
      "Epoch 48/150\n",
      "36/36 - 0s - loss: 0.4293 - accuracy: 0.8146 - val_loss: 0.5170 - val_accuracy: 0.7305 - 430ms/epoch - 12ms/step\n",
      "Epoch 49/150\n",
      "36/36 - 0s - loss: 0.4282 - accuracy: 0.8128 - val_loss: 0.5159 - val_accuracy: 0.7305 - 424ms/epoch - 12ms/step\n",
      "Epoch 50/150\n",
      "36/36 - 0s - loss: 0.4274 - accuracy: 0.8182 - val_loss: 0.5147 - val_accuracy: 0.7305 - 437ms/epoch - 12ms/step\n",
      "Epoch 51/150\n",
      "36/36 - 0s - loss: 0.4263 - accuracy: 0.8146 - val_loss: 0.5139 - val_accuracy: 0.7305 - 413ms/epoch - 11ms/step\n",
      "Epoch 52/150\n",
      "36/36 - 0s - loss: 0.4252 - accuracy: 0.8182 - val_loss: 0.5130 - val_accuracy: 0.7305 - 425ms/epoch - 12ms/step\n",
      "Epoch 53/150\n",
      "36/36 - 0s - loss: 0.4242 - accuracy: 0.8146 - val_loss: 0.5119 - val_accuracy: 0.7305 - 433ms/epoch - 12ms/step\n",
      "Epoch 54/150\n",
      "36/36 - 0s - loss: 0.4232 - accuracy: 0.8146 - val_loss: 0.5107 - val_accuracy: 0.7305 - 417ms/epoch - 12ms/step\n",
      "Epoch 55/150\n",
      "36/36 - 0s - loss: 0.4223 - accuracy: 0.8164 - val_loss: 0.5098 - val_accuracy: 0.7234 - 428ms/epoch - 12ms/step\n",
      "Epoch 56/150\n",
      "36/36 - 0s - loss: 0.4217 - accuracy: 0.8182 - val_loss: 0.5089 - val_accuracy: 0.7234 - 408ms/epoch - 11ms/step\n",
      "Epoch 57/150\n",
      "36/36 - 0s - loss: 0.4206 - accuracy: 0.8164 - val_loss: 0.5087 - val_accuracy: 0.7305 - 439ms/epoch - 12ms/step\n",
      "Epoch 58/150\n",
      "36/36 - 0s - loss: 0.4199 - accuracy: 0.8164 - val_loss: 0.5080 - val_accuracy: 0.7234 - 427ms/epoch - 12ms/step\n",
      "Epoch 59/150\n",
      "36/36 - 0s - loss: 0.4193 - accuracy: 0.8200 - val_loss: 0.5069 - val_accuracy: 0.7163 - 433ms/epoch - 12ms/step\n",
      "Epoch 60/150\n",
      "36/36 - 0s - loss: 0.4183 - accuracy: 0.8164 - val_loss: 0.5059 - val_accuracy: 0.7163 - 437ms/epoch - 12ms/step\n",
      "Epoch 61/150\n",
      "36/36 - 0s - loss: 0.4178 - accuracy: 0.8182 - val_loss: 0.5052 - val_accuracy: 0.7163 - 453ms/epoch - 13ms/step\n",
      "Epoch 62/150\n",
      "36/36 - 0s - loss: 0.4168 - accuracy: 0.8182 - val_loss: 0.5044 - val_accuracy: 0.7163 - 398ms/epoch - 11ms/step\n",
      "Epoch 63/150\n",
      "36/36 - 0s - loss: 0.4161 - accuracy: 0.8182 - val_loss: 0.5035 - val_accuracy: 0.7163 - 426ms/epoch - 12ms/step\n",
      "Epoch 64/150\n",
      "36/36 - 0s - loss: 0.4155 - accuracy: 0.8128 - val_loss: 0.5017 - val_accuracy: 0.7163 - 429ms/epoch - 12ms/step\n",
      "Epoch 65/150\n",
      "36/36 - 0s - loss: 0.4151 - accuracy: 0.8093 - val_loss: 0.5009 - val_accuracy: 0.7163 - 428ms/epoch - 12ms/step\n",
      "Epoch 66/150\n",
      "36/36 - 0s - loss: 0.4141 - accuracy: 0.8128 - val_loss: 0.4999 - val_accuracy: 0.7163 - 427ms/epoch - 12ms/step\n",
      "Epoch 67/150\n",
      "36/36 - 0s - loss: 0.4134 - accuracy: 0.8164 - val_loss: 0.4995 - val_accuracy: 0.7234 - 418ms/epoch - 12ms/step\n",
      "Epoch 68/150\n",
      "36/36 - 0s - loss: 0.4129 - accuracy: 0.8111 - val_loss: 0.4986 - val_accuracy: 0.7234 - 434ms/epoch - 12ms/step\n",
      "Epoch 69/150\n",
      "36/36 - 0s - loss: 0.4127 - accuracy: 0.8146 - val_loss: 0.4987 - val_accuracy: 0.7234 - 439ms/epoch - 12ms/step\n",
      "Epoch 70/150\n",
      "36/36 - 0s - loss: 0.4119 - accuracy: 0.8128 - val_loss: 0.4978 - val_accuracy: 0.7163 - 440ms/epoch - 12ms/step\n",
      "Epoch 71/150\n",
      "36/36 - 0s - loss: 0.4116 - accuracy: 0.8164 - val_loss: 0.4969 - val_accuracy: 0.7163 - 428ms/epoch - 12ms/step\n",
      "Epoch 72/150\n",
      "36/36 - 0s - loss: 0.4108 - accuracy: 0.8164 - val_loss: 0.4964 - val_accuracy: 0.7234 - 438ms/epoch - 12ms/step\n",
      "Epoch 73/150\n",
      "36/36 - 0s - loss: 0.4105 - accuracy: 0.8217 - val_loss: 0.4964 - val_accuracy: 0.7234 - 445ms/epoch - 12ms/step\n",
      "Epoch 74/150\n",
      "36/36 - 0s - loss: 0.4102 - accuracy: 0.8235 - val_loss: 0.4959 - val_accuracy: 0.7234 - 443ms/epoch - 12ms/step\n",
      "Epoch 75/150\n",
      "36/36 - 0s - loss: 0.4096 - accuracy: 0.8182 - val_loss: 0.4957 - val_accuracy: 0.7234 - 412ms/epoch - 11ms/step\n",
      "Epoch 76/150\n",
      "36/36 - 0s - loss: 0.4090 - accuracy: 0.8182 - val_loss: 0.4948 - val_accuracy: 0.7234 - 425ms/epoch - 12ms/step\n",
      "Epoch 77/150\n",
      "36/36 - 0s - loss: 0.4088 - accuracy: 0.8217 - val_loss: 0.4943 - val_accuracy: 0.7234 - 431ms/epoch - 12ms/step\n",
      "Epoch 78/150\n",
      "36/36 - 0s - loss: 0.4090 - accuracy: 0.8146 - val_loss: 0.4941 - val_accuracy: 0.7305 - 406ms/epoch - 11ms/step\n",
      "Epoch 79/150\n",
      "36/36 - 0s - loss: 0.4081 - accuracy: 0.8217 - val_loss: 0.4928 - val_accuracy: 0.7234 - 433ms/epoch - 12ms/step\n",
      "Epoch 80/150\n",
      "36/36 - 0s - loss: 0.4072 - accuracy: 0.8235 - val_loss: 0.4924 - val_accuracy: 0.7234 - 429ms/epoch - 12ms/step\n",
      "Epoch 81/150\n",
      "36/36 - 0s - loss: 0.4068 - accuracy: 0.8217 - val_loss: 0.4919 - val_accuracy: 0.7305 - 439ms/epoch - 12ms/step\n",
      "Epoch 82/150\n",
      "36/36 - 0s - loss: 0.4066 - accuracy: 0.8217 - val_loss: 0.4917 - val_accuracy: 0.7305 - 423ms/epoch - 12ms/step\n",
      "Epoch 83/150\n",
      "36/36 - 0s - loss: 0.4062 - accuracy: 0.8253 - val_loss: 0.4914 - val_accuracy: 0.7305 - 435ms/epoch - 12ms/step\n",
      "Epoch 84/150\n",
      "36/36 - 0s - loss: 0.4063 - accuracy: 0.8200 - val_loss: 0.4906 - val_accuracy: 0.7234 - 453ms/epoch - 13ms/step\n",
      "Epoch 85/150\n",
      "36/36 - 0s - loss: 0.4056 - accuracy: 0.8217 - val_loss: 0.4903 - val_accuracy: 0.7305 - 458ms/epoch - 13ms/step\n",
      "Epoch 86/150\n",
      "36/36 - 0s - loss: 0.4051 - accuracy: 0.8217 - val_loss: 0.4899 - val_accuracy: 0.7305 - 427ms/epoch - 12ms/step\n",
      "Epoch 87/150\n",
      "36/36 - 0s - loss: 0.4047 - accuracy: 0.8217 - val_loss: 0.4893 - val_accuracy: 0.7305 - 420ms/epoch - 12ms/step\n",
      "Epoch 88/150\n",
      "36/36 - 0s - loss: 0.4045 - accuracy: 0.8217 - val_loss: 0.4888 - val_accuracy: 0.7376 - 427ms/epoch - 12ms/step\n",
      "Epoch 89/150\n",
      "36/36 - 0s - loss: 0.4041 - accuracy: 0.8217 - val_loss: 0.4882 - val_accuracy: 0.7376 - 418ms/epoch - 12ms/step\n",
      "Epoch 90/150\n",
      "36/36 - 0s - loss: 0.4037 - accuracy: 0.8217 - val_loss: 0.4882 - val_accuracy: 0.7376 - 426ms/epoch - 12ms/step\n",
      "Epoch 91/150\n",
      "36/36 - 0s - loss: 0.4035 - accuracy: 0.8200 - val_loss: 0.4883 - val_accuracy: 0.7376 - 434ms/epoch - 12ms/step\n",
      "Epoch 92/150\n",
      "36/36 - 0s - loss: 0.4030 - accuracy: 0.8217 - val_loss: 0.4877 - val_accuracy: 0.7376 - 461ms/epoch - 13ms/step\n",
      "Epoch 93/150\n",
      "36/36 - 0s - loss: 0.4028 - accuracy: 0.8217 - val_loss: 0.4877 - val_accuracy: 0.7447 - 439ms/epoch - 12ms/step\n",
      "Epoch 94/150\n",
      "36/36 - 0s - loss: 0.4028 - accuracy: 0.8235 - val_loss: 0.4876 - val_accuracy: 0.7447 - 423ms/epoch - 12ms/step\n",
      "Epoch 95/150\n",
      "36/36 - 0s - loss: 0.4022 - accuracy: 0.8235 - val_loss: 0.4873 - val_accuracy: 0.7447 - 416ms/epoch - 12ms/step\n",
      "Epoch 96/150\n",
      "36/36 - 0s - loss: 0.4023 - accuracy: 0.8235 - val_loss: 0.4869 - val_accuracy: 0.7447 - 419ms/epoch - 12ms/step\n",
      "Epoch 97/150\n",
      "36/36 - 0s - loss: 0.4023 - accuracy: 0.8217 - val_loss: 0.4859 - val_accuracy: 0.7447 - 419ms/epoch - 12ms/step\n",
      "Epoch 98/150\n",
      "36/36 - 0s - loss: 0.4016 - accuracy: 0.8217 - val_loss: 0.4859 - val_accuracy: 0.7447 - 406ms/epoch - 11ms/step\n",
      "Epoch 99/150\n",
      "36/36 - 0s - loss: 0.4011 - accuracy: 0.8200 - val_loss: 0.4859 - val_accuracy: 0.7447 - 421ms/epoch - 12ms/step\n",
      "Epoch 100/150\n",
      "36/36 - 0s - loss: 0.4010 - accuracy: 0.8200 - val_loss: 0.4855 - val_accuracy: 0.7447 - 421ms/epoch - 12ms/step\n",
      "Epoch 101/150\n",
      "36/36 - 0s - loss: 0.4009 - accuracy: 0.8182 - val_loss: 0.4853 - val_accuracy: 0.7447 - 425ms/epoch - 12ms/step\n",
      "Epoch 102/150\n",
      "36/36 - 0s - loss: 0.4005 - accuracy: 0.8200 - val_loss: 0.4854 - val_accuracy: 0.7447 - 413ms/epoch - 11ms/step\n",
      "Epoch 103/150\n",
      "36/36 - 0s - loss: 0.4002 - accuracy: 0.8217 - val_loss: 0.4852 - val_accuracy: 0.7518 - 418ms/epoch - 12ms/step\n",
      "Epoch 104/150\n",
      "36/36 - 0s - loss: 0.4001 - accuracy: 0.8235 - val_loss: 0.4851 - val_accuracy: 0.7518 - 407ms/epoch - 11ms/step\n",
      "Epoch 105/150\n",
      "36/36 - 0s - loss: 0.3997 - accuracy: 0.8235 - val_loss: 0.4852 - val_accuracy: 0.7447 - 410ms/epoch - 11ms/step\n",
      "Epoch 106/150\n",
      "36/36 - 0s - loss: 0.3999 - accuracy: 0.8217 - val_loss: 0.4857 - val_accuracy: 0.7447 - 423ms/epoch - 12ms/step\n",
      "Epoch 107/150\n",
      "36/36 - 0s - loss: 0.3994 - accuracy: 0.8235 - val_loss: 0.4852 - val_accuracy: 0.7447 - 438ms/epoch - 12ms/step\n",
      "Epoch 108/150\n",
      "36/36 - 0s - loss: 0.3992 - accuracy: 0.8253 - val_loss: 0.4853 - val_accuracy: 0.7447 - 427ms/epoch - 12ms/step\n",
      "Epoch 109/150\n",
      "36/36 - 0s - loss: 0.3990 - accuracy: 0.8200 - val_loss: 0.4847 - val_accuracy: 0.7518 - 432ms/epoch - 12ms/step\n",
      "Epoch 110/150\n",
      "36/36 - 0s - loss: 0.3988 - accuracy: 0.8200 - val_loss: 0.4844 - val_accuracy: 0.7518 - 430ms/epoch - 12ms/step\n",
      "Epoch 111/150\n",
      "36/36 - 0s - loss: 0.3987 - accuracy: 0.8235 - val_loss: 0.4846 - val_accuracy: 0.7447 - 408ms/epoch - 11ms/step\n",
      "Epoch 112/150\n",
      "36/36 - 0s - loss: 0.3988 - accuracy: 0.8253 - val_loss: 0.4843 - val_accuracy: 0.7447 - 428ms/epoch - 12ms/step\n",
      "Epoch 113/150\n",
      "36/36 - 0s - loss: 0.3985 - accuracy: 0.8235 - val_loss: 0.4841 - val_accuracy: 0.7518 - 422ms/epoch - 12ms/step\n",
      "Epoch 114/150\n",
      "36/36 - 0s - loss: 0.3981 - accuracy: 0.8217 - val_loss: 0.4837 - val_accuracy: 0.7518 - 431ms/epoch - 12ms/step\n",
      "Epoch 115/150\n",
      "36/36 - 0s - loss: 0.3979 - accuracy: 0.8253 - val_loss: 0.4835 - val_accuracy: 0.7447 - 442ms/epoch - 12ms/step\n",
      "Epoch 116/150\n",
      "36/36 - 0s - loss: 0.3978 - accuracy: 0.8217 - val_loss: 0.4828 - val_accuracy: 0.7447 - 415ms/epoch - 12ms/step\n",
      "Epoch 117/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8217 - val_loss: 0.4827 - val_accuracy: 0.7447 - 438ms/epoch - 12ms/step\n",
      "Epoch 118/150\n",
      "36/36 - 0s - loss: 0.3980 - accuracy: 0.8200 - val_loss: 0.4836 - val_accuracy: 0.7447 - 424ms/epoch - 12ms/step\n",
      "Epoch 119/150\n",
      "36/36 - 0s - loss: 0.3975 - accuracy: 0.8182 - val_loss: 0.4829 - val_accuracy: 0.7447 - 403ms/epoch - 11ms/step\n",
      "Epoch 120/150\n",
      "36/36 - 0s - loss: 0.3971 - accuracy: 0.8200 - val_loss: 0.4828 - val_accuracy: 0.7447 - 429ms/epoch - 12ms/step\n",
      "Epoch 121/150\n",
      "36/36 - 0s - loss: 0.3972 - accuracy: 0.8200 - val_loss: 0.4833 - val_accuracy: 0.7447 - 422ms/epoch - 12ms/step\n",
      "Epoch 122/150\n",
      "36/36 - 0s - loss: 0.3970 - accuracy: 0.8182 - val_loss: 0.4829 - val_accuracy: 0.7447 - 427ms/epoch - 12ms/step\n",
      "Epoch 123/150\n",
      "36/36 - 0s - loss: 0.3968 - accuracy: 0.8200 - val_loss: 0.4811 - val_accuracy: 0.7447 - 438ms/epoch - 12ms/step\n",
      "Epoch 124/150\n",
      "36/36 - 1s - loss: 0.3974 - accuracy: 0.8182 - val_loss: 0.4814 - val_accuracy: 0.7447 - 509ms/epoch - 14ms/step\n",
      "Epoch 125/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8164 - val_loss: 0.4812 - val_accuracy: 0.7447 - 426ms/epoch - 12ms/step\n",
      "Epoch 126/150\n",
      "36/36 - 0s - loss: 0.3968 - accuracy: 0.8200 - val_loss: 0.4811 - val_accuracy: 0.7447 - 433ms/epoch - 12ms/step\n",
      "Epoch 127/150\n",
      "36/36 - 0s - loss: 0.3964 - accuracy: 0.8164 - val_loss: 0.4810 - val_accuracy: 0.7447 - 419ms/epoch - 12ms/step\n",
      "Epoch 128/150\n",
      "36/36 - 0s - loss: 0.3962 - accuracy: 0.8164 - val_loss: 0.4810 - val_accuracy: 0.7447 - 420ms/epoch - 12ms/step\n",
      "Epoch 129/150\n",
      "36/36 - 0s - loss: 0.3959 - accuracy: 0.8200 - val_loss: 0.4810 - val_accuracy: 0.7447 - 425ms/epoch - 12ms/step\n",
      "Epoch 130/150\n",
      "36/36 - 0s - loss: 0.3958 - accuracy: 0.8164 - val_loss: 0.4810 - val_accuracy: 0.7447 - 413ms/epoch - 11ms/step\n",
      "Epoch 131/150\n",
      "36/36 - 0s - loss: 0.3957 - accuracy: 0.8164 - val_loss: 0.4812 - val_accuracy: 0.7447 - 419ms/epoch - 12ms/step\n",
      "Epoch 132/150\n",
      "36/36 - 0s - loss: 0.3954 - accuracy: 0.8164 - val_loss: 0.4812 - val_accuracy: 0.7447 - 426ms/epoch - 12ms/step\n",
      "Epoch 133/150\n",
      "36/36 - 0s - loss: 0.3955 - accuracy: 0.8164 - val_loss: 0.4811 - val_accuracy: 0.7376 - 424ms/epoch - 12ms/step\n",
      "Epoch 134/150\n",
      "36/36 - 0s - loss: 0.3953 - accuracy: 0.8164 - val_loss: 0.4810 - val_accuracy: 0.7447 - 421ms/epoch - 12ms/step\n",
      "Epoch 135/150\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8182 - val_loss: 0.4808 - val_accuracy: 0.7447 - 415ms/epoch - 12ms/step\n",
      "Epoch 136/150\n",
      "36/36 - 0s - loss: 0.3951 - accuracy: 0.8164 - val_loss: 0.4807 - val_accuracy: 0.7376 - 423ms/epoch - 12ms/step\n",
      "Epoch 137/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8164 - val_loss: 0.4809 - val_accuracy: 0.7376 - 401ms/epoch - 11ms/step\n",
      "Epoch 138/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8164 - val_loss: 0.4809 - val_accuracy: 0.7376 - 463ms/epoch - 13ms/step\n",
      "Epoch 139/150\n",
      "36/36 - 0s - loss: 0.3944 - accuracy: 0.8182 - val_loss: 0.4817 - val_accuracy: 0.7447 - 467ms/epoch - 13ms/step\n",
      "Epoch 140/150\n",
      "36/36 - 0s - loss: 0.3947 - accuracy: 0.8217 - val_loss: 0.4813 - val_accuracy: 0.7447 - 435ms/epoch - 12ms/step\n",
      "Epoch 141/150\n",
      "36/36 - 0s - loss: 0.3948 - accuracy: 0.8217 - val_loss: 0.4816 - val_accuracy: 0.7447 - 430ms/epoch - 12ms/step\n",
      "Epoch 142/150\n",
      "36/36 - 0s - loss: 0.3945 - accuracy: 0.8235 - val_loss: 0.4815 - val_accuracy: 0.7447 - 434ms/epoch - 12ms/step\n",
      "Epoch 143/150\n",
      "36/36 - 0s - loss: 0.3946 - accuracy: 0.8200 - val_loss: 0.4816 - val_accuracy: 0.7305 - 432ms/epoch - 12ms/step\n",
      "Epoch 144/150\n",
      "36/36 - 0s - loss: 0.3941 - accuracy: 0.8217 - val_loss: 0.4808 - val_accuracy: 0.7305 - 409ms/epoch - 11ms/step\n",
      "Epoch 145/150\n",
      "36/36 - 0s - loss: 0.3940 - accuracy: 0.8217 - val_loss: 0.4810 - val_accuracy: 0.7305 - 428ms/epoch - 12ms/step\n",
      "Epoch 146/150\n",
      "36/36 - 0s - loss: 0.3938 - accuracy: 0.8217 - val_loss: 0.4809 - val_accuracy: 0.7305 - 412ms/epoch - 11ms/step\n",
      "Epoch 147/150\n",
      "36/36 - 0s - loss: 0.3940 - accuracy: 0.8235 - val_loss: 0.4807 - val_accuracy: 0.7376 - 420ms/epoch - 12ms/step\n",
      "Epoch 148/150\n",
      "36/36 - 0s - loss: 0.3936 - accuracy: 0.8217 - val_loss: 0.4807 - val_accuracy: 0.7305 - 421ms/epoch - 12ms/step\n",
      "Epoch 149/150\n",
      "36/36 - 0s - loss: 0.3934 - accuracy: 0.8200 - val_loss: 0.4808 - val_accuracy: 0.7305 - 417ms/epoch - 12ms/step\n",
      "Epoch 150/150\n",
      "36/36 - 0s - loss: 0.3936 - accuracy: 0.8200 - val_loss: 0.4804 - val_accuracy: 0.7305 - 420ms/epoch - 12ms/step\n"
     ]
    }
   ],
   "source": [
    "history_base = model_base.fit(x=X_train_base, y=y_train_base, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_per = model_per.fit(x=X_train_per, y=y_train_per, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n",
    "history_mdi = model_mdi.fit(x=X_train_mdi, y=y_train_mdi, epochs=150, batch_size=16, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Testdata using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "---------Base-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------Permutation-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n",
      "---------MDI-FeatureSelection-Prediction----------\n",
      "[[137   0]\n",
      " [164   0]]\n",
      "\n",
      "\n",
      "Class inactive:\n",
      "    Sensitivity (TPR): 100.000% (137 of 137)\n",
      "    Specificity (TNR):   0.000% (0 of 164)\n",
      "    Precision:          45.515% (137 of 301)\n",
      "    Neg. pred. value:      nan% (0 of 0)\n",
      "Class active:\n",
      "    Sensitivity (TPR):   0.000% (0 of 164)\n",
      "    Specificity (TNR): 100.000% (137 of 137)\n",
      "    Precision:             nan% (0 of 0)\n",
      "    Neg. pred. value:   45.515% (137 of 301)\n",
      "\n",
      "Overall accuracy:   45.515% (137 of 301)\n",
      "Balanced accuracy:  50.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/falli/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/home/falli/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/home/falli/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/home/falli/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n",
      "/home/falli/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print('    Neg. pred. value:  %7.3f%% (%d of %d)'%(100. * tn / (tn + fn) , tn, tn + fn))\n",
      "/home/falli/.pyenv/versions/3.10.12/envs/activity_prediction/lib/python3.10/site-packages/pyMLaux/functions.py:158: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  prec = tp / (tp + fp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[137,   0],\n",
       "       [164,   0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_base = model_base.predict(X_test_base)\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "\n",
    "print(\"---------Base-Prediction----------\")\n",
    "evaluate_classification_result(y_test_base,pred_base,classes=nn_data_base[\"target_names\"])\n",
    "print(\"---------Permutation-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_per,pred_per,classes=nn_data_per[\"target_names\"])\n",
    "print(\"---------MDI-FeatureSelection-Prediction----------\")\n",
    "evaluate_classification_result(y_test_mdi,pred_mdi,classes=nn_data_mdi[\"target_names\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_base = model_base.predict(X_test_base)\n",
    "classes_base = [1 if i > 0.5  else 0 for i in pred_base]\n",
    "\n",
    "pred_per = model_per.predict(X_test_per)\n",
    "classes_per = [1 if i > 0.5  else 0 for i in pred_per]\n",
    "\n",
    "pred_mdi = model_mdi.predict(X_test_mdi)\n",
    "classes_mdi = [1 if i > 0.5  else 0 for i in pred_mdi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_per.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_per):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_per\n",
    "result_df[\"PRED\"] = classes_per\n",
    "\n",
    "result_df.to_csv(result_dir/\"ACHE/fe_rf_per_nn.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(columns=[\"INDEX\"]),\n",
    "        pd.DataFrame(columns=nn_data_raw_mdi.columns[1:-1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, row in enumerate(X_test_mdi):\n",
    "    data = [i]\n",
    "    data.extend(row)\n",
    "    result_df.loc[len(result_df[\"INDEX\"])] = data\n",
    "\n",
    "result_df[\"LABEL\"] = y_test_mdi\n",
    "result_df[\"PRED\"] = classes_mdi\n",
    "\n",
    "result_df.to_csv(result_dir / \"ACHE/fe_rf_mdi_nn.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activity_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
